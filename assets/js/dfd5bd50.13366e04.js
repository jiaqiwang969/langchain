"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[13814],{3905:(e,n,t)=>{t.d(n,{Zo:()=>l,kt:()=>u});var r=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var d=r.createContext({}),p=function(e){var n=r.useContext(d),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},l=function(e){var n=p(e.components);return r.createElement(d.Provider,{value:n},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},g=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,d=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),c=p(t),g=a,u=c["".concat(d,".").concat(g)]||c[g]||m[g]||o;return t?r.createElement(u,i(i({ref:n},l),{},{components:t})):r.createElement(u,i({ref:n},l))}));function u(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,i=new Array(o);i[0]=g;var s={};for(var d in n)hasOwnProperty.call(n,d)&&(s[d]=n[d]);s.originalType=e,s[c]="string"==typeof e?e:a,i[1]=s;for(var p=2;p<o;p++)i[p]=t[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}g.displayName="MDXCreateElement"},17109:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>p});var r=t(87462),a=(t(67294),t(3905));const o={},i="SageMaker Endpoint Embeddings",s={unversionedId:"integrations/text_embedding/sagemaker-endpoint",id:"integrations/text_embedding/sagemaker-endpoint",title:"SageMaker Endpoint Embeddings",description:"Let's load the SageMaker Endpoints Embeddings class. The class can be used if you host, e.g. your own Hugging Face model on SageMaker.",source:"@site/docs/integrations/text_embedding/sagemaker-endpoint.md",sourceDirName:"integrations/text_embedding",slug:"/integrations/text_embedding/sagemaker-endpoint",permalink:"/langchain/docs/integrations/text_embedding/sagemaker-endpoint",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"OpenAI",permalink:"/langchain/docs/integrations/text_embedding/openai"},next:{title:"Self Hosted Embeddings",permalink:"/langchain/docs/integrations/text_embedding/self-hosted"}},d={},p=[],l={toc:p},c="wrapper";function m(e){let{components:n,...t}=e;return(0,a.kt)(c,(0,r.Z)({},l,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"sagemaker-endpoint-embeddings"},"SageMaker Endpoint Embeddings"),(0,a.kt)("p",null,"Let's load the SageMaker Endpoints Embeddings class. The class can be used if you host, e.g. your own Hugging Face model on SageMaker."),(0,a.kt)("p",null,"For instructions on how to do this, please see ",(0,a.kt)("a",{parentName:"p",href:"https://www.philschmid.de/custom-inference-huggingface-sagemaker"},"here"),". ",(0,a.kt)("strong",{parentName:"p"},"Note"),": In order to handle batched requests, you will need to adjust the return line in the ",(0,a.kt)("inlineCode",{parentName:"p"},"predict_fn()")," function within the custom ",(0,a.kt)("inlineCode",{parentName:"p"},"inference.py")," script:"),(0,a.kt)("p",null,"Change from"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},'return {"vectors": sentence_embeddings[0].tolist()}')),(0,a.kt)("p",null,"to:"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},'return {"vectors": sentence_embeddings.tolist()}'),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pip3 install langchain boto3\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "SagemakerEndpointEmbeddings", "source": "langchain.embeddings", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.sagemaker_endpoint.SagemakerEndpointEmbeddings.html", "title": "SageMaker Endpoint Embeddings"}, {"imported": "EmbeddingsContentHandler", "source": "langchain.embeddings.sagemaker_endpoint", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.sagemaker_endpoint.EmbeddingsContentHandler.html", "title": "SageMaker Endpoint Embeddings"}]--\x3e\nfrom typing import Dict, List\nfrom langchain.embeddings import SagemakerEndpointEmbeddings\nfrom langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\nimport json\n\n\nclass ContentHandler(EmbeddingsContentHandler):\n    content_type = "application/json"\n    accepts = "application/json"\n\n    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n        """\n        Transforms the input into bytes that can be consumed by SageMaker endpoint.\n        Args:\n            inputs: List of input strings.\n            model_kwargs: Additional keyword arguments to be passed to the endpoint.\n        Returns:\n            The transformed bytes input.\n        """\n        # Example: inference.py expects a JSON string with a "inputs" key:\n        input_str = json.dumps({"inputs": inputs, **model_kwargs})  \n        return input_str.encode("utf-8")\n\n    def transform_output(self, output: bytes) -> List[List[float]]:\n        """\n        Transforms the bytes output from the endpoint into a list of embeddings.\n        Args:\n            output: The bytes output from SageMaker endpoint.\n        Returns:\n            The transformed output - list of embeddings\n        Note:\n            The length of the outer list is the number of input strings.\n            The length of the inner lists is the embedding dimension.\n        """\n        # Example: inference.py returns a JSON string with the list of\n        # embeddings in a "vectors" key:\n        response_json = json.loads(output.read().decode("utf-8"))\n        return response_json["vectors"]\n\n\ncontent_handler = ContentHandler()\n\n\nembeddings = SagemakerEndpointEmbeddings(\n    # credentials_profile_name="credentials-profile-name",\n    endpoint_name="huggingface-pytorch-inference-2023-03-21-16-14-03-834",\n    region_name="us-east-1",\n    content_handler=content_handler,\n)\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'query_result = embeddings.embed_query("foo")\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'doc_results = embeddings.embed_documents(["foo"])\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"doc_results\n")))}m.isMDXComponent=!0}}]);