"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[98127],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>g});var o=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},r=Object.keys(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var p=o.createContext({}),s=function(e){var t=o.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},m=function(e){var t=s(e.components);return o.createElement(p.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},d=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,p=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),c=s(n),d=a,g=c["".concat(p,".").concat(d)]||c[d]||u[d]||r;return n?o.createElement(g,l(l({ref:t},m),{},{components:n})):o.createElement(g,l({ref:t},m))}));function g(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,l=new Array(r);l[0]=d;var i={};for(var p in t)hasOwnProperty.call(t,p)&&(i[p]=t[p]);i.originalType=e,i[c]="string"==typeof e?e:a,l[1]=i;for(var s=2;s<r;s++)l[s]=n[s];return o.createElement.apply(null,l)}return o.createElement.apply(null,n)}d.displayName="MDXCreateElement"},69684:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>g,frontMatter:()=>r,metadata:()=>i,toc:()=>s});var o=n(87462),a=(n(67294),n(3905));const r={},l="Google Vertex AI PaLM",i={unversionedId:"integrations/llms/google_vertex_ai_palm",id:"integrations/llms/google_vertex_ai_palm",title:"Google Vertex AI PaLM",description:"Note: This is seperate from the Google PaLM integration, it exposes Vertex AI PaLM API on Google Cloud.",source:"@site/docs/integrations/llms/google_vertex_ai_palm.md",sourceDirName:"integrations/llms",slug:"/integrations/llms/google_vertex_ai_palm",permalink:"/langchain/docs/integrations/llms/google_vertex_ai_palm",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"ForefrontAI",permalink:"/langchain/docs/integrations/llms/forefrontai"},next:{title:"GooseAI",permalink:"/langchain/docs/integrations/llms/gooseai"}},p={},s=[{value:"Setting up",id:"setting-up",level:2},{value:"Question-answering example",id:"question-answering-example",level:2},{value:"Code generation example",id:"code-generation-example",level:2},{value:"Using models deployed on Vertex Model Garden",id:"using-models-deployed-on-vertex-model-garden",level:2}],m=(c="CodeOutputBlock",function(e){return console.warn("Component "+c+" was not imported, exported, or provided by MDXProvider as global scope"),(0,a.kt)("div",e)});var c;const u={toc:s},d="wrapper";function g(e){let{components:t,...n}=e;return(0,a.kt)(d,(0,o.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"google-vertex-ai-palm"},"Google Vertex AI PaLM"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Note:")," This is seperate from the ",(0,a.kt)("inlineCode",{parentName:"p"},"Google PaLM")," integration, it exposes ",(0,a.kt)("a",{parentName:"p",href:"https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview"},"Vertex AI PaLM API")," on ",(0,a.kt)("inlineCode",{parentName:"p"},"Google Cloud"),". "),(0,a.kt)("h2",{id:"setting-up"},"Setting up"),(0,a.kt)("p",null,"By default, Google Cloud ",(0,a.kt)("a",{parentName:"p",href:"https://cloud.google.com/vertex-ai/docs/generative-ai/data-governance#foundation_model_development"},"does not use")," customer data to train its foundation models as part of Google Cloud's AI/ML Privacy Commitment. More details about how Google processes data can also be found in ",(0,a.kt)("a",{parentName:"p",href:"https://cloud.google.com/terms/data-processing-addendum"},"Google's Customer Data Processing Addendum (CDPA)"),"."),(0,a.kt)("p",null,"To use ",(0,a.kt)("inlineCode",{parentName:"p"},"Vertex AI PaLM")," you must have the ",(0,a.kt)("inlineCode",{parentName:"p"},"google-cloud-aiplatform")," Python package installed and either:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Have credentials configured for your environment (gcloud, workload identity, etc...)"),(0,a.kt)("li",{parentName:"ul"},"Store the path to a service account JSON file as the GOOGLE_APPLICATION_CREDENTIALS environment variable")),(0,a.kt)("p",null,"This codebase uses the ",(0,a.kt)("inlineCode",{parentName:"p"},"google.auth")," library which first looks for the application credentials variable mentioned above, and then looks for system-level auth."),(0,a.kt)("p",null,"For more information, see: "),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://cloud.google.com/docs/authentication/application-default-credentials#GAC"},"https://cloud.google.com/docs/authentication/application-default-credentials#GAC")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://googleapis.dev/python/google-auth/latest/reference/google.auth.html#module-google.auth"},"https://googleapis.dev/python/google-auth/latest/reference/google.auth.html#module-google.auth"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"#!pip install google-cloud-aiplatform\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "VertexAI", "source": "langchain.llms", "docs": "https://api.python.langchain.com/en/latest/llms/langchain.llms.vertexai.VertexAI.html", "title": "Google Vertex AI PaLM "}]--\x3e\nfrom langchain.llms import VertexAI\n')),(0,a.kt)("h2",{id:"question-answering-example"},"Question-answering example"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from langchain import PromptTemplate, LLMChain\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'template = """Question: {question}\n\nAnswer: Let\'s think step by step."""\n\nprompt = PromptTemplate(template=template, input_variables=["question"])\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"llm = VertexAI()\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"llm_chain = LLMChain(prompt=prompt, llm=llm)\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'question = "What NFL team won the Super Bowl in the year Justin Beiber was born?"\n\nllm_chain.run(question)\n')),(0,a.kt)(m,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    'Justin Bieber was born on March 1, 1994. The Super Bowl in 1994 was won by the San Francisco 49ers.\\nThe final answer: San Francisco 49ers.'\n"))),(0,a.kt)("h2",{id:"code-generation-example"},"Code generation example"),(0,a.kt)("p",null,"You can now leverage the ",(0,a.kt)("inlineCode",{parentName:"p"},"Codey API")," for code generation within ",(0,a.kt)("inlineCode",{parentName:"p"},"Vertex AI"),". "),(0,a.kt)("p",null,"The model names are:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"code-bison"),": for code suggestion"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"code-gecko"),": for code completion")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'llm = VertexAI(model_name="code-bison")\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"llm_chain = LLMChain(prompt=prompt, llm=llm)\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'question = "Write a python function that identifies if the number is a prime number?"\n\nllm_chain.run(question)\n')),(0,a.kt)(m,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'    \'```python\\ndef is_prime(n):\\n  """\\n  Determines if a number is prime.\\n\\n  Args:\\n    n: The number to be tested.\\n\\n  Returns:\\n    True if the number is prime, False otherwise.\\n  """\\n\\n  # Check if the number is 1.\\n  if n == 1:\\n    return False\\n\\n  # Check if the number is 2.\\n  if n == 2:\\n    return True\\n\\n\'\n'))),(0,a.kt)("h2",{id:"using-models-deployed-on-vertex-model-garden"},"Using models deployed on Vertex Model Garden"),(0,a.kt)("p",null,"Vertex Model Garden ",(0,a.kt)("a",{parentName:"p",href:"https://cloud.google.com/vertex-ai/docs/start/explore-models"},"exposes")," open-sourced models that can be deployed and served on Vertex AI. If you have successfully deployed a model from Vertex Model Garden, you can find a corresponding Vertex AI ",(0,a.kt)("a",{parentName:"p",href:"https://cloud.google.com/vertex-ai/docs/general/deployment#what_happens_when_you_deploy_a_model"},"endpoint")," in the console or via API."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "VertexAIModelGarden", "source": "langchain.llms", "docs": "https://api.python.langchain.com/en/latest/llms/langchain.llms.vertexai.VertexAIModelGarden.html", "title": "Google Vertex AI PaLM "}]--\x3e\nfrom langchain.llms import VertexAIModelGarden\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'llm = VertexAIModelGarden(\n    project="YOUR PROJECT",\n    endpoint_id="YOUR ENDPOINT_ID"\n)\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'llm("What is the meaning of life?")\n')),(0,a.kt)("p",null,"Like all LLMs, we can then compose it with other components:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "PromptTemplate", "source": "langchain.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html", "title": "Google Vertex AI PaLM "}]--\x3e\nfrom langchain.prompts import PromptTemplate\n\nprompt = PromptTemplate.from_template("What is the meaning of {thing}?")\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'llm_oss_chain = prompt | llm\n\nllm_oss_chain.invoke({"thing": "life"})\n')))}g.isMDXComponent=!0}}]);