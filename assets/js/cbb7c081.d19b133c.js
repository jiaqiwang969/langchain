"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[70569],{3905:(e,t,r)=>{r.d(t,{Zo:()=>m,kt:()=>d});var n=r(67294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function p(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var i=n.createContext({}),s=function(e){var t=n.useContext(i),r=t;return e&&(r="function"==typeof e?e(t):p(p({},t),e)),r},m=function(e){var t=s(e.components);return n.createElement(i.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},y=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,i=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),c=s(r),y=a,d=c["".concat(i,".").concat(y)]||c[y]||u[y]||o;return r?n.createElement(d,p(p({ref:t},m),{},{components:r})):n.createElement(d,p({ref:t},m))}));function d(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,p=new Array(o);p[0]=y;var l={};for(var i in t)hasOwnProperty.call(t,i)&&(l[i]=t[i]);l.originalType=e,l[c]="string"==typeof e?e:a,p[1]=l;for(var s=2;s<o;s++)p[s]=r[s];return n.createElement.apply(null,p)}return n.createElement.apply(null,r)}y.displayName="MDXCreateElement"},60874:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>i,contentTitle:()=>p,default:()=>d,frontMatter:()=>o,metadata:()=>l,toc:()=>s});var n=r(87462),a=(r(67294),r(3905));const o={},p="PromptLayer OpenAI",l={unversionedId:"integrations/llms/promptlayer_openai",id:"integrations/llms/promptlayer_openai",title:"PromptLayer OpenAI",description:"PromptLayer is the first platform that allows you to track, manage, and share your GPT prompt engineering. PromptLayer acts a middleware between your code and OpenAI\u2019s python library.",source:"@site/docs/integrations/llms/promptlayer_openai.md",sourceDirName:"integrations/llms",slug:"/integrations/llms/promptlayer_openai",permalink:"/langchain/docs/integrations/llms/promptlayer_openai",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"Prediction Guard",permalink:"/langchain/docs/integrations/llms/predictionguard"},next:{title:"RELLM",permalink:"/langchain/docs/integrations/llms/rellm_experimental"}},i={},s=[{value:"Install PromptLayer",id:"install-promptlayer",level:2},{value:"Imports",id:"imports",level:2},{value:"Set the Environment API Key",id:"set-the-environment-api-key",level:2},{value:"Use the PromptLayerOpenAI LLM like normal",id:"use-the-promptlayeropenai-llm-like-normal",level:2},{value:"Using PromptLayer Track",id:"using-promptlayer-track",level:2}],m=(c="CodeOutputBlock",function(e){return console.warn("Component "+c+" was not imported, exported, or provided by MDXProvider as global scope"),(0,a.kt)("div",e)});var c;const u={toc:s},y="wrapper";function d(e){let{components:t,...r}=e;return(0,a.kt)(y,(0,n.Z)({},u,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"promptlayer-openai"},"PromptLayer OpenAI"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"PromptLayer")," is the first platform that allows you to track, manage, and share your GPT prompt engineering. ",(0,a.kt)("inlineCode",{parentName:"p"},"PromptLayer")," acts a middleware between your code and ",(0,a.kt)("inlineCode",{parentName:"p"},"OpenAI\u2019s")," python library."),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"PromptLayer")," records all your ",(0,a.kt)("inlineCode",{parentName:"p"},"OpenAI API")," requests, allowing you to search and explore request history in the ",(0,a.kt)("inlineCode",{parentName:"p"},"PromptLayer")," dashboard."),(0,a.kt)("p",null,"This example showcases how to connect to ",(0,a.kt)("a",{parentName:"p",href:"https://www.promptlayer.com"},"PromptLayer")," to start recording your OpenAI requests."),(0,a.kt)("p",null,"Another example is ",(0,a.kt)("a",{parentName:"p",href:"https://python.langchain.com/en/latest/ecosystem/promptlayer.html"},"here"),"."),(0,a.kt)("h2",{id:"install-promptlayer"},"Install PromptLayer"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"promptlayer")," package is required to use PromptLayer with OpenAI. Install ",(0,a.kt)("inlineCode",{parentName:"p"},"promptlayer")," using pip."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pip install promptlayer\n")),(0,a.kt)("h2",{id:"imports"},"Imports"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "PromptLayerOpenAI", "source": "langchain.llms", "docs": "https://api.python.langchain.com/en/latest/llms/langchain.llms.promptlayer_openai.PromptLayerOpenAI.html", "title": "PromptLayer OpenAI"}]--\x3e\nimport os\nfrom langchain.llms import PromptLayerOpenAI\nimport promptlayer\n')),(0,a.kt)("h2",{id:"set-the-environment-api-key"},"Set the Environment API Key"),(0,a.kt)("p",null,"You can create a PromptLayer API Key at ",(0,a.kt)("a",{parentName:"p",href:"https://www.promptlayer.com"},"www.promptlayer.com")," by clicking the settings cog in the navbar."),(0,a.kt)("p",null,"Set it as an environment variable called ",(0,a.kt)("inlineCode",{parentName:"p"},"PROMPTLAYER_API_KEY"),"."),(0,a.kt)("p",null,"You also need an OpenAI Key, called ",(0,a.kt)("inlineCode",{parentName:"p"},"OPENAI_API_KEY"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from getpass import getpass\n\nPROMPTLAYER_API_KEY = getpass()\n")),(0,a.kt)(m,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"     \xb7\xb7\xb7\xb7\xb7\xb7\xb7\xb7\n"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'os.environ["PROMPTLAYER_API_KEY"] = PROMPTLAYER_API_KEY\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"from getpass import getpass\n\nOPENAI_API_KEY = getpass()\n")),(0,a.kt)(m,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"     \xb7\xb7\xb7\xb7\xb7\xb7\xb7\xb7\n"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY\n')),(0,a.kt)("h2",{id:"use-the-promptlayeropenai-llm-like-normal"},"Use the PromptLayerOpenAI LLM like normal"),(0,a.kt)("p",null,(0,a.kt)("em",{parentName:"p"},"You can optionally pass in ",(0,a.kt)("inlineCode",{parentName:"em"},"pl_tags")," to track your requests with PromptLayer's tagging feature.")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'llm = PromptLayerOpenAI(pl_tags=["langchain"])\nllm("I am a cat and I want")\n')),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"The above request should now appear on your ",(0,a.kt)("a",{parentName:"strong",href:"https://www.promptlayer.com"},"PromptLayer dashboard"),".")),(0,a.kt)("h2",{id:"using-promptlayer-track"},"Using PromptLayer Track"),(0,a.kt)("p",null,"If you would like to use any of the ",(0,a.kt)("a",{parentName:"p",href:"https://magniv.notion.site/Track-4deee1b1f7a34c1680d085f82567dab9"},"PromptLayer tracking features"),", you need to pass the argument ",(0,a.kt)("inlineCode",{parentName:"p"},"return_pl_id")," when instantializing the PromptLayer LLM to get the request id.  "),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'llm = PromptLayerOpenAI(return_pl_id=True)\nllm_results = llm.generate(["Tell me a joke"])\n\nfor res in llm_results.generations:\n    pl_request_id = res[0].generation_info["pl_request_id"]\n    promptlayer.track.score(request_id=pl_request_id, score=100)\n')),(0,a.kt)("p",null,"Using this allows you to track the performance of your model in the PromptLayer dashboard. If you are using a prompt template, you can attach a template to a request as well.\nOverall, this gives you the opportunity to track the performance of different templates and models in the PromptLayer dashboard."))}d.isMDXComponent=!0}}]);