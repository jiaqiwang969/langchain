"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8681],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>d});var r=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),p=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},c=function(e){var t=p(e.components);return r.createElement(s.Provider,{value:t},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},h=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),m=p(n),h=a,d=m["".concat(s,".").concat(h)]||m[h]||u[h]||o;return n?r.createElement(d,l(l({ref:t},c),{},{components:n})):r.createElement(d,l({ref:t},c))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,l=new Array(o);l[0]=h;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[m]="string"==typeof e?e:a,l[1]=i;for(var p=2;p<o;p++)l[p]=n[p];return r.createElement.apply(null,l)}return r.createElement.apply(null,n)}h.displayName="MDXCreateElement"},96966:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>p});var r=n(87462),a=(n(67294),n(3905));const o={},l="ChatGLM",i={unversionedId:"integrations/llms/chatglm",id:"integrations/llms/chatglm",title:"ChatGLM",description:"ChatGLM-6B is an open bilingual language model based on General Language Model (GLM) framework, with 6.2 billion parameters. With the quantization technique, users can deploy locally on consumer-grade graphics cards (only 6GB of GPU memory is required at the INT4 quantization level).",source:"@site/docs/integrations/llms/chatglm.md",sourceDirName:"integrations/llms",slug:"/integrations/llms/chatglm",permalink:"/langchain/docs/integrations/llms/chatglm",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"CerebriumAI",permalink:"/langchain/docs/integrations/llms/cerebriumai"},next:{title:"Clarifai",permalink:"/langchain/docs/integrations/llms/clarifai"}},s={},p=[],c=(m="CodeOutputBlock",function(e){return console.warn("Component "+m+" was not imported, exported, or provided by MDXProvider as global scope"),(0,a.kt)("div",e)});var m;const u={toc:p},h="wrapper";function d(e){let{components:t,...n}=e;return(0,a.kt)(h,(0,r.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"chatglm"},"ChatGLM"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/THUDM/ChatGLM-6B"},"ChatGLM-6B")," is an open bilingual language model based on General Language Model (GLM) framework, with 6.2 billion parameters. With the quantization technique, users can deploy locally on consumer-grade graphics cards (only 6GB of GPU memory is required at the INT4 quantization level). "),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/THUDM/ChatGLM2-6B"},"ChatGLM2-6B")," is the second-generation version of the open-source bilingual (Chinese-English) chat model ChatGLM-6B. It retains the smooth conversation flow and low deployment threshold of the first-generation model, while introducing the new features like better performance, longer context and more efficient inference."),(0,a.kt)("p",null,"This example goes over how to use LangChain to interact with ChatGLM2-6B Inference for text completion.\nChatGLM-6B and ChatGLM2-6B has the same api specs, so this example should work with both."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "ChatGLM", "source": "langchain.llms", "docs": "https://api.python.langchain.com/en/latest/llms/langchain.llms.chatglm.ChatGLM.html", "title": "ChatGLM"}]--\x3e\nfrom langchain.llms import ChatGLM\nfrom langchain import PromptTemplate, LLMChain\n\n# import os\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'template = """{question}"""\nprompt = PromptTemplate(template=template, input_variables=["question"])\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'# default endpoint_url for a local deployed ChatGLM api server\nendpoint_url = "http://127.0.0.1:8000"\n\n# direct access endpoint in a proxied environment\n# os.environ[\'NO_PROXY\'] = \'127.0.0.1\'\n\nllm = ChatGLM(\n    endpoint_url=endpoint_url,\n    max_token=80000,\n    history=[["\u6211\u5c06\u4ece\u7f8e\u56fd\u5230\u4e2d\u56fd\u6765\u65c5\u6e38\uff0c\u51fa\u884c\u524d\u5e0c\u671b\u4e86\u89e3\u4e2d\u56fd\u7684\u57ce\u5e02", "\u6b22\u8fce\u95ee\u6211\u4efb\u4f55\u95ee\u9898\u3002"]],\n    top_p=0.9,\n    model_kwargs={"sample_model_args": False},\n)\n\n# turn on with_history only when you want the LLM object to keep track of the conversation history\n# and send the accumulated context to the backend model api, which make it stateful. By default it is stateless.\n# llm.with_history = True\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"llm_chain = LLMChain(prompt=prompt, llm=llm)\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'question = "\u5317\u4eac\u548c\u4e0a\u6d77\u4e24\u5ea7\u57ce\u5e02\u6709\u4ec0\u4e48\u4e0d\u540c\uff1f"\n\nllm_chain.run(question)\n')),(0,a.kt)(c,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    ChatGLM payload: {'prompt': '\u5317\u4eac\u548c\u4e0a\u6d77\u4e24\u5ea7\u57ce\u5e02\u6709\u4ec0\u4e48\u4e0d\u540c\uff1f', 'temperature': 0.1, 'history': [['\u6211\u5c06\u4ece\u7f8e\u56fd\u5230\u4e2d\u56fd\u6765\u65c5\u6e38\uff0c\u51fa\u884c\u524d\u5e0c\u671b\u4e86\u89e3\u4e2d\u56fd\u7684\u57ce\u5e02', '\u6b22\u8fce\u95ee\u6211\u4efb\u4f55\u95ee\u9898\u3002']], 'max_length': 80000, 'top_p': 0.9, 'sample_model_args': False}\n\n\n\n\n\n    '\u5317\u4eac\u548c\u4e0a\u6d77\u662f\u4e2d\u56fd\u7684\u4e24\u4e2a\u9996\u90fd\uff0c\u5b83\u4eec\u5728\u8bb8\u591a\u65b9\u9762\u90fd\u6709\u6240\u4e0d\u540c\u3002\\n\\n\u5317\u4eac\u662f\u4e2d\u56fd\u7684\u653f\u6cbb\u548c\u6587\u5316\u4e2d\u5fc3\uff0c\u62e5\u6709\u60a0\u4e45\u7684\u5386\u53f2\u548c\u707f\u70c2\u7684\u6587\u5316\u3002\u5b83\u662f\u4e2d\u56fd\u6700\u91cd\u8981\u7684\u53e4\u90fd\u4e4b\u4e00\uff0c\u4e5f\u662f\u4e2d\u56fd\u5386\u53f2\u4e0a\u6700\u540e\u4e00\u4e2a\u5c01\u5efa\u738b\u671d\u7684\u90fd\u57ce\u3002\u5317\u4eac\u6709\u8bb8\u591a\u8457\u540d\u7684\u53e4\u8ff9\u548c\u666f\u70b9\uff0c\u4f8b\u5982\u7d2b\u7981\u57ce\u3001\u5929\u5b89\u95e8\u5e7f\u573a\u548c\u957f\u57ce\u7b49\u3002\\n\\n\u4e0a\u6d77\u662f\u4e2d\u56fd\u6700\u73b0\u4ee3\u5316\u7684\u57ce\u5e02\u4e4b\u4e00\uff0c\u4e5f\u662f\u4e2d\u56fd\u5546\u4e1a\u548c\u91d1\u878d\u4e2d\u5fc3\u3002\u4e0a\u6d77\u62e5\u6709\u8bb8\u591a\u56fd\u9645\u77e5\u540d\u7684\u4f01\u4e1a\u548c\u91d1\u878d\u673a\u6784\uff0c\u540c\u65f6\u4e5f\u6709\u8bb8\u591a\u8457\u540d\u7684\u666f\u70b9\u548c\u7f8e\u98df\u3002\u4e0a\u6d77\u7684\u5916\u6ee9\u662f\u4e00\u4e2a\u5386\u53f2\u60a0\u4e45\u7684\u5546\u4e1a\u533a\uff0c\u62e5\u6709\u8bb8\u591a\u6b27\u5f0f\u5efa\u7b51\u548c\u9910\u9986\u3002\\n\\n\u9664\u6b64\u4e4b\u5916\uff0c\u5317\u4eac\u548c\u4e0a\u6d77\u5728\u4ea4\u901a\u548c\u4eba\u53e3\u65b9\u9762\u4e5f\u6709\u5f88\u5927\u5dee\u5f02\u3002\u5317\u4eac\u662f\u4e2d\u56fd\u7684\u9996\u90fd\uff0c\u4eba\u53e3\u4f17\u591a\uff0c\u4ea4\u901a\u62e5\u5835\u95ee\u9898\u8f83\u4e3a\u4e25\u91cd\u3002\u800c\u4e0a\u6d77\u662f\u4e2d\u56fd\u7684\u5546\u4e1a\u548c\u91d1\u878d\u4e2d\u5fc3\uff0c\u4eba\u53e3\u5bc6\u5ea6\u8f83\u4f4e\uff0c\u4ea4\u901a\u76f8\u5bf9\u8f83\u4e3a\u4fbf\u5229\u3002\\n\\n\u603b\u7684\u6765\u8bf4\uff0c\u5317\u4eac\u548c\u4e0a\u6d77\u662f\u4e24\u4e2a\u62e5\u6709\u72ec\u7279\u9b45\u529b\u548c\u7279\u70b9\u7684\u57ce\u5e02\uff0c\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u5174\u8da3\u548c\u65f6\u95f4\u6765\u9009\u62e9\u524d\u5f80\u5176\u4e2d\u4e00\u5ea7\u57ce\u5e02\u65c5\u6e38\u3002'\n"))))}d.isMDXComponent=!0}}]);