"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[55965],{3905:(e,n,t)=>{t.d(n,{Zo:()=>p,kt:()=>u});var a=t(67294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function l(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?l(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,a,o=function(e,n){if(null==e)return{};var t,a,o={},l=Object.keys(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)t=l[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var s=a.createContext({}),c=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},p=function(e){var n=c(e.components);return a.createElement(s.Provider,{value:n},e.children)},g="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},h=a.forwardRef((function(e,n){var t=e.components,o=e.mdxType,l=e.originalType,s=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),g=c(t),h=o,u=g["".concat(s,".").concat(h)]||g[h]||m[h]||l;return t?a.createElement(u,r(r({ref:n},p),{},{components:t})):a.createElement(u,r({ref:n},p))}));function u(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var l=t.length,r=new Array(l);r[0]=h;var i={};for(var s in n)hasOwnProperty.call(n,s)&&(i[s]=n[s]);i.originalType=e,i[g]="string"==typeof e?e:o,r[1]=i;for(var c=2;c<l;c++)r[c]=t[c];return a.createElement.apply(null,r)}return a.createElement.apply(null,t)}h.displayName="MDXCreateElement"},2819:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>r,default:()=>m,frontMatter:()=>l,metadata:()=>i,toc:()=>c});var a=t(87462),o=(t(67294),t(3905));const l={},r="Log10",i={unversionedId:"integrations/providers/log10",id:"integrations/providers/log10",title:"Log10",description:"This page covers how to use the Log10 within LangChain.",source:"@site/docs/integrations/providers/log10.mdx",sourceDirName:"integrations/providers",slug:"/integrations/providers/log10",permalink:"/langchain/docs/integrations/providers/log10",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"Llama.cpp",permalink:"/langchain/docs/integrations/providers/llamacpp"},next:{title:"Marqo",permalink:"/langchain/docs/integrations/providers/marqo"}},s={},c=[{value:"What is Log10?",id:"what-is-log10",level:2},{value:"Quick start",id:"quick-start",level:2},{value:"How to enable Log10 data management for Langchain",id:"how-to-enable-log10-data-management-for-langchain",level:2},{value:"How to use tags with Log10",id:"how-to-use-tags-with-log10",level:2},{value:"How to debug Langchain calls",id:"how-to-debug-langchain-calls",level:2}],p={toc:c},g="wrapper";function m(e){let{components:n,...t}=e;return(0,o.kt)(g,(0,a.Z)({},p,t,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"log10"},"Log10"),(0,o.kt)("p",null,"This page covers how to use the ",(0,o.kt)("a",{parentName:"p",href:"https://log10.io"},"Log10")," within LangChain."),(0,o.kt)("h2",{id:"what-is-log10"},"What is Log10?"),(0,o.kt)("p",null,"Log10 is an ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/log10-io/log10"},"open source")," proxiless LLM data management and application development platform that lets you log, debug and tag your Langchain calls."),(0,o.kt)("h2",{id:"quick-start"},"Quick start"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Create your free account at ",(0,o.kt)("a",{parentName:"li",href:"https://log10.io"},"log10.io")),(0,o.kt)("li",{parentName:"ol"},"Add your ",(0,o.kt)("inlineCode",{parentName:"li"},"LOG10_TOKEN")," and ",(0,o.kt)("inlineCode",{parentName:"li"},"LOG10_ORG_ID")," from the Settings and Organization tabs respectively as environment variables."),(0,o.kt)("li",{parentName:"ol"},"Also add ",(0,o.kt)("inlineCode",{parentName:"li"},"LOG10_URL=https://log10.io")," and your usual LLM API key: for e.g. ",(0,o.kt)("inlineCode",{parentName:"li"},"OPENAI_API_KEY")," or ",(0,o.kt)("inlineCode",{parentName:"li"},"ANTHROPIC_API_KEY")," to your environment")),(0,o.kt)("h2",{id:"how-to-enable-log10-data-management-for-langchain"},"How to enable Log10 data management for Langchain"),(0,o.kt)("p",null,"Integration with log10 is a simple one-line ",(0,o.kt)("inlineCode",{parentName:"p"},"log10_callback")," integration as shown below:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "ChatOpenAI", "source": "langchain.chat_models", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html", "title": "Log10"}, {"imported": "HumanMessage", "source": "langchain.schema", "docs": "https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.HumanMessage.html", "title": "Log10"}]--\x3e\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema import HumanMessage\n\nfrom log10.langchain import Log10Callback\nfrom log10.llm import Log10Config\n\nlog10_callback = Log10Callback(log10_config=Log10Config())\n\nmessages = [\n    HumanMessage(content="You are a ping pong machine"),\n    HumanMessage(content="Ping?"),\n]\n\nllm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback])\n')),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/log10-io/log10/blob/main/logging.md#langchain-logger"},"Log10 + Langchain + Logs docs")),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://log10.io/docs/logs"},"More details + screenshots")," including instructions for self-hosting logs"),(0,o.kt)("h2",{id:"how-to-use-tags-with-log10"},"How to use tags with Log10"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "ChatAnthropic", "source": "langchain.chat_models", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.anthropic.ChatAnthropic.html", "title": "Log10"}, {"imported": "ChatOpenAI", "source": "langchain.chat_models", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html", "title": "Log10"}, {"imported": "HumanMessage", "source": "langchain.schema", "docs": "https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.HumanMessage.html", "title": "Log10"}]--\x3e\nfrom langchain import OpenAI\nfrom langchain.chat_models import ChatAnthropic\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema import HumanMessage\n\nfrom log10.langchain import Log10Callback\nfrom log10.llm import Log10Config\n\nlog10_callback = Log10Callback(log10_config=Log10Config())\n\nmessages = [\n    HumanMessage(content="You are a ping pong machine"),\n    HumanMessage(content="Ping?"),\n]\n\nllm = ChatOpenAI(model_name="gpt-3.5-turbo", callbacks=[log10_callback], temperature=0.5, tags=["test"])\ncompletion = llm.predict_messages(messages, tags=["foobar"])\nprint(completion)\n\nllm = ChatAnthropic(model="claude-2", callbacks=[log10_callback], temperature=0.7, tags=["baz"])\nllm.predict_messages(messages)\nprint(completion)\n\nllm = OpenAI(model_name="text-davinci-003", callbacks=[log10_callback], temperature=0.5)\ncompletion = llm.predict("You are a ping pong machine.\\nPing?\\n")\nprint(completion)\n')),(0,o.kt)("p",null,"You can also intermix direct OpenAI calls and Langchain LLM calls:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'import os\nfrom log10.load import log10, log10_session\nimport openai\nfrom langchain import OpenAI\n\nlog10(openai)\n\nwith log10_session(tags=["foo", "bar"]):\n    # Log a direct OpenAI call\n    response = openai.Completion.create(\n        model="text-ada-001",\n        prompt="Where is the Eiffel Tower?",\n        temperature=0,\n        max_tokens=1024,\n        top_p=1,\n        frequency_penalty=0,\n        presence_penalty=0,\n    )\n    print(response)\n\n    # Log a call via Langchain\n    llm = OpenAI(model_name="text-ada-001", temperature=0.5)\n    response = llm.predict("You are a ping pong machine.\\nPing?\\n")\n    print(response)\n')),(0,o.kt)("h2",{id:"how-to-debug-langchain-calls"},"How to debug Langchain calls"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://log10.io/docs/prompt_chain_debugging"},"Example of debugging")),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/log10-io/log10/tree/main/examples#langchain"},"More Langchain examples")))}m.isMDXComponent=!0}}]);