"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[76862],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>h});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},u=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},c="mdxType",g={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),c=p(n),m=o,h=c["".concat(s,".").concat(m)]||c[m]||g[m]||r;return n?a.createElement(h,l(l({ref:t},u),{},{components:n})):a.createElement(h,l({ref:t},u))}));function h(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,l=new Array(r);l[0]=m;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[c]="string"==typeof e?e:o,l[1]=i;for(var p=2;p<r;p++)l[p]=n[p];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},2325:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>p});var a=n(87462),o=(n(67294),n(3905));const r={},l="Plug-and-Plai",i={unversionedId:"use_cases/more/agents/agents/custom_agent_with_plugin_retrieval_using_plugnplai",id:"use_cases/more/agents/agents/custom_agent_with_plugin_retrieval_using_plugnplai",title:"Plug-and-Plai",description:"This notebook builds upon the idea of plugin retrieval, but pulls all tools from plugnplai - a directory of AI Plugins.",source:"@site/docs/use_cases/more/agents/agents/custom_agent_with_plugin_retrieval_using_plugnplai.md",sourceDirName:"use_cases/more/agents/agents",slug:"/use_cases/more/agents/agents/custom_agent_with_plugin_retrieval_using_plugnplai",permalink:"/langchain/docs/use_cases/more/agents/agents/custom_agent_with_plugin_retrieval_using_plugnplai",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"use_cases",previous:{title:"Custom Agent with PlugIn Retrieval",permalink:"/langchain/docs/use_cases/more/agents/agents/custom_agent_with_plugin_retrieval"},next:{title:"SalesGPT - Your Context-Aware AI Sales Assistant With Knowledge Base",permalink:"/langchain/docs/use_cases/more/agents/agents/sales_agent_with_context"}},s={},p=[{value:"Set up environment",id:"set-up-environment",level:2},{value:"Setup LLM",id:"setup-llm",level:2},{value:"Set up plugins",id:"set-up-plugins",level:2},{value:"Tool Retriever",id:"tool-retriever",level:2},{value:"Prompt Template",id:"prompt-template",level:2},{value:"Output Parser",id:"output-parser",level:2},{value:"Set up LLM, stop sequence, and the agent",id:"set-up-llm-stop-sequence-and-the-agent",level:2},{value:"Use the Agent",id:"use-the-agent",level:2}],u=(c="CodeOutputBlock",function(e){return console.warn("Component "+c+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var c;const g={toc:p},m="wrapper";function h(e){let{components:t,...n}=e;return(0,o.kt)(m,(0,a.Z)({},g,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"plug-and-plai"},"Plug-and-Plai"),(0,o.kt)("p",null,"This notebook builds upon the idea of ",(0,o.kt)("a",{parentName:"p",href:"./custom_agent_with_plugin_retrieval.html"},"plugin retrieval"),", but pulls all tools from ",(0,o.kt)("inlineCode",{parentName:"p"},"plugnplai")," - a directory of AI Plugins."),(0,o.kt)("h2",{id:"set-up-environment"},"Set up environment"),(0,o.kt)("p",null,"Do necessary imports, etc."),(0,o.kt)("p",null,"Install plugnplai lib to get a list of active plugins from ",(0,o.kt)("a",{parentName:"p",href:"https://plugplai.com"},"https://plugplai.com")," directory"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"pip install plugnplai -q\n")),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    \n    [notice] A new release of pip available: 22.3.1 -> 23.1.1\n    [notice] To update, run: pip install --upgrade pip\n    Note: you may need to restart the kernel to use updated packages.\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "Tool", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/tools/langchain.tools.base.Tool.html", "title": "Plug-and-Plai"}, {"imported": "AgentExecutor", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html", "title": "Plug-and-Plai"}, {"imported": "LLMSingleActionAgent", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.LLMSingleActionAgent.html", "title": "Plug-and-Plai"}, {"imported": "AgentOutputParser", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentOutputParser.html", "title": "Plug-and-Plai"}, {"imported": "StringPromptTemplate", "source": "langchain.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain.prompts.base.StringPromptTemplate.html", "title": "Plug-and-Plai"}, {"imported": "AgentAction", "source": "langchain.schema", "docs": "https://api.python.langchain.com/en/latest/schema/langchain.schema.agent.AgentAction.html", "title": "Plug-and-Plai"}, {"imported": "AgentFinish", "source": "langchain.schema", "docs": "https://api.python.langchain.com/en/latest/schema/langchain.schema.agent.AgentFinish.html", "title": "Plug-and-Plai"}, {"imported": "NLAToolkit", "source": "langchain.agents.agent_toolkits", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_toolkits.nla.toolkit.NLAToolkit.html", "title": "Plug-and-Plai"}, {"imported": "AIPlugin", "source": "langchain.tools.plugin", "docs": "https://api.python.langchain.com/en/latest/tools/langchain.tools.plugin.AIPlugin.html", "title": "Plug-and-Plai"}]--\x3e\nfrom langchain.agents import (\n    Tool,\n    AgentExecutor,\n    LLMSingleActionAgent,\n    AgentOutputParser,\n)\nfrom langchain.prompts import StringPromptTemplate\nfrom langchain import OpenAI, SerpAPIWrapper, LLMChain\nfrom typing import List, Union\nfrom langchain.schema import AgentAction, AgentFinish\nfrom langchain.agents.agent_toolkits import NLAToolkit\nfrom langchain.tools.plugin import AIPlugin\nimport re\nimport plugnplai\n')),(0,o.kt)("h2",{id:"setup-llm"},"Setup LLM"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"llm = OpenAI(temperature=0)\n")),(0,o.kt)("h2",{id:"set-up-plugins"},"Set up plugins"),(0,o.kt)("p",null,"Load and index plugins"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# Get all plugins from plugnplai.com\nurls = plugnplai.get_plugins()\n\n#  Get ChatGPT plugins - only ChatGPT verified plugins\nurls = plugnplai.get_plugins(filter="ChatGPT")\n\n#  Get working plugins - only tested plugins (in progress)\nurls = plugnplai.get_plugins(filter="working")\n\n\nAI_PLUGINS = [AIPlugin.from_url(url + "/.well-known/ai-plugin.json") for url in urls]\n')),(0,o.kt)("h2",{id:"tool-retriever"},"Tool Retriever"),(0,o.kt)("p",null,"We will use a vectorstore to create embeddings for each tool description. Then, for an incoming query we can create embeddings for that query and do a similarity search for relevant tools."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "FAISS", "source": "langchain.vectorstores", "docs": "https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.faiss.FAISS.html", "title": "Plug-and-Plai"}, {"imported": "OpenAIEmbeddings", "source": "langchain.embeddings", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html", "title": "Plug-and-Plai"}, {"imported": "Document", "source": "langchain.schema", "docs": "https://api.python.langchain.com/en/latest/schema/langchain.schema.document.Document.html", "title": "Plug-and-Plai"}]--\x3e\nfrom langchain.vectorstores import FAISS\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.schema import Document\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'embeddings = OpenAIEmbeddings()\ndocs = [\n    Document(\n        page_content=plugin.description_for_model,\n        metadata={"plugin_name": plugin.name_for_model},\n    )\n    for plugin in AI_PLUGINS\n]\nvector_store = FAISS.from_documents(docs, embeddings)\ntoolkits_dict = {\n    plugin.name_for_model: NLAToolkit.from_llm_and_ai_plugin(llm, plugin)\n    for plugin in AI_PLUGINS\n}\n')),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n    Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n    Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n    Attempting to load an OpenAPI 3.0.2 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n    Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n    Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n    Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n    Attempting to load an OpenAPI 3.0.1 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n    Attempting to load a Swagger 2.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'retriever = vector_store.as_retriever()\n\n\ndef get_tools(query):\n    # Get documents, which contain the Plugins to use\n    docs = retriever.get_relevant_documents(query)\n    # Get the toolkits, one for each plugin\n    tool_kits = [toolkits_dict[d.metadata["plugin_name"]] for d in docs]\n    # Get the tools: a separate NLAChain for each endpoint\n    tools = []\n    for tk in tool_kits:\n        tools.extend(tk.nla_tools)\n    return tools\n')),(0,o.kt)("p",null,"We can now test this retriever to see if it seems to work."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'tools = get_tools("What could I do today with my kiddo")\n[t.name for t in tools]\n')),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    ['Milo.askMilo',\n     'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.search_all_actions',\n     'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.preview_a_zap',\n     'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_configuration_link',\n     'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.list_exposed_actions',\n     'SchoolDigger_API_V2.0.Autocomplete_GetSchools',\n     'SchoolDigger_API_V2.0.Districts_GetAllDistricts2',\n     'SchoolDigger_API_V2.0.Districts_GetDistrict2',\n     'SchoolDigger_API_V2.0.Rankings_GetSchoolRank2',\n     'SchoolDigger_API_V2.0.Rankings_GetRank_District',\n     'SchoolDigger_API_V2.0.Schools_GetAllSchools20',\n     'SchoolDigger_API_V2.0.Schools_GetSchool20',\n     'Speak.translate',\n     'Speak.explainPhrase',\n     'Speak.explainTask']\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'tools = get_tools("what shirts can i buy?")\n[t.name for t in tools]\n')),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    ['Open_AI_Klarna_product_Api.productsUsingGET',\n     'Milo.askMilo',\n     'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.search_all_actions',\n     'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.preview_a_zap',\n     'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.get_configuration_link',\n     'Zapier_Natural_Language_Actions_(NLA)_API_(Dynamic)_-_Beta.list_exposed_actions',\n     'SchoolDigger_API_V2.0.Autocomplete_GetSchools',\n     'SchoolDigger_API_V2.0.Districts_GetAllDistricts2',\n     'SchoolDigger_API_V2.0.Districts_GetDistrict2',\n     'SchoolDigger_API_V2.0.Rankings_GetSchoolRank2',\n     'SchoolDigger_API_V2.0.Rankings_GetRank_District',\n     'SchoolDigger_API_V2.0.Schools_GetAllSchools20',\n     'SchoolDigger_API_V2.0.Schools_GetSchool20']\n"))),(0,o.kt)("h2",{id:"prompt-template"},"Prompt Template"),(0,o.kt)("p",null,"The prompt template is pretty standard, because we're not actually changing that much logic in the actual prompt template, but rather we are just changing how retrieval is done."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# Set up the base template\ntemplate = """Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n\n{tools}\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin! Remember to speak as a pirate when giving your final answer. Use lots of "Arg"s\n\nQuestion: {input}\n{agent_scratchpad}"""\n')),(0,o.kt)("p",null,"The custom prompt template now has the concept of a tools_getter, which we call on the input to select the tools to use"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from typing import Callable\n\n\n# Set up a prompt template\nclass CustomPromptTemplate(StringPromptTemplate):\n    # The template to use\n    template: str\n    ############## NEW ######################\n    # The list of tools available\n    tools_getter: Callable\n\n    def format(self, **kwargs) -> str:\n        # Get the intermediate steps (AgentAction, Observation tuples)\n        # Format them in a particular way\n        intermediate_steps = kwargs.pop("intermediate_steps")\n        thoughts = ""\n        for action, observation in intermediate_steps:\n            thoughts += action.log\n            thoughts += f"\\nObservation: {observation}\\nThought: "\n        # Set the agent_scratchpad variable to that value\n        kwargs["agent_scratchpad"] = thoughts\n        ############## NEW ######################\n        tools = self.tools_getter(kwargs["input"])\n        # Create a tools variable from the list of tools provided\n        kwargs["tools"] = "\\n".join(\n            [f"{tool.name}: {tool.description}" for tool in tools]\n        )\n        # Create a list of tool names for the tools provided\n        kwargs["tool_names"] = ", ".join([tool.name for tool in tools])\n        return self.template.format(**kwargs)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'prompt = CustomPromptTemplate(\n    template=template,\n    tools_getter=get_tools,\n    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n    # This includes the `intermediate_steps` variable because that is needed\n    input_variables=["input", "intermediate_steps"],\n)\n')),(0,o.kt)("h2",{id:"output-parser"},"Output Parser"),(0,o.kt)("p",null,"The output parser is unchanged from the previous notebook, since we are not changing anything about the output format."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'class CustomOutputParser(AgentOutputParser):\n    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n        # Check if agent should finish\n        if "Final Answer:" in llm_output:\n            return AgentFinish(\n                # Return values is generally always a dictionary with a single `output` key\n                # It is not recommended to try anything else at the moment :)\n                return_values={"output": llm_output.split("Final Answer:")[-1].strip()},\n                log=llm_output,\n            )\n        # Parse out the action and action input\n        regex = r"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)"\n        match = re.search(regex, llm_output, re.DOTALL)\n        if not match:\n            raise ValueError(f"Could not parse LLM output: `{llm_output}`")\n        action = match.group(1).strip()\n        action_input = match.group(2)\n        # Return the action and action input\n        return AgentAction(\n            tool=action, tool_input=action_input.strip(" ").strip(\'"\'), log=llm_output\n        )\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"output_parser = CustomOutputParser()\n")),(0,o.kt)("h2",{id:"set-up-llm-stop-sequence-and-the-agent"},"Set up LLM, stop sequence, and the agent"),(0,o.kt)("p",null,"Also the same as the previous notebook"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"llm = OpenAI(temperature=0)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"# LLM chain consisting of the LLM and a prompt\nllm_chain = LLMChain(llm=llm, prompt=prompt)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'tool_names = [tool.name for tool in tools]\nagent = LLMSingleActionAgent(\n    llm_chain=llm_chain,\n    output_parser=output_parser,\n    stop=["\\nObservation:"],\n    allowed_tools=tool_names,\n)\n')),(0,o.kt)("h2",{id:"use-the-agent"},"Use the Agent"),(0,o.kt)("p",null,"Now we can use it!"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"agent_executor = AgentExecutor.from_agent_and_tools(\n    agent=agent, tools=tools, verbose=True\n)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'agent_executor.run("what shirts can i buy?")\n')),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new AgentExecutor chain...\n    Thought: I need to find a product API\n    Action: Open_AI_Klarna_product_Api.productsUsingGET\n    Action Input: shirts\n    \n    Observation:I found 10 shirts from the API response. They range in price from $9.99 to $450.00 and come in a variety of materials, colors, and patterns. I now know what shirts I can buy\n    Final Answer: Arg, I found 10 shirts from the API response. They range in price from $9.99 to $450.00 and come in a variety of materials, colors, and patterns.\n    \n    > Finished chain.\n\n\n\n\n\n    'Arg, I found 10 shirts from the API response. They range in price from $9.99 to $450.00 and come in a variety of materials, colors, and patterns.'\n"))))}h.isMDXComponent=!0}}]);