"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[45422],{3905:(e,t,r)=>{r.d(t,{Zo:()=>i,kt:()=>h});var n=r(67294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function s(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function p(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var u=n.createContext({}),l=function(e){var t=n.useContext(u),r=t;return e&&(r="function"==typeof e?e(t):s(s({},t),e)),r},i=function(e){var t=l(e.components);return n.createElement(u.Provider,{value:t},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,a=e.originalType,u=e.parentName,i=p(e,["components","mdxType","originalType","parentName"]),c=l(r),d=o,h=c["".concat(u,".").concat(d)]||c[d]||m[d]||a;return r?n.createElement(h,s(s({ref:t},i),{},{components:r})):n.createElement(h,s({ref:t},i))}));function h(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=r.length,s=new Array(a);s[0]=d;var p={};for(var u in t)hasOwnProperty.call(t,u)&&(p[u]=t[u]);p.originalType=e,p[c]="string"==typeof e?e:o,s[1]=p;for(var l=2;l<a;l++)s[l]=r[l];return n.createElement.apply(null,s)}return n.createElement.apply(null,r)}d.displayName="MDXCreateElement"},78396:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>d,contentTitle:()=>c,default:()=>y,frontMatter:()=>i,metadata:()=>m,toc:()=>h});var n=r(87462),o=(r(67294),r(3905));const a=(s="CodeOutputBlock",function(e){return console.warn("Component "+s+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var s;const p={toc:[]},u="wrapper";function l(e){let{components:t,...r}=e;return(0,o.kt)(u,(0,n.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.output_parsers import StructuredOutputParser, ResponseSchema\nfrom langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\nfrom langchain.llms import OpenAI\nfrom langchain.chat_models import ChatOpenAI\n")),(0,o.kt)("p",null,"Here we define the response schema we want to receive."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'response_schemas = [\n    ResponseSchema(name="answer", description="answer to the user\'s question"),\n    ResponseSchema(name="source", description="source used to answer the user\'s question, should be a website.")\n]\noutput_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n')),(0,o.kt)("p",null,"We now get a string that contains instructions for how the response should be formatted, and we then insert that into our prompt."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'format_instructions = output_parser.get_format_instructions()\nprompt = PromptTemplate(\n    template="answer the users question as best as possible.\\n{format_instructions}\\n{question}",\n    input_variables=["question"],\n    partial_variables={"format_instructions": format_instructions}\n)\n')),(0,o.kt)("p",null,"We can now use this to format a prompt to send to the language model, and then parse the returned result."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"model = OpenAI(temperature=0)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'_input = prompt.format_prompt(question="what\'s the capital of france?")\noutput = model(_input.to_string())\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"output_parser.parse(output)\n")),(0,o.kt)(a,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'answer': 'Paris',\n     'source': 'https://www.worldatlas.com/articles/what-is-the-capital-of-france.html'}\n"))),(0,o.kt)("p",null,"And here's an example of using this in a chat model"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"chat_model = ChatOpenAI(temperature=0)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'prompt = ChatPromptTemplate(\n    messages=[\n        HumanMessagePromptTemplate.from_template("answer the users question as best as possible.\\n{format_instructions}\\n{question}")  \n    ],\n    input_variables=["question"],\n    partial_variables={"format_instructions": format_instructions}\n)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'_input = prompt.format_prompt(question="what\'s the capital of france?")\noutput = chat_model(_input.to_messages())\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"output_parser.parse(output.content)\n")),(0,o.kt)(a,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'answer': 'Paris', 'source': 'https://en.wikipedia.org/wiki/Paris'}\n"))))}l.isMDXComponent=!0;const i={},c="Structured output parser",m={unversionedId:"modules/model_io/output_parsers/structured",id:"modules/model_io/output_parsers/structured",title:"Structured output parser",description:"This output parser can be used when you want to return multiple fields. While the Pydantic/JSON parser is more powerful, we initially experimented with data structures having text fields only.",source:"@site/docs/modules/model_io/output_parsers/structured.mdx",sourceDirName:"modules/model_io/output_parsers",slug:"/modules/model_io/output_parsers/structured",permalink:"/langchain/docs/modules/model_io/output_parsers/structured",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Retry parser",permalink:"/langchain/docs/modules/model_io/output_parsers/retry"},next:{title:"Retrieval",permalink:"/langchain/docs/modules/data_connection/"}},d={},h=[],f={toc:h},g="wrapper";function y(e){let{components:t,...r}=e;return(0,o.kt)(g,(0,n.Z)({},f,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"structured-output-parser"},"Structured output parser"),(0,o.kt)("p",null,"This output parser can be used when you want to return multiple fields. While the Pydantic/JSON parser is more powerful, we initially experimented with data structures having text fields only."),(0,o.kt)(l,{mdxType:"Example"}))}y.isMDXComponent=!0}}]);