"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[74972],{3905:(e,t,a)=>{a.d(t,{Zo:()=>i,kt:()=>f});var n=a(67294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function p(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var m=n.createContext({}),s=function(e){var t=n.useContext(m),a=t;return e&&(a="function"==typeof e?e(t):p(p({},t),e)),a},i=function(e){var t=s(e.components);return n.createElement(m.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,m=e.parentName,i=l(e,["components","mdxType","originalType","parentName"]),c=s(a),d=o,f=c["".concat(m,".").concat(d)]||c[d]||u[d]||r;return a?n.createElement(f,p(p({ref:t},i),{},{components:a})):n.createElement(f,p({ref:t},i))}));function f(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,p=new Array(r);p[0]=d;var l={};for(var m in t)hasOwnProperty.call(t,m)&&(l[m]=t[m]);l.originalType=e,l[c]="string"==typeof e?e:o,p[1]=l;for(var s=2;s<r;s++)p[s]=a[s];return n.createElement.apply(null,p)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},96692:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>d,contentTitle:()=>c,default:()=>y,frontMatter:()=>i,metadata:()=>u,toc:()=>f});var n=a(87462),o=(a(67294),a(3905));const r=(p="CodeOutputBlock",function(e){return console.warn("Component "+p+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var p;const l={toc:[{value:"Prompt template",id:"prompt-template",level:2},{value:"Chat prompt template",id:"chat-prompt-template",level:2}]},m="wrapper";function s(e){let{components:t,...a}=e;return(0,o.kt)(m,(0,n.Z)({},l,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"Typically, language models expect the prompt to either be a string or else a list of chat messages."),(0,o.kt)("h2",{id:"prompt-template"},"Prompt template"),(0,o.kt)("p",null,"Use ",(0,o.kt)("inlineCode",{parentName:"p"},"PromptTemplate")," to create a template for a string prompt."),(0,o.kt)("p",null,"By default, ",(0,o.kt)("inlineCode",{parentName:"p"},"PromptTemplate")," uses ",(0,o.kt)("a",{parentName:"p",href:"https://docs.python.org/3/library/stdtypes.html#str.format"},"Python's str.format"),"\nsyntax for templating; however other templating syntax is available (e.g., ",(0,o.kt)("inlineCode",{parentName:"p"},"jinja2"),")."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain import PromptTemplate\n\nprompt_template = PromptTemplate.from_template(\n    "Tell me a {adjective} joke about {content}."\n)\nprompt_template.format(adjective="funny", content="chickens")\n')),(0,o.kt)(r,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'"Tell me a funny joke about chickens."\n'))),(0,o.kt)("p",null,"The template supports any number of variables, including no variables:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain import PromptTemplate\n\nprompt_template = PromptTemplate.from_template(\n"Tell me a joke"\n)\nprompt_template.format()\n')),(0,o.kt)("p",null,"For additional validation, specify ",(0,o.kt)("inlineCode",{parentName:"p"},"input_variables")," explicitly. These variables\nwill be compared against the variables present in the template string during instantiation, raising an exception if\nthere is a mismatch; for example,"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain import PromptTemplate\n\ninvalid_prompt = PromptTemplate(\n    input_variables=["adjective"],\n    template="Tell me a {adjective} joke about {content}."\n)\n')),(0,o.kt)("p",null,"You can create custom prompt templates that format the prompt in any way you want.\nFor more information, see ",(0,o.kt)("a",{parentName:"p",href:"./custom_prompt_template.html"},"Custom Prompt Templates"),"."),(0,o.kt)("h2",{id:"chat-prompt-template"},"Chat prompt template"),(0,o.kt)("p",null,"The prompt to ",(0,o.kt)("a",{parentName:"p",href:"../models/chat"},"chat models")," is a list of chat messages."),(0,o.kt)("p",null,"Each chat message is associated with content, and an additional parameter called ",(0,o.kt)("inlineCode",{parentName:"p"},"role"),".\nFor example, in the OpenAI ",(0,o.kt)("a",{parentName:"p",href:"https://platform.openai.com/docs/guides/chat/introduction"},"Chat Completions API"),", a chat message can be associated with an AI assistant, a human or a system role."),(0,o.kt)("p",null,"Create a chat prompt template like this:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.prompts import ChatPromptTemplate\n\ntemplate = ChatPromptTemplate.from_messages([\n    ("system", "You are a helpful AI bot. Your name is {name}."),\n    ("human", "Hello, how are you doing?"),\n    ("ai", "I\'m doing well, thanks!"),\n    ("human", "{user_input}"),\n])\n\nmessages = template.format_messages(\n    name="Bob",\n    user_input="What is your name?"\n)\n')),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"ChatPromptTemplate.from_messages")," accepts a variety of message representations."),(0,o.kt)("p",null,"For example, in addition to using the 2-tuple representation of (type, content) used\nabove, you could pass in an instance of ",(0,o.kt)("inlineCode",{parentName:"p"},"MessagePromptTemplate")," or ",(0,o.kt)("inlineCode",{parentName:"p"},"BaseMessage"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.prompts import ChatPromptTemplate\nfrom langchain.prompts.chat import SystemMessage, HumanMessagePromptTemplate\n\ntemplate = ChatPromptTemplate.from_messages(\n    [\n        SystemMessage(\n            content=(\n                "You are a helpful assistant that re-writes the user\'s text to "\n                "sound more upbeat."\n            )\n        ),\n        HumanMessagePromptTemplate.from_template("{text}"),\n    ]\n)\n\nfrom langchain.chat_models import ChatOpenAI\n\nllm = ChatOpenAI()\nllm(template.format_messages(text=\'i dont like eating tasty things.\'))\n')),(0,o.kt)(r,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"AIMessage(content='I absolutely adore indulging in delicious treats!', additional_kwargs={}, example=False)\n"))),(0,o.kt)("p",null,"This provides you with a lot of flexibility in how you construct your chat prompts."))}s.isMDXComponent=!0;const i={sidebar_position:0},c="Prompt templates",u={unversionedId:"modules/model_io/prompts/prompt_templates/index",id:"modules/model_io/prompts/prompt_templates/index",title:"Prompt templates",description:"Prompt templates are pre-defined recipes for generating prompts for language models.",source:"@site/docs/modules/model_io/prompts/prompt_templates/index.mdx",sourceDirName:"modules/model_io/prompts/prompt_templates",slug:"/modules/model_io/prompts/prompt_templates/",permalink:"/langchain/docs/modules/model_io/prompts/prompt_templates/",draft:!1,tags:[],version:"current",sidebarPosition:0,frontMatter:{sidebar_position:0},sidebar:"docs",previous:{title:"Prompts",permalink:"/langchain/docs/modules/model_io/prompts/"},next:{title:"Connecting to a Feature Store",permalink:"/langchain/docs/modules/model_io/prompts/prompt_templates/connecting_to_a_feature_store"}},d={},f=[],h={toc:f},g="wrapper";function y(e){let{components:t,...a}=e;return(0,o.kt)(g,(0,n.Z)({},h,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"prompt-templates"},"Prompt templates"),(0,o.kt)("p",null,"Prompt templates are pre-defined recipes for generating prompts for language models."),(0,o.kt)("p",null,"A template may include instructions, few-shot examples, and specific context and\nquestions appropriate for a given task."),(0,o.kt)("p",null,"LangChain provides tooling to create and work with prompt templates."),(0,o.kt)("p",null,"LangChain strives to create model agnostic templates to make it easy to reuse\nexisting templates across different language models."),(0,o.kt)(s,{mdxType:"GetStarted"}))}y.isMDXComponent=!0}}]);