"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[89661],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>f});var n=a(67294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),d=c(a),m=o,f=d["".concat(l,".").concat(m)]||d[m]||u[m]||r;return a?n.createElement(f,s(s({ref:t},p),{},{components:a})):n.createElement(f,s({ref:t},p))}));function f(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,s=new Array(r);s[0]=m;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[d]="string"==typeof e?e:o,s[1]=i;for(var c=2;c<r;c++)s[c]=a[c];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},17134:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>f,frontMatter:()=>r,metadata:()=>i,toc:()=>c});var n=a(87462),o=(a(67294),a(3905));const r={},s="Apify Dataset",i={unversionedId:"integrations/document_loaders/apify_dataset",id:"integrations/document_loaders/apify_dataset",title:"Apify Dataset",description:"Apify Dataset is a scaleable append-only storage with sequential access built for storing structured web scraping results, such as a list of products or Google SERPs, and then export them to various formats like JSON, CSV, or Excel. Datasets are mainly used to save results of Apify Actors\u2014serverless cloud programs for varius web scraping, crawling, and data extraction use cases.",source:"@site/docs/integrations/document_loaders/apify_dataset.md",sourceDirName:"integrations/document_loaders",slug:"/integrations/document_loaders/apify_dataset",permalink:"/langchain/docs/integrations/document_loaders/apify_dataset",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"Alibaba Cloud MaxCompute",permalink:"/langchain/docs/integrations/document_loaders/alibaba_cloud_maxcompute"},next:{title:"ArcGIS",permalink:"/langchain/docs/integrations/document_loaders/arcgis"}},l={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"An example with question answering",id:"an-example-with-question-answering",level:2}],p=(d="CodeOutputBlock",function(e){return console.warn("Component "+d+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var d;const u={toc:c},m="wrapper";function f(e){let{components:t,...a}=e;return(0,o.kt)(m,(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"apify-dataset"},"Apify Dataset"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"https://docs.apify.com/platform/storage/dataset"},"Apify Dataset")," is a scaleable append-only storage with sequential access built for storing structured web scraping results, such as a list of products or Google SERPs, and then export them to various formats like JSON, CSV, or Excel. Datasets are mainly used to save results of ",(0,o.kt)("a",{parentName:"p",href:"https://apify.com/store"},"Apify Actors"),"\u2014serverless cloud programs for varius web scraping, crawling, and data extraction use cases.")),(0,o.kt)("p",null,"This notebook shows how to load Apify datasets to LangChain."),(0,o.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,o.kt)("p",null,"You need to have an existing dataset on the Apify platform. If you don't have one, please first check out ",(0,o.kt)("a",{parentName:"p",href:"/docs/integrations/tools/apify.html"},"this notebook")," on how to use Apify to extract content from documentation, knowledge bases, help centers, or blogs."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"#!pip install apify-client\n")),(0,o.kt)("p",null,"First, import ",(0,o.kt)("inlineCode",{parentName:"p"},"ApifyDatasetLoader")," into your source code:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "ApifyDatasetLoader", "source": "langchain.document_loaders", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.apify_dataset.ApifyDatasetLoader.html", "title": "Apify Dataset"}, {"imported": "Document", "source": "langchain.document_loaders.base", "docs": "https://api.python.langchain.com/en/latest/schema/langchain.schema.document.Document.html", "title": "Apify Dataset"}]--\x3e\nfrom langchain.document_loaders import ApifyDatasetLoader\nfrom langchain.document_loaders.base import Document\n')),(0,o.kt)("p",null,"Then provide a function that maps Apify dataset record fields to LangChain ",(0,o.kt)("inlineCode",{parentName:"p"},"Document")," format."),(0,o.kt)("p",null,"For example, if your dataset items are structured like this:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-json"},'{\n    "url": "https://apify.com",\n    "text": "Apify is the best web scraping and automation platform."\n}\n')),(0,o.kt)("p",null,"The mapping function in the code below will convert them to LangChain ",(0,o.kt)("inlineCode",{parentName:"p"},"Document")," format, so that you can use them further with any LLM model (e.g. for question answering)."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'loader = ApifyDatasetLoader(\n    dataset_id="your-dataset-id",\n    dataset_mapping_function=lambda dataset_item: Document(\n        page_content=dataset_item["text"], metadata={"source": dataset_item["url"]}\n    ),\n)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"data = loader.load()\n")),(0,o.kt)("h2",{id:"an-example-with-question-answering"},"An example with question answering"),(0,o.kt)("p",null,"In this example, we use data from a dataset to answer a question."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "Document", "source": "langchain.docstore.document", "docs": "https://api.python.langchain.com/en/latest/schema/langchain.schema.document.Document.html", "title": "Apify Dataset"}, {"imported": "ApifyDatasetLoader", "source": "langchain.document_loaders", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.apify_dataset.ApifyDatasetLoader.html", "title": "Apify Dataset"}, {"imported": "VectorstoreIndexCreator", "source": "langchain.indexes", "docs": "https://api.python.langchain.com/en/latest/indexes/langchain.indexes.vectorstore.VectorstoreIndexCreator.html", "title": "Apify Dataset"}]--\x3e\nfrom langchain.docstore.document import Document\nfrom langchain.document_loaders import ApifyDatasetLoader\nfrom langchain.indexes import VectorstoreIndexCreator\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'loader = ApifyDatasetLoader(\n    dataset_id="your-dataset-id",\n    dataset_mapping_function=lambda item: Document(\n        page_content=item["text"] or "", metadata={"source": item["url"]}\n    ),\n)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"index = VectorstoreIndexCreator().from_loaders([loader])\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'query = "What is Apify?"\nresult = index.query_with_sources(query)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'print(result["answer"])\nprint(result["sources"])\n')),(0,o.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"     Apify is a platform for developing, running, and sharing serverless cloud programs. It enables users to create web scraping and automation tools and publish them on the Apify platform.\n    \n    https://docs.apify.com/platform/actors, https://docs.apify.com/platform/actors/running/actors-in-store, https://docs.apify.com/platform/security, https://docs.apify.com/platform/actors/examples\n"))))}f.isMDXComponent=!0}}]);