"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[88185],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>h});var r=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=r.createContext({}),c=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},u=function(e){var t=c(e.components);return r.createElement(l.Provider,{value:t},e.children)},d="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),d=c(n),m=o,h=d["".concat(l,".").concat(m)]||d[m]||p[m]||a;return n?r.createElement(h,s(s({ref:t},u),{},{components:n})):r.createElement(h,s({ref:t},u))}));function h(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,s=new Array(a);s[0]=m;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[d]="string"==typeof e?e:o,s[1]=i;for(var c=2;c<a;c++)s[c]=n[c];return r.createElement.apply(null,s)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},18673:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>c});var r=n(87462),o=(n(67294),n(3905));const a={},s="Parent Document Retriever",i={unversionedId:"modules/data_connection/retrievers/parent_document_retriever",id:"modules/data_connection/retrievers/parent_document_retriever",title:"Parent Document Retriever",description:"When splitting documents for retrieval, there are often conflicting desires:",source:"@site/docs/modules/data_connection/retrievers/parent_document_retriever.md",sourceDirName:"modules/data_connection/retrievers",slug:"/modules/data_connection/retrievers/parent_document_retriever",permalink:"/langchain/docs/modules/data_connection/retrievers/parent_document_retriever",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"MultiVector Retriever",permalink:"/langchain/docs/modules/data_connection/retrievers/multi_vector"},next:{title:"Self-querying",permalink:"/langchain/docs/modules/data_connection/retrievers/self_query/"}},l={},c=[{value:"Retrieving full documents",id:"retrieving-full-documents",level:2},{value:"Retrieving larger chunks",id:"retrieving-larger-chunks",level:2}],u=(d="CodeOutputBlock",function(e){return console.warn("Component "+d+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var d;const p={toc:c},m="wrapper";function h(e){let{components:t,...n}=e;return(0,o.kt)(m,(0,r.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"parent-document-retriever"},"Parent Document Retriever"),(0,o.kt)("p",null,"When splitting documents for retrieval, there are often conflicting desires:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"You may want to have small documents, so that their embeddings can most\naccurately reflect their meaning. If too long, then the embeddings can\nlose meaning."),(0,o.kt)("li",{parentName:"ol"},"You want to have long enough documents that the context of each chunk is\nretained.")),(0,o.kt)("p",null,"The ",(0,o.kt)("inlineCode",{parentName:"p"},"ParentDocumentRetriever")," strikes that balance by splitting and storing\nsmall chunks of data. During retrieval, it first fetches the small chunks\nbut then looks up the parent ids for those chunks and returns those larger\ndocuments."),(0,o.kt)("p",null,'Note that "parent document" refers to the document that a small chunk\noriginated from. This can either be the whole raw document OR a larger\nchunk.'),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "ParentDocumentRetriever", "source": "langchain.retrievers", "docs": "https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.parent_document_retriever.ParentDocumentRetriever.html", "title": "Parent Document Retriever"}]--\x3e\nfrom langchain.retrievers import ParentDocumentRetriever\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "Chroma", "source": "langchain.vectorstores", "docs": "https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.chroma.Chroma.html", "title": "Parent Document Retriever"}, {"imported": "OpenAIEmbeddings", "source": "langchain.embeddings", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html", "title": "Parent Document Retriever"}, {"imported": "RecursiveCharacterTextSplitter", "source": "langchain.text_splitter", "docs": "https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html", "title": "Parent Document Retriever"}, {"imported": "InMemoryStore", "source": "langchain.storage", "docs": "https://api.python.langchain.com/en/latest/storage/langchain.storage.in_memory.InMemoryStore.html", "title": "Parent Document Retriever"}, {"imported": "TextLoader", "source": "langchain.document_loaders", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.text.TextLoader.html", "title": "Parent Document Retriever"}]--\x3e\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.storage import InMemoryStore\nfrom langchain.document_loaders import TextLoader\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"loaders = [\n    TextLoader('../../paul_graham_essay.txt'),\n    TextLoader('../../state_of_the_union.txt'),\n]\ndocs = []\nfor l in loaders:\n    docs.extend(l.load())\n")),(0,o.kt)("h2",{id:"retrieving-full-documents"},"Retrieving full documents"),(0,o.kt)("p",null,"In this mode, we want to retrieve the full documents. Therefore, we only specify a child splitter."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# This text splitter is used to create the child documents\nchild_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n# The vectorstore to use to index the child chunks\nvectorstore = Chroma(\n    collection_name="full_documents",\n    embedding_function=OpenAIEmbeddings()\n)\n# The storage layer for the parent documents\nstore = InMemoryStore()\nretriever = ParentDocumentRetriever(\n    vectorstore=vectorstore, \n    docstore=store, \n    child_splitter=child_splitter,\n)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"retriever.add_documents(docs, ids=None)\n")),(0,o.kt)("p",null,"This should yield two keys, because we added two documents."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"list(store.yield_keys())\n")),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    ['05fe8d8a-bf60-4f87-b576-4351b23df266',\n     '571cc9e5-9ef7-4f6c-b800-835c83a1858b']\n"))),(0,o.kt)("p",null,"Let's now call the vector store search functionality - we should see that it returns small chunks (since we're storing the small chunks)."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'sub_docs = vectorstore.similarity_search("justice breyer")\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"print(sub_docs[0].page_content)\n")),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n    \n    One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.\n"))),(0,o.kt)("p",null,"Let's now retrieve from the overall retriever. This should return large documents - since it returns the documents where the smaller chunks are located."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'retrieved_docs = retriever.get_relevant_documents("justice breyer")\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"len(retrieved_docs[0].page_content)\n")),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    38539\n"))),(0,o.kt)("h2",{id:"retrieving-larger-chunks"},"Retrieving larger chunks"),(0,o.kt)("p",null,"Sometimes, the full documents can be too big to want to retrieve them as is. In that case, what we really want to do is to first split the raw documents into larger chunks, and then split it into smaller chunks. We then index the smaller chunks, but on retrieval we retrieve the larger chunks (but still not the full documents)."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# This text splitter is used to create the parent documents\nparent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n# This text splitter is used to create the child documents\n# It should create documents smaller than the parent\nchild_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n# The vectorstore to use to index the child chunks\nvectorstore = Chroma(collection_name="split_parents", embedding_function=OpenAIEmbeddings())\n# The storage layer for the parent documents\nstore = InMemoryStore()\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"retriever = ParentDocumentRetriever(\n    vectorstore=vectorstore, \n    docstore=store, \n    child_splitter=child_splitter,\n    parent_splitter=parent_splitter,\n)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"retriever.add_documents(docs)\n")),(0,o.kt)("p",null,"We can see that there are much more than two documents now - these are the larger chunks."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"len(list(store.yield_keys()))\n")),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    66\n"))),(0,o.kt)("p",null,"Let's make sure the underlying vector store still retrieves the small chunks."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'sub_docs = vectorstore.similarity_search("justice breyer")\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"print(sub_docs[0].page_content)\n")),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n    \n    One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'retrieved_docs = retriever.get_relevant_documents("justice breyer")\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"len(retrieved_docs[0].page_content)\n")),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    1849\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"print(retrieved_docs[0].page_content)\n")),(0,o.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    In state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections. \n    \n    We cannot let this happen. \n    \n    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n    \n    Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n    \n    One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n    \n    And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence. \n    \n    A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she\u2019s been nominated, she\u2019s received a broad range of support\u2014from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n    \n    And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n    \n    We can do both. At our border, we\u2019ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n    \n    We\u2019ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n    \n    We\u2019re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n    \n    We\u2019re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n"))))}h.isMDXComponent=!0}}]);