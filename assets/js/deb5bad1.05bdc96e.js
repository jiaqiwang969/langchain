"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[66242],{3905:(e,t,n)=>{n.d(t,{Zo:()=>s,kt:()=>h});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function p(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var i=a.createContext({}),m=function(e){var t=a.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},s=function(e){var t=m(e.components);return a.createElement(i.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,i=e.parentName,s=p(e,["components","mdxType","originalType","parentName"]),c=m(n),u=r,h=c["".concat(i,".").concat(u)]||c[u]||d[u]||o;return n?a.createElement(h,l(l({ref:t},s),{},{components:n})):a.createElement(h,l({ref:t},s))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,l=new Array(o);l[0]=u;var p={};for(var i in t)hasOwnProperty.call(t,i)&&(p[i]=t[i]);p.originalType=e,p[c]="string"==typeof e?e:r,l[1]=p;for(var m=2;m<o;m++)l[m]=n[m];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},8058:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>i,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>p,toc:()=>m});var a=n(87462),r=(n(67294),n(3905));const o={},l="Select by maximal marginal relevance (MMR)",p={unversionedId:"modules/model_io/prompts/example_selectors/mmr",id:"modules/model_io/prompts/example_selectors/mmr",title:"Select by maximal marginal relevance (MMR)",description:"The MaxMarginalRelevanceExampleSelector selects examples based on a combination of which examples are most similar to the inputs, while also optimizing for diversity. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples.",source:"@site/docs/modules/model_io/prompts/example_selectors/mmr.md",sourceDirName:"modules/model_io/prompts/example_selectors",slug:"/modules/model_io/prompts/example_selectors/mmr",permalink:"/langchain/docs/modules/model_io/prompts/example_selectors/mmr",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Select by length",permalink:"/langchain/docs/modules/model_io/prompts/example_selectors/length_based"},next:{title:"Select by n-gram overlap",permalink:"/langchain/docs/modules/model_io/prompts/example_selectors/ngram_overlap"}},i={},m=[],s=(c="CodeOutputBlock",function(e){return console.warn("Component "+c+" was not imported, exported, or provided by MDXProvider as global scope"),(0,r.kt)("div",e)});var c;const d={toc:m},u="wrapper";function h(e){let{components:t,...n}=e;return(0,r.kt)(u,(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"select-by-maximal-marginal-relevance-mmr"},"Select by maximal marginal relevance (MMR)"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"MaxMarginalRelevanceExampleSelector")," selects examples based on a combination of which examples are most similar to the inputs, while also optimizing for diversity. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "MaxMarginalRelevanceExampleSelector", "source": "langchain.prompts.example_selector", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain.prompts.example_selector.semantic_similarity.MaxMarginalRelevanceExampleSelector.html", "title": "Select by maximal marginal relevance (MMR)"}, {"imported": "SemanticSimilarityExampleSelector", "source": "langchain.prompts.example_selector", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain.prompts.example_selector.semantic_similarity.SemanticSimilarityExampleSelector.html", "title": "Select by maximal marginal relevance (MMR)"}, {"imported": "FAISS", "source": "langchain.vectorstores", "docs": "https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.faiss.FAISS.html", "title": "Select by maximal marginal relevance (MMR)"}, {"imported": "OpenAIEmbeddings", "source": "langchain.embeddings", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html", "title": "Select by maximal marginal relevance (MMR)"}, {"imported": "FewShotPromptTemplate", "source": "langchain.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain.prompts.few_shot.FewShotPromptTemplate.html", "title": "Select by maximal marginal relevance (MMR)"}, {"imported": "PromptTemplate", "source": "langchain.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html", "title": "Select by maximal marginal relevance (MMR)"}]--\x3e\nfrom langchain.prompts.example_selector import (\n    MaxMarginalRelevanceExampleSelector,\n    SemanticSimilarityExampleSelector,\n)\nfrom langchain.vectorstores import FAISS\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.prompts import FewShotPromptTemplate, PromptTemplate\n\nexample_prompt = PromptTemplate(\n    input_variables=["input", "output"],\n    template="Input: {input}\\nOutput: {output}",\n)\n\n# Examples of a pretend task of creating antonyms.\nexamples = [\n    {"input": "happy", "output": "sad"},\n    {"input": "tall", "output": "short"},\n    {"input": "energetic", "output": "lethargic"},\n    {"input": "sunny", "output": "gloomy"},\n    {"input": "windy", "output": "calm"},\n]\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n    # The list of examples available to select from.\n    examples,\n    # The embedding class used to produce embeddings which are used to measure semantic similarity.\n    OpenAIEmbeddings(),\n    # The VectorStore class that is used to store the embeddings and do a similarity search over.\n    FAISS,\n    # The number of examples to produce.\n    k=2,\n)\nmmr_prompt = FewShotPromptTemplate(\n    # We provide an ExampleSelector instead of examples.\n    example_selector=example_selector,\n    example_prompt=example_prompt,\n    prefix="Give the antonym of every input",\n    suffix="Input: {adjective}\\nOutput:",\n    input_variables=["adjective"],\n)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Input is a feeling, so should select the happy/sad example as the first one\nprint(mmr_prompt.format(adjective="worried"))\n')),(0,r.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    Give the antonym of every input\n    \n    Input: happy\n    Output: sad\n    \n    Input: windy\n    Output: calm\n    \n    Input: worried\n    Output:\n"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# Let\'s compare this to what we would just get if we went solely off of similarity,\n# by using SemanticSimilarityExampleSelector instead of MaxMarginalRelevanceExampleSelector.\nexample_selector = SemanticSimilarityExampleSelector.from_examples(\n    # The list of examples available to select from.\n    examples,\n    # The embedding class used to produce embeddings which are used to measure semantic similarity.\n    OpenAIEmbeddings(),\n    # The VectorStore class that is used to store the embeddings and do a similarity search over.\n    FAISS,\n    # The number of examples to produce.\n    k=2,\n)\nsimilar_prompt = FewShotPromptTemplate(\n    # We provide an ExampleSelector instead of examples.\n    example_selector=example_selector,\n    example_prompt=example_prompt,\n    prefix="Give the antonym of every input",\n    suffix="Input: {adjective}\\nOutput:",\n    input_variables=["adjective"],\n)\nprint(similar_prompt.format(adjective="worried"))\n')),(0,r.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    Give the antonym of every input\n    \n    Input: happy\n    Output: sad\n    \n    Input: sunny\n    Output: gloomy\n    \n    Input: worried\n    Output:\n"))))}h.isMDXComponent=!0}}]);