"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3085],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>g});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},p=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},u="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=c(n),d=o,g=u["".concat(l,".").concat(d)]||u[d]||h[d]||i;return n?a.createElement(g,r(r({ref:t},p),{},{components:n})):a.createElement(g,r({ref:t},p))}));function g(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,r=new Array(i);r[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:o,r[1]=s;for(var c=2;c<i;c++)r[c]=n[c];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},55777:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>u,default:()=>w,frontMatter:()=>p,metadata:()=>h,toc:()=>g});var a=n(87462),o=(n(67294),n(3905));const i=(r="CodeOutputBlock",function(e){return console.warn("Component "+r+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var r;const s={toc:[{value:"Initialize Tools",id:"initialize-tools",level:3},{value:"Adding in memory",id:"adding-in-memory",level:2}]},l="wrapper";function c(e){let{components:t,...n}=e;return(0,o.kt)(l,(0,a.Z)({},s,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"This functionality is natively available using agent types: ",(0,o.kt)("inlineCode",{parentName:"p"},"structured-chat-zero-shot-react-description")," or ",(0,o.kt)("inlineCode",{parentName:"p"},"AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'import os\nos.environ["LANGCHAIN_TRACING"] = "true" # If you want to trace the execution of the program, set to "true"\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.agents import AgentType\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.agents import initialize_agent\n")),(0,o.kt)("h3",{id:"initialize-tools"},"Initialize Tools"),(0,o.kt)("p",null,"We will test the agent using a web browser."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.agents.agent_toolkits import PlayWrightBrowserToolkit\nfrom langchain.tools.playwright.utils import (\n    create_async_playwright_browser,\n    create_sync_playwright_browser, # A synchronous browser is available, though it isn't compatible with jupyter.\n)\n\n# This import is required only for jupyter notebooks, since they have their own eventloop\nimport nest_asyncio\nnest_asyncio.apply()\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"async_browser = create_async_playwright_browser()\nbrowser_toolkit = PlayWrightBrowserToolkit.from_browser(async_browser=async_browser)\ntools = browser_toolkit.get_tools()\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"llm = ChatOpenAI(temperature=0) # Also works well with Anthropic models\nagent_chain = initialize_agent(tools, llm, agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'response = await agent_chain.arun(input="Hi I\'m Erica.")\nprint(response)\n')),(0,o.kt)(i,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'    \n    \n    > Entering new AgentExecutor chain...\n    Action:\n    ```\n    {\n      "action": "Final Answer",\n      "action_input": "Hello Erica, how can I assist you today?"\n    }\n    ```\n    \n    \n    > Finished chain.\n    Hello Erica, how can I assist you today?\n'))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'response = await agent_chain.arun(input="Don\'t need help really just chatting.")\nprint(response)\n')),(0,o.kt)(i,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new AgentExecutor chain...\n    \n    > Finished chain.\n    I'm here to chat! How's your day going?\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'response = await agent_chain.arun(input="Browse to blog.langchain.dev and summarize the text, please.")\nprint(response)\n')),(0,o.kt)(i,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'    \n    \n    > Entering new AgentExecutor chain...\n    Action:\n    ```\n    {\n      "action": "navigate_browser",\n      "action_input": {\n        "url": "https://blog.langchain.dev/"\n      }\n    }\n    ```\n    \n    \n    Observation: Navigating to https://blog.langchain.dev/ returned status code 200\n    Thought:I need to extract the text from the webpage to summarize it.\n    Action:\n    ```\n    {\n      "action": "extract_text",\n      "action_input": {}\n    }\n    ```\n    \n    Observation: LangChain LangChain Home About GitHub Docs LangChain The official LangChain blog. Auto-Evaluator Opportunities Editor\'s Note: this is a guest blog post by Lance Martin.\n    \n    \n    TL;DR\n    \n    We recently open-sourced an auto-evaluator tool for grading LLM question-answer chains. We are now releasing an open source, free to use hosted app and API to expand usability. Below we discuss a few opportunities to further improve May 1, 2023 5 min read Callbacks Improvements TL;DR: We\'re announcing improvements to our callbacks system, which powers logging, tracing, streaming output, and some awesome third-party integrations. This will better support concurrent runs with independent callbacks, tracing of deeply nested trees of LangChain components, and callback handlers scoped to a single request (which is super useful for May 1, 2023 3 min read Unleashing the power of AI Collaboration with Parallelized LLM Agent Actor Trees Editor\'s note: the following is a guest blog post from Cyrus at Shaman AI. We use guest blog posts to highlight interesting and novel applications, and this is certainly that. There\'s been a lot of talk about agents recently, but most have been discussions around a single agent. If multiple Apr 28, 2023 4 min read Gradio & LLM Agents Editor\'s note: this is a guest blog post from Freddy Boulton, a software engineer at Gradio. We\'re excited to share this post because it brings a large number of exciting new tools into the ecosystem. Agents are largely defined by the tools they have, so to be able to equip Apr 23, 2023 4 min read RecAlign - The smart content filter for social media feed [Editor\'s Note] This is a guest post by Tian Jin. We are highlighting this application as we think it is a novel use case. Specifically, we think recommendation systems are incredibly impactful in our everyday lives and there has not been a ton of discourse on how LLMs will impact Apr 22, 2023 3 min read Improving Document Retrieval with Contextual Compression Note: This post assumes some familiarity with LangChain and is moderately technical.\n    \n    \ud83d\udca1 TL;DR: We\u2019ve introduced a new abstraction and a new document Retriever to facilitate the post-processing of retrieved documents. Specifically, the new abstraction makes it easy to take a set of retrieved documents and extract from them Apr 20, 2023 3 min read Autonomous Agents & Agent Simulations Over the past two weeks, there has been a massive increase in using LLMs in an agentic manner. Specifically, projects like AutoGPT, BabyAGI, CAMEL, and Generative Agents have popped up. The LangChain community has now implemented some parts of all of those projects in the LangChain framework. While researching and Apr 18, 2023 7 min read AI-Powered Medical Knowledge: Revolutionizing Care for Rare Conditions [Editor\'s Note]: This is a guest post by Jack Simon, who recently participated in a hackathon at Williams College. He built a LangChain-powered chatbot focused on appendiceal cancer, aiming to make specialized knowledge more accessible to those in need. If you are interested in building a chatbot for another rare Apr 17, 2023 3 min read Auto-Eval of Question-Answering Tasks By Lance Martin\n    \n    Context\n    \n    LLM ops platforms, such as LangChain, make it easy to assemble LLM components (e.g., models, document retrievers, data loaders) into chains. Question-Answering is one of the most popular applications of these chains. But it is often not always obvious to determine what parameters (e.g. Apr 15, 2023 3 min read Announcing LangChainJS Support for Multiple JS Environments TLDR: We\'re announcing support for running LangChain.js in browsers, Cloudflare Workers, Vercel/Next.js, Deno, Supabase Edge Functions, alongside existing support for Node.js ESM and CJS. See install/upgrade docs and breaking changes list.\n    \n    \n    Context\n    \n    Originally we designed LangChain.js to run in Node.js, which is the Apr 11, 2023 3 min read LangChain x Supabase Supabase is holding an AI Hackathon this week. Here at LangChain we are big fans of both Supabase and hackathons, so we thought this would be a perfect time to highlight the multiple ways you can use LangChain and Supabase together.\n    \n    The reason we like Supabase so much is that Apr 8, 2023 2 min read Announcing our $10M seed round led by Benchmark It was only six months ago that we released the first version of LangChain, but it seems like several years. When we launched, generative AI was starting to go mainstream: stable diffusion had just been released and was captivating people\u2019s imagination and fueling an explosion in developer activity, Jasper Apr 4, 2023 4 min read Custom Agents One of the most common requests we\'ve heard is better functionality and documentation for creating custom agents. This has always been a bit tricky - because in our mind it\'s actually still very unclear what an "agent" actually is, and therefore what the "right" abstractions for them may be. Recently, Apr 3, 2023 3 min read Retrieval TL;DR: We are adjusting our abstractions to make it easy for other retrieval methods besides the LangChain VectorDB object to be used in LangChain. This is done with the goals of (1) allowing retrievers constructed elsewhere to be used more easily in LangChain, (2) encouraging more experimentation with alternative Mar 23, 2023 4 min read LangChain + Zapier Natural Language Actions (NLA) We are super excited to team up with Zapier and integrate their new Zapier NLA API into LangChain, which you can now use with your agents and chains. With this integration, you have access to the 5k+ apps and 20k+ actions on Zapier\'s platform through a natural language API interface. Mar 16, 2023 2 min read Evaluation Evaluation of language models, and by extension applications built on top of language models, is hard. With recent model releases (OpenAI, Anthropic, Google) evaluation is becoming a bigger and bigger issue. People are starting to try to tackle this, with OpenAI releasing OpenAI/evals - focused on evaluating OpenAI models. Mar 14, 2023 3 min read LLMs and SQL Francisco Ingham and Jon Luo are two of the community members leading the change on the SQL integrations. We\u2019re really excited to write this blog post with them going over all the tips and tricks they\u2019ve learned doing so. We\u2019re even more excited to announce that we\u2019 Mar 13, 2023 8 min read Origin Web Browser [Editor\'s Note]: This is the second of hopefully many guest posts. We intend to highlight novel applications building on top of LangChain. If you are interested in working with us on such a post, please reach out to harrison@langchain.dev.\n    \n    Authors: Parth Asawa (pgasawa@), Ayushi Batwara (ayushi.batwara@), Jason Mar 8, 2023 4 min read Prompt Selectors One common complaint we\'ve heard is that the default prompt templates do not work equally well for all models. This became especially pronounced this past week when OpenAI released a ChatGPT API. This new API had a completely new interface (which required new abstractions) and as a result many users Mar 8, 2023 2 min read Chat Models Last week OpenAI released a ChatGPT endpoint. It came marketed with several big improvements, most notably being 10x cheaper and a lot faster. But it also came with a completely new API endpoint. We were able to quickly write a wrapper for this endpoint to let users use it like Mar 6, 2023 6 min read Using the ChatGPT API to evaluate the ChatGPT API OpenAI released a new ChatGPT API yesterday. Lots of people were excited to try it. But how does it actually compare to the existing API? It will take some time before there is a definitive answer, but here are some initial thoughts. Because I\'m lazy, I also enrolled the help Mar 2, 2023 5 min read Agent Toolkits Today, we\'re announcing agent toolkits, a new abstraction that allows developers to create agents designed for a particular use-case (for example, interacting with a relational database or interacting with an OpenAPI spec). We hope to continue developing different toolkits that can enable agents to do amazing feats. Toolkits are supported Mar 1, 2023 3 min read TypeScript Support It\'s finally here... TypeScript support for LangChain.\n    \n    What does this mean? It means that all your favorite prompts, chains, and agents are all recreatable in TypeScript natively. Both the Python version and TypeScript version utilize the same serializable format, meaning that artifacts can seamlessly be shared between languages. As an Feb 17, 2023 2 min read Streaming Support in LangChain We\u2019re excited to announce streaming support in LangChain. There\'s been a lot of talk about the best UX for LLM applications, and we believe streaming is at its core. We\u2019ve also updated the chat-langchain repo to include streaming and async execution. We hope that this repo can serve Feb 14, 2023 2 min read LangChain + Chroma Today we\u2019re announcing LangChain\'s integration with Chroma, the first step on the path to the Modern A.I Stack.\n    \n    \n    LangChain - The A.I-native developer toolkit\n    \n    We started LangChain with the intent to build a modular and flexible framework for developing A.I-native applications. Some of the use cases Feb 13, 2023 2 min read Page 1 of 2 Older Posts \u2192 LangChain \xa9 2023 Sign up Powered by Ghost\n    Thought:\n    > Finished chain.\n    The LangChain blog has recently released an open-source auto-evaluator tool for grading LLM question-answer chains and is now releasing an open-source, free-to-use hosted app and API to expand usability. The blog also discusses various opportunities to further improve the LangChain platform.\n'))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'response = await agent_chain.arun(input="What\'s the latest xkcd comic about?")\nprint(response)\n')),(0,o.kt)(i,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'    \n    \n    > Entering new AgentExecutor chain...\n    Thought: I can navigate to the xkcd website and extract the latest comic title and alt text to answer the question.\n    Action:\n    ```\n    {\n      "action": "navigate_browser",\n      "action_input": {\n        "url": "https://xkcd.com/"\n      }\n    }\n    ```\n    \n    Observation: Navigating to https://xkcd.com/ returned status code 200\n    Thought:I can extract the latest comic title and alt text using CSS selectors.\n    Action:\n    ```\n    {\n      "action": "get_elements",\n      "action_input": {\n        "selector": "#ctitle, #comic img",\n        "attributes": ["alt", "src"]\n      }\n    }\n    ``` \n    \n    Observation: [{"alt": "Tapetum Lucidum", "src": "//imgs.xkcd.com/comics/tapetum_lucidum.png"}]\n    Thought:\n    > Finished chain.\n    The latest xkcd comic is titled "Tapetum Lucidum" and the image can be found at https://xkcd.com/2565/.\n'))),(0,o.kt)("h2",{id:"adding-in-memory"},"Adding in memory"),(0,o.kt)("p",null,"Here is how you add in memory to this agent:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.prompts import MessagesPlaceholder\nfrom langchain.memory import ConversationBufferMemory\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'chat_history = MessagesPlaceholder(variable_name="chat_history")\nmemory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'agent_chain = initialize_agent(\n    tools, \n    llm, \n    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION, \n    verbose=True, \n    memory=memory, \n    agent_kwargs = {\n        "memory_prompts": [chat_history],\n        "input_variables": ["input", "agent_scratchpad", "chat_history"]\n    }\n)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'response = await agent_chain.arun(input="Hi I\'m Erica.")\nprint(response)\n')),(0,o.kt)(i,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'    \n    \n    > Entering new AgentExecutor chain...\n    Action:\n    ```\n    {\n      "action": "Final Answer",\n      "action_input": "Hi Erica! How can I assist you today?"\n    }\n    ```\n    \n    \n    > Finished chain.\n    Hi Erica! How can I assist you today?\n'))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'response = await agent_chain.arun(input="whats my name?")\nprint(response)\n')),(0,o.kt)(i,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new AgentExecutor chain...\n    Your name is Erica.\n    \n    > Finished chain.\n    Your name is Erica.\n"))))}c.isMDXComponent=!0;const p={},u="Structured tool chat",h={unversionedId:"modules/agents/agent_types/structured_chat",id:"modules/agents/agent_types/structured_chat",title:"Structured tool chat",description:"The structured tool chat agent is capable of using multi-input tools.",source:"@site/docs/modules/agents/agent_types/structured_chat.mdx",sourceDirName:"modules/agents/agent_types",slug:"/modules/agents/agent_types/structured_chat",permalink:"/langchain/docs/modules/agents/agent_types/structured_chat",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Self-ask with search",permalink:"/langchain/docs/modules/agents/agent_types/self_ask_with_search"},next:{title:"XML Agent",permalink:"/langchain/docs/modules/agents/agent_types/xml_agent"}},d={},g=[],m={toc:g},y="wrapper";function w(e){let{components:t,...n}=e;return(0,o.kt)(y,(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"structured-tool-chat"},"Structured tool chat"),(0,o.kt)("p",null,"The structured tool chat agent is capable of using multi-input tools."),(0,o.kt)("p",null,"Older agents are configured to specify an action input as a single string, but this agent can use the provided tools' ",(0,o.kt)("inlineCode",{parentName:"p"},"args_schema")," to populate the action input."),(0,o.kt)(c,{mdxType:"Example"}))}w.isMDXComponent=!0}}]);