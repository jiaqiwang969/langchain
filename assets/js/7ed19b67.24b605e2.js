"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[38759],{3905:(e,n,t)=>{t.d(n,{Zo:()=>s,kt:()=>h});var o=t(67294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,o,r=function(e,n){if(null==e)return{};var t,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)t=a[o],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)t=a[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var p=o.createContext({}),d=function(e){var n=o.useContext(p),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},s=function(e){var n=d(e.components);return o.createElement(p.Provider,{value:n},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},c=o.forwardRef((function(e,n){var t=e.components,r=e.mdxType,a=e.originalType,p=e.parentName,s=i(e,["components","mdxType","originalType","parentName"]),m=d(t),c=r,h=m["".concat(p,".").concat(c)]||m[c]||u[c]||a;return t?o.createElement(h,l(l({ref:n},s),{},{components:t})):o.createElement(h,l({ref:n},s))}));function h(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var a=t.length,l=new Array(a);l[0]=c;var i={};for(var p in n)hasOwnProperty.call(n,p)&&(i[p]=n[p]);i.originalType=e,i[m]="string"==typeof e?e:r,l[1]=i;for(var d=2;d<a;d++)l[d]=t[d];return o.createElement.apply(null,l)}return o.createElement.apply(null,t)}c.displayName="MDXCreateElement"},40135:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>l,default:()=>u,frontMatter:()=>a,metadata:()=>i,toc:()=>d});var o=t(87462),r=(t(67294),t(3905));const a={},l="Modal",i={unversionedId:"integrations/providers/modal",id:"integrations/providers/modal",title:"Modal",description:"This page covers how to use the Modal ecosystem to run LangChain custom LLMs.",source:"@site/docs/integrations/providers/modal.mdx",sourceDirName:"integrations/providers",slug:"/integrations/providers/modal",permalink:"/langchain/docs/integrations/providers/modal",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"MLflow",permalink:"/langchain/docs/integrations/providers/mlflow_tracking"},next:{title:"ModelScope",permalink:"/langchain/docs/integrations/providers/modelscope"}},p={},d=[{value:"Installation and Setup",id:"installation-and-setup",level:2},{value:"Define your Modal Functions and Webhooks",id:"define-your-modal-functions-and-webhooks",level:2},{value:"Deploy the web endpoint",id:"deploy-the-web-endpoint",level:3},{value:"LLM wrapper around Modal web endpoint",id:"llm-wrapper-around-modal-web-endpoint",level:2}],s={toc:d},m="wrapper";function u(e){let{components:n,...t}=e;return(0,r.kt)(m,(0,o.Z)({},s,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"modal"},"Modal"),(0,r.kt)("p",null,"This page covers how to use the Modal ecosystem to run LangChain custom LLMs.\nIt is broken into two parts: "),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Modal installation and web endpoint deployment"),(0,r.kt)("li",{parentName:"ol"},"Using deployed web endpoint with ",(0,r.kt)("inlineCode",{parentName:"li"},"LLM")," wrapper class.")),(0,r.kt)("h2",{id:"installation-and-setup"},"Installation and Setup"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Install with ",(0,r.kt)("inlineCode",{parentName:"li"},"pip install modal")),(0,r.kt)("li",{parentName:"ul"},"Run ",(0,r.kt)("inlineCode",{parentName:"li"},"modal token new"))),(0,r.kt)("h2",{id:"define-your-modal-functions-and-webhooks"},"Define your Modal Functions and Webhooks"),(0,r.kt)("p",null,"You must include a prompt. There is a rigid response structure:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'class Item(BaseModel):\n    prompt: str\n\n@stub.function()\n@modal.web_endpoint(method="POST")\ndef get_text(item: Item):\n    return {"prompt": run_gpt2.call(item.prompt)}\n')),(0,r.kt)("p",null,"The following is an example with the GPT2 model:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from pydantic import BaseModel\n\nimport modal\n\nCACHE_PATH = "/root/model_cache"\n\nclass Item(BaseModel):\n    prompt: str\n\nstub = modal.Stub(name="example-get-started-with-langchain")\n\ndef download_model():\n    from transformers import GPT2Tokenizer, GPT2LMHeadModel\n    tokenizer = GPT2Tokenizer.from_pretrained(\'gpt2\')\n    model = GPT2LMHeadModel.from_pretrained(\'gpt2\')\n    tokenizer.save_pretrained(CACHE_PATH)\n    model.save_pretrained(CACHE_PATH)\n\n# Define a container image for the LLM function below, which\n# downloads and stores the GPT-2 model.\nimage = modal.Image.debian_slim().pip_install(\n    "tokenizers", "transformers", "torch", "accelerate"\n).run_function(download_model)\n\n@stub.function(\n    gpu="any",\n    image=image,\n    retries=3,\n)\ndef run_gpt2(text: str):\n    from transformers import GPT2Tokenizer, GPT2LMHeadModel\n    tokenizer = GPT2Tokenizer.from_pretrained(CACHE_PATH)\n    model = GPT2LMHeadModel.from_pretrained(CACHE_PATH)\n    encoded_input = tokenizer(text, return_tensors=\'pt\').input_ids\n    output = model.generate(encoded_input, max_length=50, do_sample=True)\n    return tokenizer.decode(output[0], skip_special_tokens=True)\n\n@stub.function()\n@modal.web_endpoint(method="POST")\ndef get_text(item: Item):\n    return {"prompt": run_gpt2.call(item.prompt)}\n')),(0,r.kt)("h3",{id:"deploy-the-web-endpoint"},"Deploy the web endpoint"),(0,r.kt)("p",null,"Deploy the web endpoint to Modal cloud with the ",(0,r.kt)("a",{parentName:"p",href:"https://modal.com/docs/reference/cli/deploy"},(0,r.kt)("inlineCode",{parentName:"a"},"modal deploy"))," CLI command.\nYour web endpoint will acquire a persistent URL under the ",(0,r.kt)("inlineCode",{parentName:"p"},"modal.run")," domain."),(0,r.kt)("h2",{id:"llm-wrapper-around-modal-web-endpoint"},"LLM wrapper around Modal web endpoint"),(0,r.kt)("p",null,"The  ",(0,r.kt)("inlineCode",{parentName:"p"},"Modal")," LLM wrapper class which will accept your deployed web endpoint's URL."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "Modal", "source": "langchain.llms", "docs": "https://api.python.langchain.com/en/latest/llms/langchain.llms.modal.Modal.html", "title": "Modal"}]--\x3e\nfrom langchain.llms import Modal\n\nendpoint_url = "https://ecorp--custom-llm-endpoint.modal.run"  # REPLACE ME with your deployed Modal web endpoint\'s URL\n\nllm = Modal(endpoint_url=endpoint_url)\nllm_chain = LLMChain(prompt=prompt, llm=llm)\n\nquestion = "What NFL team won the Super Bowl in the year Justin Beiber was born?"\n\nllm_chain.run(question)\n')))}u.isMDXComponent=!0}}]);