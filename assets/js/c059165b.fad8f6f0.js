"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[40878],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>k});var o=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function r(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},i=Object.keys(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(o=0;o<i.length;o++)n=i[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=o.createContext({}),c=function(e){var t=o.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},u=function(e){var t=c(e.components);return o.createElement(l.Provider,{value:t},e.children)},d="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},m=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,l=e.parentName,u=r(e,["components","mdxType","originalType","parentName"]),d=c(n),m=a,k=d["".concat(l,".").concat(m)]||d[m]||p[m]||i;return n?o.createElement(k,s(s({ref:t},u),{},{components:n})):o.createElement(k,s({ref:t},u))}));function k(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,s=new Array(i);s[0]=m;var r={};for(var l in t)hasOwnProperty.call(t,l)&&(r[l]=t[l]);r.originalType=e,r[d]="string"==typeof e?e:a,s[1]=r;for(var c=2;c<i;c++)s[c]=n[c];return o.createElement.apply(null,s)}return o.createElement.apply(null,n)}m.displayName="MDXCreateElement"},45503:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var o=n(87462),a=(n(67294),n(3905));const i={},s="Rockset",r={unversionedId:"integrations/document_loaders/rockset",id:"integrations/document_loaders/rockset",title:"Rockset",description:"Rockset is a real-time analytics database which enables queries on massive, semi-structured data without operational burden. With Rockset, ingested data is queryable within one second and analytical queries against that data typically execute in milliseconds. Rockset is compute optimized, making it suitable for serving high concurrency applications in the sub-100TB range (or larger than 100s of TBs with rollups).",source:"@site/docs/integrations/document_loaders/rockset.md",sourceDirName:"integrations/document_loaders",slug:"/integrations/document_loaders/rockset",permalink:"/langchain/docs/integrations/document_loaders/rockset",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"Roam",permalink:"/langchain/docs/integrations/document_loaders/roam"},next:{title:"RSS Feeds",permalink:"/langchain/docs/integrations/document_loaders/rss"}},l={},c=[{value:"Setting up the environment",id:"setting-up-the-environment",level:2},{value:"Using multiple columns as content",id:"using-multiple-columns-as-content",level:2}],u={toc:c},d="wrapper";function p(e){let{components:t,...n}=e;return(0,a.kt)(d,(0,o.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"rockset"},"Rockset"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Rockset is a real-time analytics database which enables queries on massive, semi-structured data without operational burden. With Rockset, ingested data is queryable within one second and analytical queries against that data typically execute in milliseconds. Rockset is compute optimized, making it suitable for serving high concurrency applications in the sub-100TB range (or larger than 100s of TBs with rollups).")),(0,a.kt)("p",null,"This notebook demonstrates how to use Rockset as a document loader in langchain. To get started, make sure you have a Rockset account and an API key available."),(0,a.kt)("h2",{id:"setting-up-the-environment"},"Setting up the environment"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Go to the ",(0,a.kt)("a",{parentName:"li",href:"https://console.rockset.com/apikeys"},"Rockset console")," and get an API key. Find your API region from the ",(0,a.kt)("a",{parentName:"li",href:"https://rockset.com/docs/rest-api/#introduction"},"API reference"),". For the purpose of this notebook, we will assume you're using Rockset from ",(0,a.kt)("inlineCode",{parentName:"li"},"Oregon(us-west-2)"),"."),(0,a.kt)("li",{parentName:"ol"},"Set your the environment variable ",(0,a.kt)("inlineCode",{parentName:"li"},"ROCKSET_API_KEY"),"."),(0,a.kt)("li",{parentName:"ol"},"Install the Rockset python client, which will be used by langchain to interact with the Rockset database.")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"$ pip3 install rockset\n")),(0,a.kt)("h1",{id:"loading-documents"},"Loading Documents"),(0,a.kt)("p",null,"The Rockset integration with LangChain allows you to load documents from Rockset collections with SQL queries. In order to do this you must construct a ",(0,a.kt)("inlineCode",{parentName:"p"},"RocksetLoader")," object. Here is an example snippet that initializes a ",(0,a.kt)("inlineCode",{parentName:"p"},"RocksetLoader"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "RocksetLoader", "source": "langchain.document_loaders", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.rocksetdb.RocksetLoader.html", "title": "Rockset"}]--\x3e\nfrom langchain.document_loaders import RocksetLoader\nfrom rockset import RocksetClient, Regions, models\n\nloader = RocksetLoader(\n    RocksetClient(Regions.usw2a1, "<api key>"),\n    models.QueryRequestSql(query="SELECT * FROM langchain_demo LIMIT 3"),  # SQL query\n    ["text"],  # content columns\n    metadata_keys=["id", "date"],  # metadata columns\n)\n')),(0,a.kt)("p",null,"Here, you can see that the following query is run:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM langchain_demo LIMIT 3\n")),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"text")," column in the collection is used as the page content, and the record's ",(0,a.kt)("inlineCode",{parentName:"p"},"id")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"date")," columns are used as metadata (if you do not pass anything into ",(0,a.kt)("inlineCode",{parentName:"p"},"metadata_keys"),", the whole Rockset document will be used as metadata). "),(0,a.kt)("p",null,"To execute the query and access an iterator over the resulting ",(0,a.kt)("inlineCode",{parentName:"p"},"Document"),"s, run:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"loader.lazy_load()\n")),(0,a.kt)("p",null,"To execute the query and access all resulting ",(0,a.kt)("inlineCode",{parentName:"p"},"Document"),"s at once, run:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"loader.load()\n")),(0,a.kt)("p",null,"Here is an example response of ",(0,a.kt)("inlineCode",{parentName:"p"},"loader.load()"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'[\n    Document(\n        page_content="Lorem ipsum dolor sit amet, consectetur adipiscing elit. Maecenas a libero porta, dictum ipsum eget, hendrerit neque. Morbi blandit, ex ut suscipit viverra, enim velit tincidunt tellus, a tempor velit nunc et ex. Proin hendrerit odio nec convallis lobortis. Aenean in purus dolor. Vestibulum orci orci, laoreet eget magna in, commodo euismod justo.", \n        metadata={"id": 83209, "date": "2022-11-13T18:26:45.000000Z"}\n    ),\n    Document(\n        page_content="Integer at finibus odio. Nam sit amet enim cursus lacus gravida feugiat vestibulum sed libero. Aenean eleifend est quis elementum tincidunt. Curabitur sit amet ornare erat. Nulla id dolor ut magna volutpat sodales fringilla vel ipsum. Donec ultricies, lacus sed fermentum dignissim, lorem elit aliquam ligula, sed suscipit sapien purus nec ligula.", \n        metadata={"id": 89313, "date": "2022-11-13T18:28:53.000000Z"}\n    ),\n    Document(\n        page_content="Morbi tortor enim, commodo id efficitur vitae, fringilla nec mi. Nullam molestie faucibus aliquet. Praesent a est facilisis, condimentum justo sit amet, viverra erat. Fusce volutpat nisi vel purus blandit, et facilisis felis accumsan. Phasellus luctus ligula ultrices tellus tempor hendrerit. Donec at ultricies leo.", \n        metadata={"id": 87732, "date": "2022-11-13T18:49:04.000000Z"}\n    )\n]\n')),(0,a.kt)("h2",{id:"using-multiple-columns-as-content"},"Using multiple columns as content"),(0,a.kt)("p",null,"You can choose to use multiple columns as content:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "RocksetLoader", "source": "langchain.document_loaders", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.rocksetdb.RocksetLoader.html", "title": "Rockset"}]--\x3e\nfrom langchain.document_loaders import RocksetLoader\nfrom rockset import RocksetClient, Regions, models\n\nloader = RocksetLoader(\n    RocksetClient(Regions.usw2a1, "<api key>"),\n    models.QueryRequestSql(query="SELECT * FROM langchain_demo LIMIT 1 WHERE id=38"),\n    ["sentence1", "sentence2"],  # TWO content columns\n)\n')),(0,a.kt)("p",null,'Assuming the "sentence1" field is ',(0,a.kt)("inlineCode",{parentName:"p"},'"This is the first sentence."'),' and the "sentence2" field is ',(0,a.kt)("inlineCode",{parentName:"p"},'"This is the second sentence."'),", the ",(0,a.kt)("inlineCode",{parentName:"p"},"page_content")," of the resulting ",(0,a.kt)("inlineCode",{parentName:"p"},"Document")," would be:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"This is the first sentence.\nThis is the second sentence.\n")),(0,a.kt)("p",null,"You can define you own function to join content columns by setting the ",(0,a.kt)("inlineCode",{parentName:"p"},"content_columns_joiner")," argument in the ",(0,a.kt)("inlineCode",{parentName:"p"},"RocksetLoader")," constructor. ",(0,a.kt)("inlineCode",{parentName:"p"},"content_columns_joiner")," is a method that takes in a ",(0,a.kt)("inlineCode",{parentName:"p"},"List[Tuple[str, Any]]]")," as an argument, representing a list of tuples of (column name, column value). By default, this is a method that joins each column value with a new line."),(0,a.kt)("p",null,"For example, if you wanted to join sentence1 and sentence2 with a space instead of a new line, you could set ",(0,a.kt)("inlineCode",{parentName:"p"},"content_columns_joiner")," like so:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'RocksetLoader(\n    RocksetClient(Regions.usw2a1, "<api key>"),\n    models.QueryRequestSql(query="SELECT * FROM langchain_demo LIMIT 1 WHERE id=38"),\n    ["sentence1", "sentence2"],\n    content_columns_joiner=lambda docs: " ".join(\n        [doc[1] for doc in docs]\n    ),  # join with space instead of /n\n)\n')),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"page_content")," of the resulting ",(0,a.kt)("inlineCode",{parentName:"p"},"Document")," would be:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"This is the first sentence. This is the second sentence.\n")),(0,a.kt)("p",null,"Oftentimes you want to include the column name in the ",(0,a.kt)("inlineCode",{parentName:"p"},"page_content"),". You can do that like this:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'RocksetLoader(\n    RocksetClient(Regions.usw2a1, "<api key>"),\n    models.QueryRequestSql(query="SELECT * FROM langchain_demo LIMIT 1 WHERE id=38"),\n    ["sentence1", "sentence2"],\n    content_columns_joiner=lambda docs: "\\n".join(\n        [f"{doc[0]}: {doc[1]}" for doc in docs]\n    ),\n)\n')),(0,a.kt)("p",null,"This would result in the following ",(0,a.kt)("inlineCode",{parentName:"p"},"page_content"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"sentence1: This is the first sentence.\nsentence2: This is the second sentence.\n")))}p.isMDXComponent=!0}}]);