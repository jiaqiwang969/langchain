"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[48419],{3905:(n,e,t)=>{t.d(e,{Zo:()=>h,kt:()=>g});var a=t(67294);function o(n,e,t){return e in n?Object.defineProperty(n,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):n[e]=t,n}function i(n,e){var t=Object.keys(n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(n);e&&(a=a.filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable}))),t.push.apply(t,a)}return t}function r(n){for(var e=1;e<arguments.length;e++){var t=null!=arguments[e]?arguments[e]:{};e%2?i(Object(t),!0).forEach((function(e){o(n,e,t[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(t,e))}))}return n}function s(n,e){if(null==n)return{};var t,a,o=function(n,e){if(null==n)return{};var t,a,o={},i=Object.keys(n);for(a=0;a<i.length;a++)t=i[a],e.indexOf(t)>=0||(o[t]=n[t]);return o}(n,e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(n);for(a=0;a<i.length;a++)t=i[a],e.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(n,t)&&(o[t]=n[t])}return o}var l=a.createContext({}),u=function(n){var e=a.useContext(l),t=e;return n&&(t="function"==typeof n?n(e):r(r({},e),n)),t},h=function(n){var e=u(n.components);return a.createElement(l.Provider,{value:e},n.children)},p="mdxType",c={inlineCode:"code",wrapper:function(n){var e=n.children;return a.createElement(a.Fragment,{},e)}},m=a.forwardRef((function(n,e){var t=n.components,o=n.mdxType,i=n.originalType,l=n.parentName,h=s(n,["components","mdxType","originalType","parentName"]),p=u(t),m=o,g=p["".concat(l,".").concat(m)]||p[m]||c[m]||i;return t?a.createElement(g,r(r({ref:e},h),{},{components:t})):a.createElement(g,r({ref:e},h))}));function g(n,e){var t=arguments,o=e&&e.mdxType;if("string"==typeof n||o){var i=t.length,r=new Array(i);r[0]=m;var s={};for(var l in e)hasOwnProperty.call(e,l)&&(s[l]=e[l]);s.originalType=n,s[p]="string"==typeof n?n:o,r[1]=s;for(var u=2;u<i;u++)r[u]=t[u];return a.createElement.apply(null,r)}return a.createElement.apply(null,t)}m.displayName="MDXCreateElement"},80985:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>g,frontMatter:()=>i,metadata:()=>s,toc:()=>u});var a=t(87462),o=(t(67294),t(3905));const i={},r="OpenAI Multi Functions Agent",s={unversionedId:"modules/agents/agent_types/openai_multi_functions_agent",id:"modules/agents/agent_types/openai_multi_functions_agent",title:"OpenAI Multi Functions Agent",description:"This notebook showcases using an agent that uses the OpenAI functions ability to respond to the prompts of the user using a Large Language Model.",source:"@site/docs/modules/agents/agent_types/openai_multi_functions_agent.md",sourceDirName:"modules/agents/agent_types",slug:"/modules/agents/agent_types/openai_multi_functions_agent",permalink:"/langchain/docs/modules/agents/agent_types/openai_multi_functions_agent",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"OpenAI functions",permalink:"/langchain/docs/modules/agents/agent_types/openai_functions_agent"},next:{title:"Plan-and-execute",permalink:"/langchain/docs/modules/agents/agent_types/plan_and_execute"}},l={},u=[{value:"Configuring max iteration behavior",id:"configuring-max-iteration-behavior",level:2}],h=(p="CodeOutputBlock",function(n){return console.warn("Component "+p+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",n)});var p;const c={toc:u},m="wrapper";function g(n){let{components:e,...t}=n;return(0,o.kt)(m,(0,a.Z)({},c,t,{components:e,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"openai-multi-functions-agent"},"OpenAI Multi Functions Agent"),(0,o.kt)("p",null,"This notebook showcases using an agent that uses the OpenAI functions ability to respond to the prompts of the user using a Large Language Model."),(0,o.kt)("p",null,"Install ",(0,o.kt)("inlineCode",{parentName:"p"},"openai"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"google-search-results")," packages which are required as the LangChain packages call them internally."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"pip install openai google-search-results\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "initialize_agent", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.initialize.initialize_agent.html", "title": "OpenAI Multi Functions Agent"}, {"imported": "Tool", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/tools/langchain.tools.base.Tool.html", "title": "OpenAI Multi Functions Agent"}, {"imported": "AgentType", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_types.AgentType.html", "title": "OpenAI Multi Functions Agent"}, {"imported": "ChatOpenAI", "source": "langchain.chat_models", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html", "title": "OpenAI Multi Functions Agent"}]--\x3e\nfrom langchain import SerpAPIWrapper\nfrom langchain.agents import initialize_agent, Tool\nfrom langchain.agents import AgentType\nfrom langchain.chat_models import ChatOpenAI\n')),(0,o.kt)("p",null,"The agent is given the ability to perform search functionalities with the respective tool"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"SerpAPIWrapper"),":"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"This initializes the ",(0,o.kt)("inlineCode",{parentName:"p"},"SerpAPIWrapper")," for search functionality (search).")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'import getpass\nimport os\n\nos.environ["SERPAPI_API_KEY"] = getpass.getpass()\n')),(0,o.kt)(h,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    \xb7\xb7\xb7\xb7\xb7\xb7\xb7\xb7\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# Initialize the OpenAI language model\n# Replace <your_api_key> in openai_api_key="<your_api_key>" with your actual OpenAI key.\nllm = ChatOpenAI(temperature=0, model="gpt-3.5-turbo-0613")\n\n# Initialize the SerpAPIWrapper for search functionality\n# Replace <your_api_key> in serpapi_api_key="<your_api_key>" with your actual SerpAPI key.\nsearch = SerpAPIWrapper()\n\n# Define a list of tools offered by the agent\ntools = [\n    Tool(\n        name="Search",\n        func=search.run,\n        description="Useful when you need to answer questions about current events. You should ask targeted questions.",\n    ),\n]\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"mrkl = initialize_agent(\n    tools, llm, agent=AgentType.OPENAI_MULTI_FUNCTIONS, verbose=True\n)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"# Do this so we can see exactly what's going on under the hood\nimport langchain\n\nlangchain.debug = True\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'mrkl.run("What is the weather in LA and SF?")\n')),(0,o.kt)(h,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'    [chain/start] [1:chain:AgentExecutor] Entering Chain run with input:\n    {\n      "input": "What is the weather in LA and SF?"\n    }\n    [llm/start] [1:chain:AgentExecutor > 2:llm:ChatOpenAI] Entering LLM run with input:\n    {\n      "prompts": [\n        "System: You are a helpful AI assistant.\\nHuman: What is the weather in LA and SF?"\n      ]\n    }\n    [llm/end] [1:chain:AgentExecutor > 2:llm:ChatOpenAI] [2.91s] Exiting LLM run with output:\n    {\n      "generations": [\n        [\n          {\n            "text": "",\n            "generation_info": null,\n            "message": {\n              "content": "",\n              "additional_kwargs": {\n                "function_call": {\n                  "name": "tool_selection",\n                  "arguments": "{\\n  \\"actions\\": [\\n    {\\n      \\"action_name\\": \\"Search\\",\\n      \\"action\\": {\\n        \\"tool_input\\": \\"weather in Los Angeles\\"\\n      }\\n    },\\n    {\\n      \\"action_name\\": \\"Search\\",\\n      \\"action\\": {\\n        \\"tool_input\\": \\"weather in San Francisco\\"\\n      }\\n    }\\n  ]\\n}"\n                }\n              },\n              "example": false\n            }\n          }\n        ]\n      ],\n      "llm_output": {\n        "token_usage": {\n          "prompt_tokens": 81,\n          "completion_tokens": 75,\n          "total_tokens": 156\n        },\n        "model_name": "gpt-3.5-turbo-0613"\n      },\n      "run": null\n    }\n    [tool/start] [1:chain:AgentExecutor > 3:tool:Search] Entering Tool run with input:\n    "{\'tool_input\': \'weather in Los Angeles\'}"\n    [tool/end] [1:chain:AgentExecutor > 3:tool:Search] [608.693ms] Exiting Tool run with output:\n    "Mostly cloudy early, then sunshine for the afternoon. High 76F. Winds SW at 5 to 10 mph. Humidity59%."\n    [tool/start] [1:chain:AgentExecutor > 4:tool:Search] Entering Tool run with input:\n    "{\'tool_input\': \'weather in San Francisco\'}"\n    [tool/end] [1:chain:AgentExecutor > 4:tool:Search] [517.475ms] Exiting Tool run with output:\n    "Partly cloudy this evening, then becoming cloudy after midnight. Low 53F. Winds WSW at 10 to 20 mph. Humidity83%."\n    [llm/start] [1:chain:AgentExecutor > 5:llm:ChatOpenAI] Entering LLM run with input:\n    {\n      "prompts": [\n        "System: You are a helpful AI assistant.\\nHuman: What is the weather in LA and SF?\\nAI: {\'name\': \'tool_selection\', \'arguments\': \'{\\\\n  \\"actions\\": [\\\\n    {\\\\n      \\"action_name\\": \\"Search\\",\\\\n      \\"action\\": {\\\\n        \\"tool_input\\": \\"weather in Los Angeles\\"\\\\n      }\\\\n    },\\\\n    {\\\\n      \\"action_name\\": \\"Search\\",\\\\n      \\"action\\": {\\\\n        \\"tool_input\\": \\"weather in San Francisco\\"\\\\n      }\\\\n    }\\\\n  ]\\\\n}\'}\\nFunction: Mostly cloudy early, then sunshine for the afternoon. High 76F. Winds SW at 5 to 10 mph. Humidity59%.\\nAI: {\'name\': \'tool_selection\', \'arguments\': \'{\\\\n  \\"actions\\": [\\\\n    {\\\\n      \\"action_name\\": \\"Search\\",\\\\n      \\"action\\": {\\\\n        \\"tool_input\\": \\"weather in Los Angeles\\"\\\\n      }\\\\n    },\\\\n    {\\\\n      \\"action_name\\": \\"Search\\",\\\\n      \\"action\\": {\\\\n        \\"tool_input\\": \\"weather in San Francisco\\"\\\\n      }\\\\n    }\\\\n  ]\\\\n}\'}\\nFunction: Partly cloudy this evening, then becoming cloudy after midnight. Low 53F. Winds WSW at 10 to 20 mph. Humidity83%."\n      ]\n    }\n    [llm/end] [1:chain:AgentExecutor > 5:llm:ChatOpenAI] [2.33s] Exiting LLM run with output:\n    {\n      "generations": [\n        [\n          {\n            "text": "The weather in Los Angeles is mostly cloudy with a high of 76\xb0F and a humidity of 59%. The weather in San Francisco is partly cloudy in the evening, becoming cloudy after midnight, with a low of 53\xb0F and a humidity of 83%.",\n            "generation_info": null,\n            "message": {\n              "content": "The weather in Los Angeles is mostly cloudy with a high of 76\xb0F and a humidity of 59%. The weather in San Francisco is partly cloudy in the evening, becoming cloudy after midnight, with a low of 53\xb0F and a humidity of 83%.",\n              "additional_kwargs": {},\n              "example": false\n            }\n          }\n        ]\n      ],\n      "llm_output": {\n        "token_usage": {\n          "prompt_tokens": 307,\n          "completion_tokens": 54,\n          "total_tokens": 361\n        },\n        "model_name": "gpt-3.5-turbo-0613"\n      },\n      "run": null\n    }\n    [chain/end] [1:chain:AgentExecutor] [6.37s] Exiting Chain run with output:\n    {\n      "output": "The weather in Los Angeles is mostly cloudy with a high of 76\xb0F and a humidity of 59%. The weather in San Francisco is partly cloudy in the evening, becoming cloudy after midnight, with a low of 53\xb0F and a humidity of 83%."\n    }\n\n\n\n\n\n    \'The weather in Los Angeles is mostly cloudy with a high of 76\xb0F and a humidity of 59%. The weather in San Francisco is partly cloudy in the evening, becoming cloudy after midnight, with a low of 53\xb0F and a humidity of 83%.\'\n'))),(0,o.kt)("h2",{id:"configuring-max-iteration-behavior"},"Configuring max iteration behavior"),(0,o.kt)("p",null,"To make sure that our agent doesn't get stuck in excessively long loops, we can set ",(0,o.kt)("inlineCode",{parentName:"p"},"max_iterations"),". We can also set an early stopping method, which will determine our agent's behavior once the number of max iterations is hit. By default, the early stopping uses method ",(0,o.kt)("inlineCode",{parentName:"p"},"force")," which just returns that constant string. Alternatively, you could specify method ",(0,o.kt)("inlineCode",{parentName:"p"},"generate")," which then does one FINAL pass through the LLM to generate an output."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'mrkl = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.OPENAI_FUNCTIONS,\n    verbose=True,\n    max_iterations=2,\n    early_stopping_method="generate",\n)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'mrkl.run("What is the weather in NYC today, yesterday, and the day before?")\n')),(0,o.kt)(h,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'    [chain/start] [1:chain:AgentExecutor] Entering Chain run with input:\n    {\n      "input": "What is the weather in NYC today, yesterday, and the day before?"\n    }\n    [llm/start] [1:chain:AgentExecutor > 2:llm:ChatOpenAI] Entering LLM run with input:\n    {\n      "prompts": [\n        "System: You are a helpful AI assistant.\\nHuman: What is the weather in NYC today, yesterday, and the day before?"\n      ]\n    }\n    [llm/end] [1:chain:AgentExecutor > 2:llm:ChatOpenAI] [1.27s] Exiting LLM run with output:\n    {\n      "generations": [\n        [\n          {\n            "text": "",\n            "generation_info": null,\n            "message": {\n              "lc": 1,\n              "type": "constructor",\n              "id": [\n                "langchain",\n                "schema",\n                "messages",\n                "AIMessage"\n              ],\n              "kwargs": {\n                "content": "",\n                "additional_kwargs": {\n                  "function_call": {\n                    "name": "Search",\n                    "arguments": "{\\n  \\"query\\": \\"weather in NYC today\\"\\n}"\n                  }\n                }\n              }\n            }\n          }\n        ]\n      ],\n      "llm_output": {\n        "token_usage": {\n          "prompt_tokens": 79,\n          "completion_tokens": 17,\n          "total_tokens": 96\n        },\n        "model_name": "gpt-3.5-turbo-0613"\n      },\n      "run": null\n    }\n    [tool/start] [1:chain:AgentExecutor > 3:tool:Search] Entering Tool run with input:\n    "{\'query\': \'weather in NYC today\'}"\n    [tool/end] [1:chain:AgentExecutor > 3:tool:Search] [3.84s] Exiting Tool run with output:\n    "10:00 am \xb7 Feels Like85\xb0 \xb7 WindSE 4 mph \xb7 Humidity78% \xb7 UV Index3 of 11 \xb7 Cloud Cover81% \xb7 Rain Amount0 in ..."\n    [llm/start] [1:chain:AgentExecutor > 4:llm:ChatOpenAI] Entering LLM run with input:\n    {\n      "prompts": [\n        "System: You are a helpful AI assistant.\\nHuman: What is the weather in NYC today, yesterday, and the day before?\\nAI: {\'name\': \'Search\', \'arguments\': \'{\\\\n  \\"query\\": \\"weather in NYC today\\"\\\\n}\'}\\nFunction: 10:00 am \xb7 Feels Like85\xb0 \xb7 WindSE 4 mph \xb7 Humidity78% \xb7 UV Index3 of 11 \xb7 Cloud Cover81% \xb7 Rain Amount0 in ..."\n      ]\n    }\n    [llm/end] [1:chain:AgentExecutor > 4:llm:ChatOpenAI] [1.24s] Exiting LLM run with output:\n    {\n      "generations": [\n        [\n          {\n            "text": "",\n            "generation_info": null,\n            "message": {\n              "lc": 1,\n              "type": "constructor",\n              "id": [\n                "langchain",\n                "schema",\n                "messages",\n                "AIMessage"\n              ],\n              "kwargs": {\n                "content": "",\n                "additional_kwargs": {\n                  "function_call": {\n                    "name": "Search",\n                    "arguments": "{\\n  \\"query\\": \\"weather in NYC yesterday\\"\\n}"\n                  }\n                }\n              }\n            }\n          }\n        ]\n      ],\n      "llm_output": {\n        "token_usage": {\n          "prompt_tokens": 142,\n          "completion_tokens": 17,\n          "total_tokens": 159\n        },\n        "model_name": "gpt-3.5-turbo-0613"\n      },\n      "run": null\n    }\n    [tool/start] [1:chain:AgentExecutor > 5:tool:Search] Entering Tool run with input:\n    "{\'query\': \'weather in NYC yesterday\'}"\n    [tool/end] [1:chain:AgentExecutor > 5:tool:Search] [1.15s] Exiting Tool run with output:\n    "New York Temperature Yesterday. Maximum temperature yesterday: 81 \xb0F (at 1:51 pm) Minimum temperature yesterday: 72 \xb0F (at 7:17 pm) Average temperature ..."\n    [llm/start] [1:llm:ChatOpenAI] Entering LLM run with input:\n    {\n      "prompts": [\n        "System: You are a helpful AI assistant.\\nHuman: What is the weather in NYC today, yesterday, and the day before?\\nAI: {\'name\': \'Search\', \'arguments\': \'{\\\\n  \\"query\\": \\"weather in NYC today\\"\\\\n}\'}\\nFunction: 10:00 am \xb7 Feels Like85\xb0 \xb7 WindSE 4 mph \xb7 Humidity78% \xb7 UV Index3 of 11 \xb7 Cloud Cover81% \xb7 Rain Amount0 in ...\\nAI: {\'name\': \'Search\', \'arguments\': \'{\\\\n  \\"query\\": \\"weather in NYC yesterday\\"\\\\n}\'}\\nFunction: New York Temperature Yesterday. Maximum temperature yesterday: 81 \xb0F (at 1:51 pm) Minimum temperature yesterday: 72 \xb0F (at 7:17 pm) Average temperature ..."\n      ]\n    }\n    [llm/end] [1:llm:ChatOpenAI] [2.68s] Exiting LLM run with output:\n    {\n      "generations": [\n        [\n          {\n            "text": "Today in NYC, the weather is currently 85\xb0F with a southeast wind of 4 mph. The humidity is at 78% and there is 81% cloud cover. There is no rain expected today.\\n\\nYesterday in NYC, the maximum temperature was 81\xb0F at 1:51 pm, and the minimum temperature was 72\xb0F at 7:17 pm.\\n\\nFor the day before yesterday, I do not have the specific weather information.",\n            "generation_info": null,\n            "message": {\n              "lc": 1,\n              "type": "constructor",\n              "id": [\n                "langchain",\n                "schema",\n                "messages",\n                "AIMessage"\n              ],\n              "kwargs": {\n                "content": "Today in NYC, the weather is currently 85\xb0F with a southeast wind of 4 mph. The humidity is at 78% and there is 81% cloud cover. There is no rain expected today.\\n\\nYesterday in NYC, the maximum temperature was 81\xb0F at 1:51 pm, and the minimum temperature was 72\xb0F at 7:17 pm.\\n\\nFor the day before yesterday, I do not have the specific weather information.",\n                "additional_kwargs": {}\n              }\n            }\n          }\n        ]\n      ],\n      "llm_output": {\n        "token_usage": {\n          "prompt_tokens": 160,\n          "completion_tokens": 91,\n          "total_tokens": 251\n        },\n        "model_name": "gpt-3.5-turbo-0613"\n      },\n      "run": null\n    }\n    [chain/end] [1:chain:AgentExecutor] [10.18s] Exiting Chain run with output:\n    {\n      "output": "Today in NYC, the weather is currently 85\xb0F with a southeast wind of 4 mph. The humidity is at 78% and there is 81% cloud cover. There is no rain expected today.\\n\\nYesterday in NYC, the maximum temperature was 81\xb0F at 1:51 pm, and the minimum temperature was 72\xb0F at 7:17 pm.\\n\\nFor the day before yesterday, I do not have the specific weather information."\n    }\n\n\n\n\n\n    \'Today in NYC, the weather is currently 85\xb0F with a southeast wind of 4 mph. The humidity is at 78% and there is 81% cloud cover. There is no rain expected today.\\n\\nYesterday in NYC, the maximum temperature was 81\xb0F at 1:51 pm, and the minimum temperature was 72\xb0F at 7:17 pm.\\n\\nFor the day before yesterday, I do not have the specific weather information.\'\n'))),(0,o.kt)("p",null,"Notice that we never get around to looking up the weather the day before yesterday, due to hitting our ",(0,o.kt)("inlineCode",{parentName:"p"},"max_iterations")," limit."))}g.isMDXComponent=!0}}]);