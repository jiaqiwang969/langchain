"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[47625],{3905:(e,a,n)=>{n.d(a,{Zo:()=>p,kt:()=>k});var t=n(67294);function r(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function l(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),n.push.apply(n,t)}return n}function o(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?l(Object(n),!0).forEach((function(a){r(e,a,n[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))}))}return e}function i(e,a){if(null==e)return{};var n,t,r=function(e,a){if(null==e)return{};var n,t,r={},l=Object.keys(e);for(t=0;t<l.length;t++)n=l[t],a.indexOf(n)>=0||(r[n]=e[n]);return r}(e,a);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(t=0;t<l.length;t++)n=l[t],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=t.createContext({}),c=function(e){var a=t.useContext(s),n=a;return e&&(n="function"==typeof e?e(a):o(o({},a),e)),n},p=function(e){var a=c(e.components);return t.createElement(s.Provider,{value:a},e.children)},m="mdxType",g={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},h=t.forwardRef((function(e,a){var n=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),m=c(n),h=r,k=m["".concat(s,".").concat(h)]||m[h]||g[h]||l;return n?t.createElement(k,o(o({ref:a},p),{},{components:n})):t.createElement(k,o({ref:a},p))}));function k(e,a){var n=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var l=n.length,o=new Array(l);o[0]=h;var i={};for(var s in a)hasOwnProperty.call(a,s)&&(i[s]=a[s]);i.originalType=e,i[m]="string"==typeof e?e:r,o[1]=i;for(var c=2;c<l;c++)o[c]=n[c];return t.createElement.apply(null,o)}return t.createElement.apply(null,n)}h.displayName="MDXCreateElement"},1859:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>s,contentTitle:()=>o,default:()=>g,frontMatter:()=>l,metadata:()=>i,toc:()=>c});var t=n(87462),r=(n(67294),n(3905));const l={},o="SageMaker Tracking",i={unversionedId:"integrations/providers/sagemaker_tracking",id:"integrations/providers/sagemaker_tracking",title:"SageMaker Tracking",description:"This notebook shows how LangChain Callback can be used to log and track prompts and other LLM hyperparameters into SageMaker Experiments. Here, we use different scenarios to showcase the capability:",source:"@site/docs/integrations/providers/sagemaker_tracking.md",sourceDirName:"integrations/providers",slug:"/integrations/providers/sagemaker_tracking",permalink:"/langchain/docs/integrations/providers/sagemaker_tracking",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"SageMaker Endpoint",permalink:"/langchain/docs/integrations/providers/sagemaker_endpoint"},next:{title:"ScaNN",permalink:"/langchain/docs/integrations/providers/scann"}},s={},c=[{value:"Installation and Setup",id:"installation-and-setup",level:2},{value:"LLM Prompt Tracking",id:"llm-prompt-tracking",level:2},{value:"Scenario 1 - LLM",id:"scenario-1---llm",level:3},{value:"Scenario 2 - Sequential Chain",id:"scenario-2---sequential-chain",level:3},{value:"Scenario 3 - Agent with Tools",id:"scenario-3---agent-with-tools",level:3},{value:"Load Log Data",id:"load-log-data",level:2}],p={toc:c},m="wrapper";function g(e){let{components:a,...n}=e;return(0,r.kt)(m,(0,t.Z)({},p,n,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"sagemaker-tracking"},"SageMaker Tracking"),(0,r.kt)("p",null,"This notebook shows how LangChain Callback can be used to log and track prompts and other LLM hyperparameters into SageMaker Experiments. Here, we use different scenarios to showcase the capability:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Scenario 1"),": ",(0,r.kt)("em",{parentName:"li"},"Single LLM")," - A case where a single LLM model is used to generate output based on a given prompt."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Scenario 2"),": ",(0,r.kt)("em",{parentName:"li"},"Sequential Chain")," - A case where a sequential chain of two LLM models is used."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Scenario 3"),": ",(0,r.kt)("em",{parentName:"li"},"Agent with Tools (Chain of Thought)")," - A case where multiple tools (search and math) are used in addition to an LLM.")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://aws.amazon.com/sagemaker/"},"Amazon SageMaker")," is a fully managed service that is used to quickly and easily build, train and deploy machine learning (ML) models. "),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html"},"Amazon SageMaker Experiments")," is a capability of Amazon SageMaker that lets you organize, track, compare and evaluate ML experiments and model versions."),(0,r.kt)("p",null,"In this notebook, we will create a single experiment to log the prompts from each scenario."),(0,r.kt)("h2",{id:"installation-and-setup"},"Installation and Setup"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pip install sagemaker\npip install openai\npip install google-search-results\n")),(0,r.kt)("p",null,"First, setup the required API keys"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"OpenAI: ",(0,r.kt)("a",{parentName:"li",href:"https://platform.openai.com/account/api-keys"},"https://platform.openai.com/account/api-keys")," (For OpenAI LLM model)"),(0,r.kt)("li",{parentName:"ul"},"Google SERP API: ",(0,r.kt)("a",{parentName:"li",href:"https://serpapi.com/manage-api-key"},"https://serpapi.com/manage-api-key")," (For Google Search Tool)")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import os\n\n## Add your API keys below\nos.environ["OPENAI_API_KEY"] = "<ADD-KEY-HERE>"\nos.environ["SERPAPI_API_KEY"] = "<ADD-KEY-HERE>"\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "OpenAI", "source": "langchain.llms", "docs": "https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html", "title": "SageMaker Tracking"}, {"imported": "PromptTemplate", "source": "langchain.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html", "title": "SageMaker Tracking"}, {"imported": "LLMChain", "source": "langchain.chains", "docs": "https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html", "title": "SageMaker Tracking"}, {"imported": "SimpleSequentialChain", "source": "langchain.chains", "docs": "https://api.python.langchain.com/en/latest/chains/langchain.chains.sequential.SimpleSequentialChain.html", "title": "SageMaker Tracking"}, {"imported": "initialize_agent", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.initialize.initialize_agent.html", "title": "SageMaker Tracking"}, {"imported": "load_tools", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.load_tools.load_tools.html", "title": "SageMaker Tracking"}, {"imported": "Tool", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/tools/langchain.tools.base.Tool.html", "title": "SageMaker Tracking"}, {"imported": "SageMakerCallbackHandler", "source": "langchain.callbacks", "docs": "https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.sagemaker_callback.SageMakerCallbackHandler.html", "title": "SageMaker Tracking"}]--\x3e\nfrom langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain, SimpleSequentialChain\nfrom langchain.agents import initialize_agent, load_tools\nfrom langchain.agents import Tool\nfrom langchain.callbacks import SageMakerCallbackHandler\n\nfrom sagemaker.analytics import ExperimentAnalytics\nfrom sagemaker.session import Session\nfrom sagemaker.experiments.run import Run\n')),(0,r.kt)("h2",{id:"llm-prompt-tracking"},"LLM Prompt Tracking"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'#LLM Hyperparameters\nHPARAMS = {\n    "temperature": 0.1,\n    "model_name": "text-davinci-003",\n}\n\n#Bucket used to save prompt logs (Use `None` is used to save the default bucket or otherwise change it)\nBUCKET_NAME = None\n\n#Experiment name\nEXPERIMENT_NAME = "langchain-sagemaker-tracker"\n\n#Create SageMaker Session with the given bucket\nsession = Session(default_bucket=BUCKET_NAME)\n')),(0,r.kt)("h3",{id:"scenario-1---llm"},"Scenario 1 - LLM"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'RUN_NAME = "run-scenario-1"\nPROMPT_TEMPLATE = "tell me a joke about {topic}"\nINPUT_VARIABLES = {"topic": "fish"}\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"with Run(experiment_name=EXPERIMENT_NAME, run_name=RUN_NAME, sagemaker_session=session) as run:\n\n    # Create SageMaker Callback\n    sagemaker_callback = SageMakerCallbackHandler(run)\n\n    # Define LLM model with callback\n    llm = OpenAI(callbacks=[sagemaker_callback], **HPARAMS)\n\n    # Create prompt template\n    prompt = PromptTemplate.from_template(template=PROMPT_TEMPLATE)\n\n    # Create LLM Chain\n    chain = LLMChain(llm=llm, prompt=prompt, callbacks=[sagemaker_callback])\n\n    # Run chain\n    chain.run(**INPUT_VARIABLES)\n\n    # Reset the callback\n    sagemaker_callback.flush_tracker()\n")),(0,r.kt)("h3",{id:"scenario-2---sequential-chain"},"Scenario 2 - Sequential Chain"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'RUN_NAME = "run-scenario-2"\n\nPROMPT_TEMPLATE_1 = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.\nTitle: {title}\nPlaywright: This is a synopsis for the above play:"""\nPROMPT_TEMPLATE_2 = """You are a play critic from the New York Times. Given the synopsis of play, it is your job to write a review for that play.\nPlay Synopsis: {synopsis}\nReview from a New York Times play critic of the above play:"""\n\nINPUT_VARIABLES = {\n    "input": "documentary about good video games that push the boundary of game design"\n}\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"with Run(experiment_name=EXPERIMENT_NAME, run_name=RUN_NAME, sagemaker_session=session) as run:\n\n    # Create SageMaker Callback\n    sagemaker_callback = SageMakerCallbackHandler(run)\n\n    # Create prompt templates for the chain\n    prompt_template1 = PromptTemplate.from_template(template=PROMPT_TEMPLATE_1)\n    prompt_template2 = PromptTemplate.from_template(template=PROMPT_TEMPLATE_2)\n\n    # Define LLM model with callback\n    llm = OpenAI(callbacks=[sagemaker_callback], **HPARAMS)\n\n    # Create chain1\n    chain1 = LLMChain(llm=llm, prompt=prompt_template1, callbacks=[sagemaker_callback])\n\n    # Create chain2\n    chain2 = LLMChain(llm=llm, prompt=prompt_template2, callbacks=[sagemaker_callback])\n\n    # Create Sequential chain\n    overall_chain = SimpleSequentialChain(chains=[chain1, chain2], callbacks=[sagemaker_callback])\n\n    # Run overall sequential chain\n    overall_chain.run(**INPUT_VARIABLES)\n\n    # Reset the callback\n    sagemaker_callback.flush_tracker()\n")),(0,r.kt)("h3",{id:"scenario-3---agent-with-tools"},"Scenario 3 - Agent with Tools"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'RUN_NAME = "run-scenario-3"\nPROMPT_TEMPLATE = "Who is the oldest person alive? And what is their current age raised to the power of 1.51?"\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'with Run(experiment_name=EXPERIMENT_NAME, run_name=RUN_NAME, sagemaker_session=session) as run:\n\n    # Create SageMaker Callback\n    sagemaker_callback = SageMakerCallbackHandler(run)\n\n    # Define LLM model with callback\n    llm = OpenAI(callbacks=[sagemaker_callback], **HPARAMS)\n\n    # Define tools\n    tools = load_tools(["serpapi", "llm-math"], llm=llm, callbacks=[sagemaker_callback])\n\n    # Initialize agent with all the tools\n    agent = initialize_agent(tools, llm, agent="zero-shot-react-description", callbacks=[sagemaker_callback])\n\n    # Run agent\n    agent.run(input=PROMPT_TEMPLATE)\n\n    # Reset the callback\n    sagemaker_callback.flush_tracker()\n')),(0,r.kt)("h2",{id:"load-log-data"},"Load Log Data"),(0,r.kt)("p",null,"Once the prompts are logged, we can easily load and convert them to Pandas DataFrame as follows."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"#Load\nlogs = ExperimentAnalytics(experiment_name=EXPERIMENT_NAME)\n\n#Convert as pandas dataframe\ndf = logs.dataframe(force_refresh=True)\n\nprint(df.shape)\ndf.head()\n")),(0,r.kt)("p",null,"As can be seen above, there are three runs (rows) in the experiment corresponding to each scenario. Each run logs the prompts and related LLM settings/hyperparameters as json and are saved in s3 bucket. Feel free to load and explore the log data from each json path."))}g.isMDXComponent=!0}}]);