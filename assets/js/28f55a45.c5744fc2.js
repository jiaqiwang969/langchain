"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8872],{3905:(e,n,a)=>{a.d(n,{Zo:()=>s,kt:()=>d});var t=a(67294);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function o(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function p(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?o(Object(a),!0).forEach((function(n){r(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function l(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},o=Object.keys(e);for(t=0;t<o.length;t++)a=o[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)a=o[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var i=t.createContext({}),h=function(e){var n=t.useContext(i),a=n;return e&&(a="function"==typeof e?e(n):p(p({},n),e)),a},s=function(e){var n=h(e.components);return t.createElement(i.Provider,{value:n},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},c=t.forwardRef((function(e,n){var a=e.components,r=e.mdxType,o=e.originalType,i=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),u=h(a),c=r,d=u["".concat(i,".").concat(c)]||u[c]||m[c]||o;return a?t.createElement(d,p(p({ref:n},s),{},{components:a})):t.createElement(d,p({ref:n},s))}));function d(e,n){var a=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=a.length,p=new Array(o);p[0]=c;var l={};for(var i in n)hasOwnProperty.call(n,i)&&(l[i]=n[i]);l.originalType=e,l[u]="string"==typeof e?e:r,p[1]=l;for(var h=2;h<o;h++)p[h]=a[h];return t.createElement.apply(null,p)}return t.createElement.apply(null,a)}c.displayName="MDXCreateElement"},93146:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>i,contentTitle:()=>p,default:()=>d,frontMatter:()=>o,metadata:()=>l,toc:()=>h});var t=a(87462),r=(a(67294),a(3905));const o={},p="Neo4j DB QA chain",l={unversionedId:"use_cases/more/graph/graph_cypher_qa",id:"use_cases/more/graph/graph_cypher_qa",title:"Neo4j DB QA chain",description:"This notebook shows how to use LLMs to provide a natural language interface to a graph database you can query with the Cypher query language.",source:"@site/docs/use_cases/more/graph/graph_cypher_qa.md",sourceDirName:"use_cases/more/graph",slug:"/use_cases/more/graph/graph_cypher_qa",permalink:"/langchain/docs/use_cases/more/graph/graph_cypher_qa",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"use_cases",previous:{title:"ArangoDB QA chain",permalink:"/langchain/docs/use_cases/more/graph/graph_arangodb_qa"},next:{title:"FalkorDBQAChain",permalink:"/langchain/docs/use_cases/more/graph/graph_falkordb_qa"}},i={},h=[{value:"Seeding the database",id:"seeding-the-database",level:2},{value:"Refresh graph schema information",id:"refresh-graph-schema-information",level:2},{value:"Querying the graph",id:"querying-the-graph",level:2},{value:"Limit the number of results",id:"limit-the-number-of-results",level:2},{value:"Return intermediate results",id:"return-intermediate-results",level:2},{value:"Return direct results",id:"return-direct-results",level:2},{value:"Add examples in the Cypher generation prompt",id:"add-examples-in-the-cypher-generation-prompt",level:2},{value:"Use separate LLMs for Cypher and answer generation",id:"use-separate-llms-for-cypher-and-answer-generation",level:2}],s=(u="CodeOutputBlock",function(e){return console.warn("Component "+u+" was not imported, exported, or provided by MDXProvider as global scope"),(0,r.kt)("div",e)});var u;const m={toc:h},c="wrapper";function d(e){let{components:n,...a}=e;return(0,r.kt)(c,(0,t.Z)({},m,a,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"neo4j-db-qa-chain"},"Neo4j DB QA chain"),(0,r.kt)("p",null,"This notebook shows how to use LLMs to provide a natural language interface to a graph database you can query with the Cypher query language."),(0,r.kt)("p",null,"You will need to have a running Neo4j instance. One option is to create a ",(0,r.kt)("a",{parentName:"p",href:"https://neo4j.com/cloud/platform/aura-graph-database/"},"free Neo4j database instance in their Aura cloud service"),". You can also run the database locally using the ",(0,r.kt)("a",{parentName:"p",href:"https://neo4j.com/download/"},"Neo4j Desktop application"),", or running a docker container.\nYou can run a local docker container by running the executing the following script:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'docker run \\\n    --name neo4j \\\n    -p 7474:7474 -p 7687:7687 \\\n    -d \\\n    -e NEO4J_AUTH=neo4j/pleaseletmein \\\n    -e NEO4J_PLUGINS=\\[\\"apoc\\"\\]  \\\n    neo4j:latest\n')),(0,r.kt)("p",null,"If you are using the docker container, you need to wait a couple of second for the database to start."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "ChatOpenAI", "source": "langchain.chat_models", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html", "title": "Neo4j DB QA chain"}, {"imported": "GraphCypherQAChain", "source": "langchain.chains", "docs": "https://api.python.langchain.com/en/latest/chains/langchain.chains.graph_qa.cypher.GraphCypherQAChain.html", "title": "Neo4j DB QA chain"}, {"imported": "Neo4jGraph", "source": "langchain.graphs", "docs": "https://api.python.langchain.com/en/latest/graphs/langchain.graphs.neo4j_graph.Neo4jGraph.html", "title": "Neo4j DB QA chain"}]--\x3e\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import GraphCypherQAChain\nfrom langchain.graphs import Neo4jGraph\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'graph = Neo4jGraph(\n    url="bolt://localhost:7687", username="neo4j", password="pleaseletmein"\n)\n')),(0,r.kt)("h2",{id:"seeding-the-database"},"Seeding the database"),(0,r.kt)("p",null,"Assuming your database is empty, you can populate it using Cypher query language. The following Cypher statement is idempotent, which means the database information will be the same if you run it one or multiple times."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'graph.query(\n    """\nMERGE (m:Movie {name:"Top Gun"})\nWITH m\nUNWIND ["Tom Cruise", "Val Kilmer", "Anthony Edwards", "Meg Ryan"] AS actor\nMERGE (a:Actor {name:actor})\nMERGE (a)-[:ACTED_IN]->(m)\n"""\n)\n')),(0,r.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    []\n"))),(0,r.kt)("h2",{id:"refresh-graph-schema-information"},"Refresh graph schema information"),(0,r.kt)("p",null,"If the schema of database changes, you can refresh the schema information needed to generate Cypher statements."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"graph.refresh_schema()\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"print(graph.get_schema)\n")),(0,r.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    \n            Node properties are the following:\n            [{'properties': [{'property': 'name', 'type': 'STRING'}], 'labels': 'Movie'}, {'properties': [{'property': 'name', 'type': 'STRING'}], 'labels': 'Actor'}]\n            Relationship properties are the following:\n            []\n            The relationships are the following:\n            ['(:Actor)-[:ACTED_IN]->(:Movie)']\n            \n"))),(0,r.kt)("h2",{id:"querying-the-graph"},"Querying the graph"),(0,r.kt)("p",null,"We can now use the graph cypher QA chain to ask question of the graph"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"chain = GraphCypherQAChain.from_llm(\n    ChatOpenAI(temperature=0), graph=graph, verbose=True\n)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'chain.run("Who played in Top Gun?")\n')),(0,r.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new GraphCypherQAChain chain...\n    Generated Cypher:\n    MATCH (a:Actor)-[:ACTED_IN]->(m:Movie {name: 'Top Gun'})\n    RETURN a.name\n    Full Context:\n    [{'a.name': 'Tom Cruise'}, {'a.name': 'Val Kilmer'}, {'a.name': 'Anthony Edwards'}, {'a.name': 'Meg Ryan'}]\n    \n    > Finished chain.\n\n\n\n\n\n    'Tom Cruise, Val Kilmer, Anthony Edwards, and Meg Ryan played in Top Gun.'\n"))),(0,r.kt)("h2",{id:"limit-the-number-of-results"},"Limit the number of results"),(0,r.kt)("p",null,"You can limit the number of results from the Cypher QA Chain using the ",(0,r.kt)("inlineCode",{parentName:"p"},"top_k")," parameter.\nThe default is 10."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"chain = GraphCypherQAChain.from_llm(\n    ChatOpenAI(temperature=0), graph=graph, verbose=True, top_k=2\n)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'chain.run("Who played in Top Gun?")\n')),(0,r.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new GraphCypherQAChain chain...\n    Generated Cypher:\n    MATCH (a:Actor)-[:ACTED_IN]->(m:Movie {name: 'Top Gun'})\n    RETURN a.name\n    Full Context:\n    [{'a.name': 'Tom Cruise'}, {'a.name': 'Val Kilmer'}]\n    \n    > Finished chain.\n\n\n\n\n\n    'Tom Cruise and Val Kilmer played in Top Gun.'\n"))),(0,r.kt)("h2",{id:"return-intermediate-results"},"Return intermediate results"),(0,r.kt)("p",null,"You can return intermediate steps from the Cypher QA Chain using the ",(0,r.kt)("inlineCode",{parentName:"p"},"return_intermediate_steps")," parameter"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"chain = GraphCypherQAChain.from_llm(\n    ChatOpenAI(temperature=0), graph=graph, verbose=True, return_intermediate_steps=True\n)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'result = chain("Who played in Top Gun?")\nprint(f"Intermediate steps: {result[\'intermediate_steps\']}")\nprint(f"Final answer: {result[\'result\']}")\n')),(0,r.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new GraphCypherQAChain chain...\n    Generated Cypher:\n    MATCH (a:Actor)-[:ACTED_IN]->(m:Movie {name: 'Top Gun'})\n    RETURN a.name\n    Full Context:\n    [{'a.name': 'Tom Cruise'}, {'a.name': 'Val Kilmer'}, {'a.name': 'Anthony Edwards'}, {'a.name': 'Meg Ryan'}]\n    \n    > Finished chain.\n    Intermediate steps: [{'query': \"MATCH (a:Actor)-[:ACTED_IN]->(m:Movie {name: 'Top Gun'})\\nRETURN a.name\"}, {'context': [{'a.name': 'Tom Cruise'}, {'a.name': 'Val Kilmer'}, {'a.name': 'Anthony Edwards'}, {'a.name': 'Meg Ryan'}]}]\n    Final answer: Tom Cruise, Val Kilmer, Anthony Edwards, and Meg Ryan played in Top Gun.\n"))),(0,r.kt)("h2",{id:"return-direct-results"},"Return direct results"),(0,r.kt)("p",null,"You can return direct results from the Cypher QA Chain using the ",(0,r.kt)("inlineCode",{parentName:"p"},"return_direct")," parameter"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"chain = GraphCypherQAChain.from_llm(\n    ChatOpenAI(temperature=0), graph=graph, verbose=True, return_direct=True\n)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'chain.run("Who played in Top Gun?")\n')),(0,r.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new GraphCypherQAChain chain...\n    Generated Cypher:\n    MATCH (a:Actor)-[:ACTED_IN]->(m:Movie {name: 'Top Gun'})\n    RETURN a.name\n    \n    > Finished chain.\n\n\n\n\n\n    [{'a.name': 'Tom Cruise'},\n     {'a.name': 'Val Kilmer'},\n     {'a.name': 'Anthony Edwards'},\n     {'a.name': 'Meg Ryan'}]\n"))),(0,r.kt)("h2",{id:"add-examples-in-the-cypher-generation-prompt"},"Add examples in the Cypher generation prompt"),(0,r.kt)("p",null,"You can define the Cypher statement you want the LLM to generate for particular questions"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "PromptTemplate", "source": "langchain.prompts.prompt", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html", "title": "Neo4j DB QA chain"}]--\x3e\nfrom langchain.prompts.prompt import PromptTemplate\n\n\nCYPHER_GENERATION_TEMPLATE = """Task:Generate Cypher statement to query a graph database.\nInstructions:\nUse only the provided relationship types and properties in the schema.\nDo not use any other relationship types or properties that are not provided.\nSchema:\n{schema}\nNote: Do not include any explanations or apologies in your responses.\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\nDo not include any text except the generated Cypher statement.\nExamples: Here are a few examples of generated Cypher statements for particular questions:\n# How many people played in Top Gun?\nMATCH (m:Movie {{title:"Top Gun"}})<-[:ACTED_IN]-()\nRETURN count(*) AS numberOfActors\n\nThe question is:\n{question}"""\n\nCYPHER_GENERATION_PROMPT = PromptTemplate(\n    input_variables=["schema", "question"], template=CYPHER_GENERATION_TEMPLATE\n)\n\nchain = GraphCypherQAChain.from_llm(\n    ChatOpenAI(temperature=0), graph=graph, verbose=True, cypher_prompt=CYPHER_GENERATION_PROMPT\n)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'chain.run("How many people played in Top Gun?")\n')),(0,r.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new GraphCypherQAChain chain...\n    Generated Cypher:\n    MATCH (m:Movie {name:\"Top Gun\"})<-[:ACTED_IN]-(:Actor)\n    RETURN count(*) AS numberOfActors\n    Full Context:\n    [{'numberOfActors': 4}]\n    \n    > Finished chain.\n\n\n\n\n\n    'Four people played in Top Gun.'\n"))),(0,r.kt)("h2",{id:"use-separate-llms-for-cypher-and-answer-generation"},"Use separate LLMs for Cypher and answer generation"),(0,r.kt)("p",null,"You can use the ",(0,r.kt)("inlineCode",{parentName:"p"},"cypher_llm")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"qa_llm")," parameters to define different llms"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'chain = GraphCypherQAChain.from_llm(\n     graph=graph,\n     cypher_llm=ChatOpenAI(temperature=0, model="gpt-3.5-turbo"),\n     qa_llm=ChatOpenAI(temperature=0, model="gpt-3.5-turbo-16k"),\n     verbose=True,\n)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'chain.run("Who played in Top Gun?")\n')),(0,r.kt)(s,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    \n    \n    > Entering new GraphCypherQAChain chain...\n    Generated Cypher:\n    MATCH (a:Actor)-[:ACTED_IN]->(m:Movie {name: 'Top Gun'})\n    RETURN a.name\n    Full Context:\n    [{'a.name': 'Tom Cruise'}, {'a.name': 'Val Kilmer'}, {'a.name': 'Anthony Edwards'}, {'a.name': 'Meg Ryan'}]\n    \n    > Finished chain.\n\n\n\n\n\n    'Tom Cruise, Val Kilmer, Anthony Edwards, and Meg Ryan played in Top Gun.'\n"))))}d.isMDXComponent=!0}}]);