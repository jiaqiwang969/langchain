"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[47155],{3905:(e,t,n)=>{n.d(t,{Zo:()=>l,kt:()=>h});var o=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},r=Object.keys(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)n=r[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var c=o.createContext({}),m=function(e){var t=o.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},l=function(e){var t=m(e.components);return o.createElement(c.Provider,{value:t},e.children)},d="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},u=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),d=m(n),u=a,h=d["".concat(c,".").concat(u)]||d[u]||p[u]||r;return n?o.createElement(h,i(i({ref:t},l),{},{components:n})):o.createElement(h,i({ref:t},l))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,i=new Array(r);i[0]=u;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[d]="string"==typeof e?e:a,i[1]=s;for(var m=2;m<r;m++)i[m]=n[m];return o.createElement.apply(null,i)}return o.createElement.apply(null,n)}u.displayName="MDXCreateElement"},67912:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>m});var o=n(87462),a=(n(67294),n(3905));const r={},i="Lost in the middle: The problem with long contexts",s={unversionedId:"modules/data_connection/document_transformers/post_retrieval/long_context_reorder",id:"modules/data_connection/document_transformers/post_retrieval/long_context_reorder",title:"Lost in the middle: The problem with long contexts",description:"No matter the architecture of your model, there is a substantial performance degradation when you include 10+ retrieved documents.",source:"@site/docs/modules/data_connection/document_transformers/post_retrieval/long_context_reorder.md",sourceDirName:"modules/data_connection/document_transformers/post_retrieval",slug:"/modules/data_connection/document_transformers/post_retrieval/long_context_reorder",permalink:"/langchain/docs/modules/data_connection/document_transformers/post_retrieval/long_context_reorder",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Split by tokens",permalink:"/langchain/docs/modules/data_connection/document_transformers/text_splitters/split_by_token"},next:{title:"Text embedding models",permalink:"/langchain/docs/modules/data_connection/text_embedding/"}},c={},m=[],l=(d="CodeOutputBlock",function(e){return console.warn("Component "+d+" was not imported, exported, or provided by MDXProvider as global scope"),(0,a.kt)("div",e)});var d;const p={toc:m},u="wrapper";function h(e){let{components:t,...n}=e;return(0,a.kt)(u,(0,o.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"lost-in-the-middle-the-problem-with-long-contexts"},"Lost in the middle: The problem with long contexts"),(0,a.kt)("p",null,"No matter the architecture of your model, there is a substantial performance degradation when you include 10+ retrieved documents.\nIn brief: When models must access relevant information in the middle of long contexts, they tend to ignore the provided documents.\nSee: ",(0,a.kt)("a",{parentName:"p",href:"https://arxiv.org/abs/2307.03172"},"https://arxiv.org/abs/2307.03172")),(0,a.kt)("p",null,"To avoid this issue you can re-order documents after retrieval to avoid performance degradation."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "Chroma", "source": "langchain.vectorstores", "docs": "https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.chroma.Chroma.html", "title": "Lost in the middle: The problem with long contexts"}, {"imported": "HuggingFaceEmbeddings", "source": "langchain.embeddings", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.huggingface.HuggingFaceEmbeddings.html", "title": "Lost in the middle: The problem with long contexts"}, {"imported": "LongContextReorder", "source": "langchain.document_transformers", "docs": "https://api.python.langchain.com/en/latest/document_transformers/langchain.document_transformers.long_context_reorder.LongContextReorder.html", "title": "Lost in the middle: The problem with long contexts"}, {"imported": "StuffDocumentsChain", "source": "langchain.chains", "docs": "https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.StuffDocumentsChain.html", "title": "Lost in the middle: The problem with long contexts"}, {"imported": "LLMChain", "source": "langchain.chains", "docs": "https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html", "title": "Lost in the middle: The problem with long contexts"}, {"imported": "PromptTemplate", "source": "langchain.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html", "title": "Lost in the middle: The problem with long contexts"}, {"imported": "OpenAI", "source": "langchain.llms", "docs": "https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html", "title": "Lost in the middle: The problem with long contexts"}]--\x3e\nimport os\nimport chromadb\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.document_transformers import (\n    LongContextReorder,\n)\nfrom langchain.chains import StuffDocumentsChain, LLMChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain.llms import OpenAI\n\n# Get embeddings.\nembeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")\n\ntexts = [\n    "Basquetball is a great sport.",\n    "Fly me to the moon is one of my favourite songs.",\n    "The Celtics are my favourite team.",\n    "This is a document about the Boston Celtics",\n    "I simply love going to the movies",\n    "The Boston Celtics won the game by 20 points",\n    "This is just a random text.",\n    "Elden Ring is one of the best games in the last 15 years.",\n    "L. Kornet is one of the best Celtics players.",\n    "Larry Bird was an iconic NBA player.",\n]\n\n# Create a retriever\nretriever = Chroma.from_texts(texts, embedding=embeddings).as_retriever(\n    search_kwargs={"k": 10}\n)\nquery = "What can you tell me about the Celtics?"\n\n# Get relevant documents ordered by relevance score\ndocs = retriever.get_relevant_documents(query)\ndocs\n')),(0,a.kt)(l,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    [Document(page_content='This is a document about the Boston Celtics', metadata={}),\n     Document(page_content='The Celtics are my favourite team.', metadata={}),\n     Document(page_content='L. Kornet is one of the best Celtics players.', metadata={}),\n     Document(page_content='The Boston Celtics won the game by 20 points', metadata={}),\n     Document(page_content='Larry Bird was an iconic NBA player.', metadata={}),\n     Document(page_content='Elden Ring is one of the best games in the last 15 years.', metadata={}),\n     Document(page_content='Basquetball is a great sport.', metadata={}),\n     Document(page_content='I simply love going to the movies', metadata={}),\n     Document(page_content='Fly me to the moon is one of my favourite songs.', metadata={}),\n     Document(page_content='This is just a random text.', metadata={})]\n"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"# Reorder the documents:\n# Less relevant document will be at the middle of the list and more\n# relevant elements at beginning / end.\nreordering = LongContextReorder()\nreordered_docs = reordering.transform_documents(docs)\n\n# Confirm that the 4 relevant documents are at beginning and end.\nreordered_docs\n")),(0,a.kt)(l,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    [Document(page_content='The Celtics are my favourite team.', metadata={}),\n     Document(page_content='The Boston Celtics won the game by 20 points', metadata={}),\n     Document(page_content='Elden Ring is one of the best games in the last 15 years.', metadata={}),\n     Document(page_content='I simply love going to the movies', metadata={}),\n     Document(page_content='This is just a random text.', metadata={}),\n     Document(page_content='Fly me to the moon is one of my favourite songs.', metadata={}),\n     Document(page_content='Basquetball is a great sport.', metadata={}),\n     Document(page_content='Larry Bird was an iconic NBA player.', metadata={}),\n     Document(page_content='L. Kornet is one of the best Celtics players.', metadata={}),\n     Document(page_content='This is a document about the Boston Celtics', metadata={})]\n"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'# We prepare and run a custom Stuff chain with reordered docs as context.\n\n# Override prompts\ndocument_prompt = PromptTemplate(\n    input_variables=["page_content"], template="{page_content}"\n)\ndocument_variable_name = "context"\nllm = OpenAI()\nstuff_prompt_override = """Given this text extracts:\n-----\n{context}\n-----\nPlease answer the following question:\n{query}"""\nprompt = PromptTemplate(\n    template=stuff_prompt_override, input_variables=["context", "query"]\n)\n\n# Instantiate the chain\nllm_chain = LLMChain(llm=llm, prompt=prompt)\nchain = StuffDocumentsChain(\n    llm_chain=llm_chain,\n    document_prompt=document_prompt,\n    document_variable_name=document_variable_name,\n)\nchain.run(input_documents=reordered_docs, query=query)\n')))}h.isMDXComponent=!0}}]);