"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7947],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>h});var a=t(67294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,o=function(e,n){if(null==e)return{};var t,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var s=a.createContext({}),p=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},c=function(e){var n=p(e.components);return a.createElement(s.Provider,{value:n},e.children)},m="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),m=p(t),u=o,h=m["".concat(s,".").concat(u)]||m[u]||d[u]||r;return t?a.createElement(h,i(i({ref:n},c),{},{components:t})):a.createElement(h,i({ref:n},c))}));function h(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var r=t.length,i=new Array(r);i[0]=u;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[m]="string"==typeof e?e:o,i[1]=l;for(var p=2;p<r;p++)i[p]=t[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},61088:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var a=t(87462),o=(t(67294),t(3905));const r={},i="SageMakerEndpoint",l={unversionedId:"integrations/llms/sagemaker",id:"integrations/llms/sagemaker",title:"SageMakerEndpoint",description:"Amazon SageMaker is a system that can build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.",source:"@site/docs/integrations/llms/sagemaker.md",sourceDirName:"integrations/llms",slug:"/integrations/llms/sagemaker",permalink:"/langchain/docs/integrations/llms/sagemaker",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"Runhouse",permalink:"/langchain/docs/integrations/llms/runhouse"},next:{title:"StochasticAI",permalink:"/langchain/docs/integrations/llms/stochasticai"}},s={},p=[{value:"Set up",id:"set-up",level:2},{value:"Example",id:"example",level:2}],c={toc:p},m="wrapper";function d(e){let{components:n,...t}=e;return(0,o.kt)(m,(0,a.Z)({},c,t,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"sagemakerendpoint"},"SageMakerEndpoint"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://aws.amazon.com/sagemaker/"},"Amazon SageMaker")," is a system that can build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows."),(0,o.kt)("p",null,"This notebooks goes over how to use an LLM hosted on a ",(0,o.kt)("inlineCode",{parentName:"p"},"SageMaker endpoint"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"pip3 install langchain boto3\n")),(0,o.kt)("h2",{id:"set-up"},"Set up"),(0,o.kt)("p",null,"You have to set up following required parameters of the ",(0,o.kt)("inlineCode",{parentName:"p"},"SagemakerEndpoint")," call:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"endpoint_name"),": The name of the endpoint from the deployed Sagemaker model.\nMust be unique within an AWS Region."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"credentials_profile_name"),": The name of the profile in the ~/.aws/credentials or ~/.aws/config files, which\nhas either access keys or role information specified.\nIf not specified, the default credential profile or, if on an EC2 instance,\ncredentials from IMDS will be used.\nSee: ",(0,o.kt)("a",{parentName:"li",href:"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html"},"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html"))),(0,o.kt)("h2",{id:"example"},"Example"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "Document", "source": "langchain.docstore.document", "docs": "https://api.python.langchain.com/en/latest/schema/langchain.schema.document.Document.html", "title": "SageMakerEndpoint"}]--\x3e\nfrom langchain.docstore.document import Document\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'example_doc_1 = """\nPeter and Elizabeth took a taxi to attend the night party in the city. While in the party, Elizabeth collapsed and was rushed to the hospital.\nSince she was diagnosed with a brain injury, the doctor told Peter to stay besides her until she gets well.\nTherefore, Peter stayed with her at the hospital for 3 days without leaving.\n"""\n\ndocs = [\n    Document(\n        page_content=example_doc_1,\n    )\n]\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "LLMContentHandler", "source": "langchain.llms.sagemaker_endpoint", "docs": "https://api.python.langchain.com/en/latest/llms/langchain.llms.sagemaker_endpoint.LLMContentHandler.html", "title": "SageMakerEndpoint"}, {"imported": "load_qa_chain", "source": "langchain.chains.question_answering", "docs": "https://api.python.langchain.com/en/latest/chains/langchain.chains.question_answering.load_qa_chain.html", "title": "SageMakerEndpoint"}]--\x3e\nfrom typing import Dict\n\nfrom langchain import PromptTemplate, SagemakerEndpoint\nfrom langchain.llms.sagemaker_endpoint import LLMContentHandler\nfrom langchain.chains.question_answering import load_qa_chain\nimport json\n\nquery = """How long was Elizabeth hospitalized?\n"""\n\nprompt_template = """Use the following pieces of context to answer the question at the end.\n\n{context}\n\nQuestion: {question}\nAnswer:"""\nPROMPT = PromptTemplate(\n    template=prompt_template, input_variables=["context", "question"]\n)\n\n\nclass ContentHandler(LLMContentHandler):\n    content_type = "application/json"\n    accepts = "application/json"\n\n    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n        input_str = json.dumps({prompt: prompt, **model_kwargs})\n        return input_str.encode("utf-8")\n\n    def transform_output(self, output: bytes) -> str:\n        response_json = json.loads(output.read().decode("utf-8"))\n        return response_json[0]["generated_text"]\n\n\ncontent_handler = ContentHandler()\n\nchain = load_qa_chain(\n    llm=SagemakerEndpoint(\n        endpoint_name="endpoint-name",\n        credentials_profile_name="credentials-profile-name",\n        region_name="us-west-2",\n        model_kwargs={"temperature": 1e-10},\n        content_handler=content_handler,\n    ),\n    prompt=PROMPT,\n)\n\nchain({"input_documents": docs, "question": query}, return_only_outputs=True)\n')))}d.isMDXComponent=!0}}]);