"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[90641],{3905:(e,n,t)=>{t.d(n,{Zo:()=>p,kt:()=>g});var a=t(67294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function c(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=a.createContext({}),l=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},p=function(e){var n=l(e.components);return a.createElement(s.Provider,{value:n},e.children)},d="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,p=c(e,["components","mdxType","originalType","parentName"]),d=l(t),u=r,g=d["".concat(s,".").concat(u)]||d[u]||m[u]||o;return t?a.createElement(g,i(i({ref:n},p),{},{components:t})):a.createElement(g,i({ref:n},p))}));function g(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=t.length,i=new Array(o);i[0]=u;var c={};for(var s in n)hasOwnProperty.call(n,s)&&(c[s]=n[s]);c.originalType=e,c[d]="string"==typeof e?e:r,i[1]=c;for(var l=2;l<o;l++)i[l]=t[l];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},67302:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>c,toc:()=>l});var a=t(87462),r=(t(67294),t(3905));const o={},i="Pinecone",c={unversionedId:"integrations/vectorstores/pinecone",id:"integrations/vectorstores/pinecone",title:"Pinecone",description:"Pinecone is a vector database with broad functionality.",source:"@site/docs/integrations/vectorstores/pinecone.md",sourceDirName:"integrations/vectorstores",slug:"/integrations/vectorstores/pinecone",permalink:"/langchain/docs/integrations/vectorstores/pinecone",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"PGVector",permalink:"/langchain/docs/integrations/vectorstores/pgvector"},next:{title:"Qdrant",permalink:"/langchain/docs/integrations/vectorstores/qdrant"}},s={},l=[{value:"Adding More Text to an Existing Index",id:"adding-more-text-to-an-existing-index",level:3},{value:"Maximal Marginal Relevance Searches",id:"maximal-marginal-relevance-searches",level:3}],p={toc:l},d="wrapper";function m(e){let{components:n,...t}=e;return(0,r.kt)(d,(0,a.Z)({},p,t,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"pinecone"},"Pinecone"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},(0,r.kt)("a",{parentName:"p",href:"https://docs.pinecone.io/docs/overview"},"Pinecone")," is a vector database with broad functionality.")),(0,r.kt)("p",null,"This notebook shows how to use functionality related to the ",(0,r.kt)("inlineCode",{parentName:"p"},"Pinecone")," vector database."),(0,r.kt)("p",null,"To use Pinecone, you must have an API key.\nHere are the ",(0,r.kt)("a",{parentName:"p",href:"https://docs.pinecone.io/docs/quickstart"},"installation instructions"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pip install pinecone-client openai tiktoken langchain\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import os\nimport getpass\n\nos.environ["PINECONE_API_KEY"] = getpass.getpass("Pinecone API Key:")\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'os.environ["PINECONE_ENV"] = getpass.getpass("Pinecone Environment:")\n')),(0,r.kt)("p",null,"We want to use ",(0,r.kt)("inlineCode",{parentName:"p"},"OpenAIEmbeddings")," so we have to get the OpenAI API Key."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'os.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "OpenAIEmbeddings", "source": "langchain.embeddings.openai", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html", "title": "Pinecone"}, {"imported": "CharacterTextSplitter", "source": "langchain.text_splitter", "docs": "https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.CharacterTextSplitter.html", "title": "Pinecone"}, {"imported": "Pinecone", "source": "langchain.vectorstores", "docs": "https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.pinecone.Pinecone.html", "title": "Pinecone"}, {"imported": "TextLoader", "source": "langchain.document_loaders", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.text.TextLoader.html", "title": "Pinecone"}]--\x3e\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import Pinecone\nfrom langchain.document_loaders import TextLoader\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "TextLoader", "source": "langchain.document_loaders", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.text.TextLoader.html", "title": "Pinecone"}]--\x3e\nfrom langchain.document_loaders import TextLoader\n\nloader = TextLoader("../../../state_of_the_union.txt")\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocs = text_splitter.split_documents(documents)\n\nembeddings = OpenAIEmbeddings()\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import pinecone\n\n# initialize pinecone\npinecone.init(\n    api_key=os.getenv("PINECONE_API_KEY"),  # find at app.pinecone.io\n    environment=os.getenv("PINECONE_ENV"),  # next to api key in console\n)\n\nindex_name = "langchain-demo"\n\n# First, check if our index already exists. If it doesn\'t, we create it\nif index_name not in pinecone.list_indexes():\n    # we create a new index\n    pinecone.create_index(\n      name=index_name,\n      metric=\'cosine\',\n      dimension=1536  \n)\n# The OpenAI embedding model `text-embedding-ada-002 uses 1536 dimensions`\ndocsearch = Pinecone.from_documents(docs, embeddings, index_name=index_name)\n\n# if you already have an index, you can load it like this\n# docsearch = Pinecone.from_existing_index(index_name, embeddings)\n\nquery = "What did the president say about Ketanji Brown Jackson"\ndocs = docsearch.similarity_search(query)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"print(docs[0].page_content)\n")),(0,r.kt)("h3",{id:"adding-more-text-to-an-existing-index"},"Adding More Text to an Existing Index"),(0,r.kt)("p",null,"More text can embedded and upserted to an existing Pinecone index using the ",(0,r.kt)("inlineCode",{parentName:"p"},"add_texts")," function"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'index = pinecone.Index("langchain-demo")\nvectorstore = Pinecone(index, embeddings.embed_query, "text")\n\nvectorstore.add_texts("More text!")\n')),(0,r.kt)("h3",{id:"maximal-marginal-relevance-searches"},"Maximal Marginal Relevance Searches"),(0,r.kt)("p",null,"In addition to using similarity search in the retriever object, you can also use ",(0,r.kt)("inlineCode",{parentName:"p"},"mmr")," as retriever."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'retriever = docsearch.as_retriever(search_type="mmr")\nmatched_docs = retriever.get_relevant_documents(query)\nfor i, d in enumerate(matched_docs):\n    print(f"\\n## Document {i}\\n")\n    print(d.page_content)\n')),(0,r.kt)("p",null,"Or use ",(0,r.kt)("inlineCode",{parentName:"p"},"max_marginal_relevance_search")," directly:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'found_docs = docsearch.max_marginal_relevance_search(query, k=2, fetch_k=10)\nfor i, doc in enumerate(found_docs):\n    print(f"{i + 1}.", doc.page_content, "\\n")\n')))}m.isMDXComponent=!0}}]);