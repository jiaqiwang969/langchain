"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[90774],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>m});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var c=n.createContext({}),l=function(e){var t=n.useContext(c),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},p=function(e){var t=l(e.components);return n.createElement(c.Provider,{value:t},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},h=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,c=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),d=l(a),h=r,m=d["".concat(c,".").concat(h)]||d[h]||u[h]||o;return a?n.createElement(m,i(i({ref:t},p),{},{components:a})):n.createElement(m,i({ref:t},p))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=h;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[d]="string"==typeof e?e:r,i[1]=s;for(var l=2;l<o;l++)i[l]=a[l];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}h.displayName="MDXCreateElement"},4180:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var n=a(87462),r=(a(67294),a(3905));const o={},i="Vectara",s={unversionedId:"integrations/vectorstores/vectara",id:"integrations/vectorstores/vectara",title:"Vectara",description:"Vectara is a API platform for building GenAI applications. It provides an easy-to-use API for document indexing and querying that is managed by Vectara and is optimized for performance and accuracy.",source:"@site/docs/integrations/vectorstores/vectara.md",sourceDirName:"integrations/vectorstores",slug:"/integrations/vectorstores/vectara",permalink:"/langchain/docs/integrations/vectorstores/vectara",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"USearch",permalink:"/langchain/docs/integrations/vectorstores/usearch"},next:{title:"Weaviate",permalink:"/langchain/docs/integrations/vectorstores/weaviate"}},c={},l=[{value:"Connecting to Vectara from LangChain",id:"connecting-to-vectara-from-langchain",level:2},{value:"Similarity search",id:"similarity-search",level:2},{value:"Similarity search with score",id:"similarity-search-with-score",level:2},{value:"Vectara as a Retriever",id:"vectara-as-a-retriever",level:2}],p=(d="CodeOutputBlock",function(e){return console.warn("Component "+d+" was not imported, exported, or provided by MDXProvider as global scope"),(0,r.kt)("div",e)});var d;const u={toc:l},h="wrapper";function m(e){let{components:t,...a}=e;return(0,r.kt)(h,(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"vectara"},"Vectara"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},(0,r.kt)("a",{parentName:"p",href:"https://vectara.com/"},"Vectara")," is a API platform for building GenAI applications. It provides an easy-to-use API for document indexing and querying that is managed by Vectara and is optimized for performance and accuracy.\nSee the ",(0,r.kt)("a",{parentName:"p",href:"https://docs.vectara.com/docs/"},"Vectara API documentation ")," for more information on how to use the API.")),(0,r.kt)("p",null,"This notebook shows how to use functionality related to the ",(0,r.kt)("inlineCode",{parentName:"p"},"Vectara"),"'s integration with langchain.\nNote that unlike many other integrations in this category, Vectara provides an end-to-end managed service for ",(0,r.kt)("a",{parentName:"p",href:"https://vectara.com/grounded-generation/"},"Grounded Generation")," (aka retrieval agumented generation), which includes:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"A way to extract text from document files and chunk them into sentences."),(0,r.kt)("li",{parentName:"ol"},"Its own embeddings model and vector store - each text segment is encoded into a vector embedding and stored in the Vectara internal vector store"),(0,r.kt)("li",{parentName:"ol"},"A query service that automatically encodes the query into embedding, and retrieves the most relevant text segments (including support for ",(0,r.kt)("a",{parentName:"li",href:"https://docs.vectara.com/docs/api-reference/search-apis/lexical-matching"},"Hybrid Search"),")")),(0,r.kt)("p",null,"All of these are supported in this LangChain integration."),(0,r.kt)("h1",{id:"setup"},"Setup"),(0,r.kt)("p",null,"You will need a Vectara account to use Vectara with LangChain. To get started, use the following steps:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"https://console.vectara.com/signup"},"Sign up")," for a Vectara account if you don't already have one. Once you have completed your sign up you will have a Vectara customer ID. You can find your customer ID by clicking on your name, on the top-right of the Vectara console window."),(0,r.kt)("li",{parentName:"ol"},"Within your account you can create one or more corpora. Each corpus represents an area that stores text data upon ingest from input documents. To create a corpus, use the ",(0,r.kt)("strong",{parentName:"li"},'"Create Corpus"')," button. You then provide a name to your corpus as well as a description. Optionally you can define filtering attributes and apply some advanced options. If you click on your created corpus, you can see its name and corpus ID right on the top."),(0,r.kt)("li",{parentName:"ol"},"Next you'll need to create API keys to access the corpus. Click on the ",(0,r.kt)("strong",{parentName:"li"},'"Authorization"')," tab in the corpus view and then the ",(0,r.kt)("strong",{parentName:"li"},'"Create API Key"'),' button. Give your key a name, and choose whether you want query only or query+index for your key. Click "Create" and you now have an active API key. Keep this key confidential. ')),(0,r.kt)("p",null,"To use LangChain with Vectara, you'll need to have these three values: customer ID, corpus ID and api_key.\nYou can provide those to LangChain in two ways:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Include in your environment these three variables: ",(0,r.kt)("inlineCode",{parentName:"li"},"VECTARA_CUSTOMER_ID"),", ",(0,r.kt)("inlineCode",{parentName:"li"},"VECTARA_CORPUS_ID")," and ",(0,r.kt)("inlineCode",{parentName:"li"},"VECTARA_API_KEY"),".")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"For example, you can set these variables using os.environ and getpass as follows:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import os\nimport getpass\n\nos.environ["VECTARA_CUSTOMER_ID"] = getpass.getpass("Vectara Customer ID:")\nos.environ["VECTARA_CORPUS_ID"] = getpass.getpass("Vectara Corpus ID:")\nos.environ["VECTARA_API_KEY"] = getpass.getpass("Vectara API Key:")\n')),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},"Add them to the Vectara vectorstore constructor:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"vectorstore = Vectara(\n                vectara_customer_id=vectara_customer_id,\n                vectara_corpus_id=vectara_corpus_id,\n                vectara_api_key=vectara_api_key\n            )\n")),(0,r.kt)("h2",{id:"connecting-to-vectara-from-langchain"},"Connecting to Vectara from LangChain"),(0,r.kt)("p",null,"To get started, let's ingest the documents using the from_documents() method.\nWe assume here that you've added your VECTARA_CUSTOMER_ID, VECTARA_CORPUS_ID and query+indexing VECTARA_API_KEY as environment variables."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "FakeEmbeddings", "source": "langchain.embeddings", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.fake.FakeEmbeddings.html", "title": "Vectara"}, {"imported": "CharacterTextSplitter", "source": "langchain.text_splitter", "docs": "https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.CharacterTextSplitter.html", "title": "Vectara"}, {"imported": "Vectara", "source": "langchain.vectorstores", "docs": "https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.vectara.Vectara.html", "title": "Vectara"}, {"imported": "TextLoader", "source": "langchain.document_loaders", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.text.TextLoader.html", "title": "Vectara"}]--\x3e\nfrom langchain.embeddings import FakeEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import Vectara\nfrom langchain.document_loaders import TextLoader\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'loader = TextLoader("../../modules/state_of_the_union.txt")\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocs = text_splitter.split_documents(documents)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'vectara = Vectara.from_documents(\n    docs,\n    embedding=FakeEmbeddings(size=768),\n    doc_metadata={"speech": "state-of-the-union"},\n)\n')),(0,r.kt)("p",null,"Vectara's indexing API provides a file upload API where the file is handled directly by Vectara - pre-processed, chunked optimally and added to the Vectara vector store.\nTo use this, we added the add_files() method (as well as from_files()). "),(0,r.kt)("p",null,"Let's see this in action. We pick two PDF documents to upload: "),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},'The "I have a dream" speech by Dr. King'),(0,r.kt)("li",{parentName:"ol"},'Churchill\'s "We Shall Fight on the Beaches" speech')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import tempfile\nimport urllib.request\n\nurls = [\n    [\n        "https://www.gilderlehrman.org/sites/default/files/inline-pdfs/king.dreamspeech.excerpts.pdf",\n        "I-have-a-dream",\n    ],\n    [\n        "https://www.parkwayschools.net/cms/lib/MO01931486/Centricity/Domain/1578/Churchill_Beaches_Speech.pdf",\n        "we shall fight on the beaches",\n    ],\n]\nfiles_list = []\nfor url, _ in urls:\n    name = tempfile.NamedTemporaryFile().name\n    urllib.request.urlretrieve(url, name)\n    files_list.append(name)\n\ndocsearch: Vectara = Vectara.from_files(\n    files=files_list,\n    embedding=FakeEmbeddings(size=768),\n    metadatas=[{"url": url, "speech": title} for url, title in urls],\n)\n')),(0,r.kt)("h2",{id:"similarity-search"},"Similarity search"),(0,r.kt)("p",null,"The simplest scenario for using Vectara is to perform a similarity search. "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'query = "What did the president say about Ketanji Brown Jackson"\nfound_docs = vectara.similarity_search(\n    query, n_sentence_context=0, filter="doc.speech = \'state-of-the-union\'"\n)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"print(found_docs[0].page_content)\n")),(0,r.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson.\n"))),(0,r.kt)("h2",{id:"similarity-search-with-score"},"Similarity search with score"),(0,r.kt)("p",null,"Sometimes we might want to perform the search, but also obtain a relevancy score to know how good is a particular result."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'query = "What did the president say about Ketanji Brown Jackson"\nfound_docs = vectara.similarity_search_with_score(\n    query, filter="doc.speech = \'state-of-the-union\'", score_threshold=0.2,\n)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'document, score = found_docs[0]\nprint(document.page_content)\nprint(f"\\nScore: {score}")\n')),(0,r.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    Justice Breyer, thank you for your service. One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence. A former top litigator in private practice.\n    \n    Score: 0.786569\n"))),(0,r.kt)("p",null,"Now let's do similar search for content in the files we uploaded"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'query = "We must forever conduct our struggle"\nmin_score = 1.2\nfound_docs = vectara.similarity_search_with_score(\n    query, filter="doc.speech = \'I-have-a-dream\'", score_threshold=min_score,\n)\nprint(f"With this threshold of {min_score} we have {len(found_docs)} documents")\n')),(0,r.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    With this threshold of 1.2 we have 0 documents\n"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'query = "We must forever conduct our struggle"\nmin_score = 0.2\nfound_docs = vectara.similarity_search_with_score(\n    query, filter="doc.speech = \'I-have-a-dream\'", score_threshold=min_score,\n)\nprint(f"With this threshold of {min_score} we have {len(found_docs)} documents")\n')),(0,r.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    With this threshold of 0.2 we have 3 documents\n"))),(0,r.kt)("h2",{id:"vectara-as-a-retriever"},"Vectara as a Retriever"),(0,r.kt)("p",null,"Vectara, as all the other LangChain vectorstores, is most often used as a LangChain Retriever:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"retriever = vectara.as_retriever()\nretriever\n")),(0,r.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    VectaraRetriever(tags=['Vectara'], metadata=None, vectorstore=<langchain.vectorstores.vectara.Vectara object at 0x1586bd330>, search_type='similarity', search_kwargs={'lambda_val': 0.025, 'k': 5, 'filter': '', 'n_sentence_context': '2'})\n"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'query = "What did the president say about Ketanji Brown Jackson"\nretriever.get_relevant_documents(query)[0]\n')),(0,r.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    Document(page_content='Justice Breyer, thank you for your service. One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence. A former top litigator in private practice.', metadata={'source': 'langchain', 'lang': 'eng', 'offset': '596', 'len': '97', 'speech': 'state-of-the-union'})\n"))))}m.isMDXComponent=!0}}]);