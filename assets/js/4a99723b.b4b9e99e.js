"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[33169],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>d});var n=a(67294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var l=n.createContext({}),m=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},c=function(e){var t=m(e.components);return n.createElement(l.Provider,{value:t},e.children)},p="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),p=m(a),u=o,d=p["".concat(l,".").concat(u)]||p[u]||h[u]||r;return a?n.createElement(d,s(s({ref:t},c),{},{components:a})):n.createElement(d,s({ref:t},c))}));function d(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,s=new Array(r);s[0]=u;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[p]="string"==typeof e?e:o,s[1]=i;for(var m=2;m<r;m++)s[m]=a[m];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},23656:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>m});var n=a(87462),o=(a(67294),a(3905));const r={},s="Xata chat memory",i={unversionedId:"integrations/memory/xata_chat_message_history",id:"integrations/memory/xata_chat_message_history",title:"Xata chat memory",description:"Xata is a serverless data platform, based on PostgreSQL and Elasticsearch. It provides a Python SDK for interacting with your database, and a UI for managing your data. With the XataChatMessageHistory class, you can use Xata databases for longer-term persistence of chat sessions.",source:"@site/docs/integrations/memory/xata_chat_message_history.md",sourceDirName:"integrations/memory",slug:"/integrations/memory/xata_chat_message_history",permalink:"/langchain/docs/integrations/memory/xata_chat_message_history",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"Streamlit Chat Message History",permalink:"/langchain/docs/integrations/memory/streamlit_chat_message_history"},next:{title:"Zep Memory",permalink:"/langchain/docs/integrations/memory/zep_memory"}},l={},m=[{value:"Setup",id:"setup",level:2},{value:"Create a database",id:"create-a-database",level:3},{value:"Create a simple memory store",id:"create-a-simple-memory-store",level:2},{value:"Conversational Q&amp;A chain on your data with memory",id:"conversational-qa-chain-on-your-data-with-memory",level:2}],c={toc:m},p="wrapper";function h(e){let{components:t,...a}=e;return(0,o.kt)(p,(0,n.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"xata-chat-memory"},"Xata chat memory"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://xata.io"},"Xata")," is a serverless data platform, based on PostgreSQL and Elasticsearch. It provides a Python SDK for interacting with your database, and a UI for managing your data. With the ",(0,o.kt)("inlineCode",{parentName:"p"},"XataChatMessageHistory")," class, you can use Xata databases for longer-term persistence of chat sessions."),(0,o.kt)("p",null,"This notebook covers:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"A simple example showing what ",(0,o.kt)("inlineCode",{parentName:"li"},"XataChatMessageHistory")," does."),(0,o.kt)("li",{parentName:"ul"},"A more complex example using a REACT agent that answer questions based on a knowledge based or documentation (stored in Xata as a vector store) and also having a long-term searchable history of its past messages (stored in Xata as a memory store)")),(0,o.kt)("h2",{id:"setup"},"Setup"),(0,o.kt)("h3",{id:"create-a-database"},"Create a database"),(0,o.kt)("p",null,"In the ",(0,o.kt)("a",{parentName:"p",href:"https://app.xata.io"},"Xata UI")," create a new database. You can name it whatever you want, in this notepad we'll use ",(0,o.kt)("inlineCode",{parentName:"p"},"langchain"),". The Langchain integration can auto-create the table used for storying the memory, and this is what we'll use in this example. If you want to pre-create the table, ensure it has the right schema and set ",(0,o.kt)("inlineCode",{parentName:"p"},"create_table")," to ",(0,o.kt)("inlineCode",{parentName:"p"},"False")," when creating the class. Pre-creating the table saves one round-trip to the database during each session initialization."),(0,o.kt)("p",null,"Let's first install our dependencies:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"pip install xata openai langchain\n")),(0,o.kt)("p",null,"Next, we need to get the environment variables for Xata. You can create a new API key by visiting your ",(0,o.kt)("a",{parentName:"p",href:"https://app.xata.io/settings"},"account settings"),". To find the database URL, go to the Settings page of the database that you have created. The database URL should look something like this: ",(0,o.kt)("inlineCode",{parentName:"p"},"https://demo-uni3q8.eu-west-1.xata.sh/db/langchain"),"."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'import getpass\n\napi_key = getpass.getpass("Xata API key: ")\ndb_url = input("Xata database URL (copy it from your DB settings):")\n')),(0,o.kt)("h2",{id:"create-a-simple-memory-store"},"Create a simple memory store"),(0,o.kt)("p",null,"To test the memory store functionality in isolation, let's use the following code snippet:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "XataChatMessageHistory", "source": "langchain.memory", "docs": "https://api.python.langchain.com/en/latest/memory/langchain.memory.chat_message_histories.xata.XataChatMessageHistory.html", "title": "Xata chat memory"}]--\x3e\nfrom langchain.memory import XataChatMessageHistory\n\nhistory = XataChatMessageHistory(\n    session_id="session-1",\n    api_key=api_key,\n    db_url=db_url,\n    table_name="memory"\n)\n\nhistory.add_user_message("hi!")\n\nhistory.add_ai_message("whats up?")\n')),(0,o.kt)("p",null,"The above code creates a session with the ID ",(0,o.kt)("inlineCode",{parentName:"p"},"session-1")," and stores two messages in it. After running the above, if you visit the Xata UI, you should see a table named ",(0,o.kt)("inlineCode",{parentName:"p"},"memory")," and the two messages added to it."),(0,o.kt)("p",null,"You can retrieve the message history for a particular session with the following code:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"history.messages\n")),(0,o.kt)("h2",{id:"conversational-qa-chain-on-your-data-with-memory"},"Conversational Q&A chain on your data with memory"),(0,o.kt)("p",null,"Let's now see a more complex example in which we combine OpenAI, the Xata Vector Store integration, and the Xata memory store integration to create a Q&A chat bot on your data, with follow-up questions and history."),(0,o.kt)("p",null,"We're going to need to access the OpenAI API, so let's configure the API key:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'import os\n\nos.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")\n')),(0,o.kt)("p",null,"To store the documents that the chatbot will search for answers, add a table named ",(0,o.kt)("inlineCode",{parentName:"p"},"docs")," to your ",(0,o.kt)("inlineCode",{parentName:"p"},"langchain")," database using the Xata UI, and add the following columns:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"content"),' of type "Text". This is used to store the ',(0,o.kt)("inlineCode",{parentName:"li"},"Document.pageContent")," values."),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"embedding"),' of type "Vector". Use the dimension used by the model you plan to use. In this notebook we use OpenAI embeddings, which have 1536 dimensions.')),(0,o.kt)("p",null,"Let's create the vector store and add some sample docs to it:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "OpenAIEmbeddings", "source": "langchain.embeddings.openai", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html", "title": "Xata chat memory"}, {"imported": "XataVectorStore", "source": "langchain.vectorstores.xata", "docs": "https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.xata.XataVectorStore.html", "title": "Xata chat memory"}]--\x3e\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.vectorstores.xata import XataVectorStore\n\nembeddings = OpenAIEmbeddings()\n\ntexts = [\n    "Xata is a Serverless Data platform based on PostgreSQL",\n    "Xata offers a built-in vector type that can be used to store and query vectors",\n    "Xata includes similarity search"\n]\n\nvector_store = XataVectorStore.from_texts(texts, embeddings, api_key=api_key, db_url=db_url, table_name="docs")\n')),(0,o.kt)("p",null,"After running the above command, if you go to the Xata UI, you should see the documents loaded together with their embeddings in the ",(0,o.kt)("inlineCode",{parentName:"p"},"docs")," table."),(0,o.kt)("p",null,"Let's now create a ConversationBufferMemory to store the chat messages from both the user and the AI."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "ConversationBufferMemory", "source": "langchain.memory", "docs": "https://api.python.langchain.com/en/latest/memory/langchain.memory.buffer.ConversationBufferMemory.html", "title": "Xata chat memory"}]--\x3e\nfrom langchain.memory import ConversationBufferMemory\nfrom uuid import uuid4\n\nchat_memory = XataChatMessageHistory(\n    session_id=str(uuid4()),   # needs to be unique per user session\n    api_key=api_key,\n    db_url=db_url,\n    table_name="memory"\n)\nmemory = ConversationBufferMemory(memory_key="chat_history", chat_memory=chat_memory, return_messages=True)\n')),(0,o.kt)("p",null,"Now it's time to create an Agent to use both the vector store and the chat memory together."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "initialize_agent", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.initialize.initialize_agent.html", "title": "Xata chat memory"}, {"imported": "AgentType", "source": "langchain.agents", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_types.AgentType.html", "title": "Xata chat memory"}, {"imported": "create_retriever_tool", "source": "langchain.agents.agent_toolkits", "docs": "https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_toolkits.conversational_retrieval.tool.create_retriever_tool.html", "title": "Xata chat memory"}, {"imported": "ChatOpenAI", "source": "langchain.chat_models", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html", "title": "Xata chat memory"}]--\x3e\nfrom langchain.agents import initialize_agent, AgentType\nfrom langchain.agents.agent_toolkits import create_retriever_tool\nfrom langchain.chat_models import ChatOpenAI\n\ntool = create_retriever_tool(\n    vector_store.as_retriever(), \n    "search_docs",\n    "Searches and returns documents from the Xata manual. Useful when you need to answer questions about Xata."\n)\ntools = [tool]\n\nllm = ChatOpenAI(temperature=0)\n\nagent = initialize_agent(\n    tools,\n    llm,\n    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n    verbose=True,\n    memory=memory)\n')),(0,o.kt)("p",null,"To test, let's tell the agent our name:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'agent.run(input="My name is bob")\n')),(0,o.kt)("p",null,"Now, let's now ask the agent some questions about Xata:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'agent.run(input="What is xata?")\n')),(0,o.kt)("p",null,"Notice that it answers based on the data stored in the document store. And now, let's ask a follow up question:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'agent.run(input="Does it support similarity search?")\n')),(0,o.kt)("p",null,"And now let's test its memory:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'agent.run(input="Did I tell you my name? What is it?")\n')))}h.isMDXComponent=!0}}]);