"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[87152],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>y});var r=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function p(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=r.createContext({}),s=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):p(p({},t),e)),n},m=function(e){var t=s(e.components);return r.createElement(l.Provider,{value:t},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),u=s(n),d=o,y=u["".concat(l,".").concat(d)]||u[d]||c[d]||a;return n?r.createElement(y,p(p({ref:t},m),{},{components:n})):r.createElement(y,p({ref:t},m))}));function y(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,p=new Array(a);p[0]=d;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[u]="string"==typeof e?e:o,p[1]=i;for(var s=2;s<a;s++)p[s]=n[s];return r.createElement.apply(null,p)}return r.createElement.apply(null,n)}d.displayName="MDXCreateElement"},54018:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>u,default:()=>g,frontMatter:()=>m,metadata:()=>c,toc:()=>y});var r=n(87462),o=(n(67294),n(3905));const a=(p="CodeOutputBlock",function(e){return console.warn("Component "+p+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var p;const i={toc:[]},l="wrapper";function s(e){let{components:t,...n}=e;return(0,o.kt)(l,(0,r.Z)({},i,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.prompts import FewShotPromptTemplate, PromptTemplate\n\nexample_prompt = PromptTemplate(\n    input_variables=["input", "output"],\n    template="Input: {input}\\nOutput: {output}",\n)\n\n# Examples of a pretend task of creating antonyms.\nexamples = [\n    {"input": "happy", "output": "sad"},\n    {"input": "tall", "output": "short"},\n    {"input": "energetic", "output": "lethargic"},\n    {"input": "sunny", "output": "gloomy"},\n    {"input": "windy", "output": "calm"},\n]\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'example_selector = SemanticSimilarityExampleSelector.from_examples(\n    # The list of examples available to select from.\n    examples, \n    # The embedding class used to produce embeddings which are used to measure semantic similarity.\n    OpenAIEmbeddings(), \n    # The VectorStore class that is used to store the embeddings and do a similarity search over.\n    Chroma, \n    # The number of examples to produce.\n    k=1\n)\nsimilar_prompt = FewShotPromptTemplate(\n    # We provide an ExampleSelector instead of examples.\n    example_selector=example_selector,\n    example_prompt=example_prompt,\n    prefix="Give the antonym of every input",\n    suffix="Input: {adjective}\\nOutput:", \n    input_variables=["adjective"],\n)\n')),(0,o.kt)(a,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Running Chroma using direct local API.\n    Using DuckDB in-memory for database. Data will be transient.\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# Input is a feeling, so should select the happy/sad example\nprint(similar_prompt.format(adjective="worried"))\n')),(0,o.kt)(a,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Give the antonym of every input\n    \n    Input: happy\n    Output: sad\n    \n    Input: worried\n    Output:\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# Input is a measurement, so should select the tall/short example\nprint(similar_prompt.format(adjective="fat"))\n')),(0,o.kt)(a,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Give the antonym of every input\n    \n    Input: happy\n    Output: sad\n    \n    Input: fat\n    Output:\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# You can add new examples to the SemanticSimilarityExampleSelector as well\nsimilar_prompt.example_selector.add_example({"input": "enthusiastic", "output": "apathetic"})\nprint(similar_prompt.format(adjective="joyful"))\n')),(0,o.kt)(a,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Give the antonym of every input\n    \n    Input: happy\n    Output: sad\n    \n    Input: joyful\n    Output:\n"))))}s.isMDXComponent=!0;const m={},u="Select by similarity",c={unversionedId:"modules/model_io/prompts/example_selectors/similarity",id:"modules/model_io/prompts/example_selectors/similarity",title:"Select by similarity",description:"This object selects examples based on similarity to the inputs. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs.",source:"@site/docs/modules/model_io/prompts/example_selectors/similarity.mdx",sourceDirName:"modules/model_io/prompts/example_selectors",slug:"/modules/model_io/prompts/example_selectors/similarity",permalink:"/langchain/docs/modules/model_io/prompts/example_selectors/similarity",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Select by n-gram overlap",permalink:"/langchain/docs/modules/model_io/prompts/example_selectors/ngram_overlap"},next:{title:"Language models",permalink:"/langchain/docs/modules/model_io/models/"}},d={},y=[],h={toc:y},f="wrapper";function g(e){let{components:t,...n}=e;return(0,o.kt)(f,(0,r.Z)({},h,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"select-by-similarity"},"Select by similarity"),(0,o.kt)("p",null,"This object selects examples based on similarity to the inputs. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs."),(0,o.kt)(s,{mdxType:"Example"}))}g.isMDXComponent=!0}}]);