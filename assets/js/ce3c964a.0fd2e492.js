"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[72e3],{3905:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>f});var n=r(67294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function s(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function i(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var l=n.createContext({}),u=function(e){var t=n.useContext(l),r=t;return e&&(r="function"==typeof e?e(t):s(s({},t),e)),r},c=function(e){var t=u(e.components);return n.createElement(l.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),p=u(r),d=o,f=p["".concat(l,".").concat(d)]||p[d]||m[d]||a;return r?n.createElement(f,s(s({ref:t},c),{},{components:r})):n.createElement(f,s({ref:t},c))}));function f(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=r.length,s=new Array(a);s[0]=d;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[p]="string"==typeof e?e:o,s[1]=i;for(var u=2;u<a;u++)s[u]=r[u];return n.createElement.apply(null,s)}return n.createElement.apply(null,r)}d.displayName="MDXCreateElement"},59984:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>f,frontMatter:()=>a,metadata:()=>i,toc:()=>u});var n=r(87462),o=(r(67294),r(3905));const a={},s="Multiple Retrieval Sources",i={unversionedId:"use_cases/question_answering/how_to/multiple_retrieval",id:"use_cases/question_answering/how_to/multiple_retrieval",title:"Multiple Retrieval Sources",description:"Often times you may want to do retrieval over multiple sources. These can be different vectorstores (where one contains information about topic X and the other contains info about topic Y). They could also be completely different databases altogether!",source:"@site/docs/use_cases/question_answering/how_to/multiple_retrieval.md",sourceDirName:"use_cases/question_answering/how_to",slug:"/use_cases/question_answering/how_to/multiple_retrieval",permalink:"/langchain/docs/use_cases/question_answering/how_to/multiple_retrieval",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"use_cases",previous:{title:"Dynamically select from multiple retrievers",permalink:"/langchain/docs/use_cases/question_answering/how_to/multi_retrieval_qa_router"},next:{title:"Cite sources",permalink:"/langchain/docs/use_cases/question_answering/how_to/qa_citations"}},l={},u=[{value:"Set up SQL query",id:"set-up-sql-query",level:2},{value:"Set up vectorstore",id:"set-up-vectorstore",level:2},{value:"Combine",id:"combine",level:2}],c=(p="CodeOutputBlock",function(e){return console.warn("Component "+p+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var p;const m={toc:u},d="wrapper";function f(e){let{components:t,...r}=e;return(0,o.kt)(d,(0,n.Z)({},m,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"multiple-retrieval-sources"},"Multiple Retrieval Sources"),(0,o.kt)("p",null,"Often times you may want to do retrieval over multiple sources. These can be different vectorstores (where one contains information about topic X and the other contains info about topic Y). They could also be completely different databases altogether!"),(0,o.kt)("p",null,"A key part is is doing as much of the retrieval in parrelel as possible. This will keep the latency as low as possible. Luckily, ",(0,o.kt)("a",{parentName:"p",href:"../../"},"LangChain Expression Language")," supports parrellism out of the box."),(0,o.kt)("p",null,"Let's take a look where we do retrieval over a SQL database and a vectorstore."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from langchain.chat_models import ChatOpenAI\n")),(0,o.kt)("h2",{id:"set-up-sql-query"},"Set up SQL query"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.utilities import SQLDatabase\nfrom langchain.chains import create_sql_query_chain\n\ndb = SQLDatabase.from_uri("sqlite:///../../../../../notebooks/Chinook.db")\nquery_chain = create_sql_query_chain(ChatOpenAI(temperature=0), db)\n')),(0,o.kt)("h2",{id:"set-up-vectorstore"},"Set up vectorstore"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.indexes import VectorstoreIndexCreator\nfrom langchain.schema.document import Document\nindex_creator = VectorstoreIndexCreator()\nindex = index_creator.from_documents([Document(page_content="Foo")])\nretriever = index.vectorstore.as_retriever()\n')),(0,o.kt)("h2",{id:"combine"},"Combine"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.prompts import ChatPromptTemplate\n\nsystem_message = """Use the information from the below two sources to answer any questions.\n\nSource 1: a SQL database about employee data\n<source1>\n{source1}\n</source1>\n\nSource 2: a text database of random information\n<source2>\n{source2}\n</source2>\n"""\n\nprompt = ChatPromptTemplate.from_messages([("system", system_message), ("human", "{question}")])\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'full_chain = {\n    "source1": {"question": lambda x: x["question"]} | query_chain | db.run,\n    "source2": (lambda x: x[\'question\']) | retriever,\n    "question": lambda x: x[\'question\'],\n} | prompt | ChatOpenAI()\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'response = full_chain.invoke({"question":"How many Employees are there"})\nprint(response)\n')),(0,o.kt)(c,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n\n\n    content='There are 8 employees.' additional_kwargs={} example=False\n"))))}f.isMDXComponent=!0}}]);