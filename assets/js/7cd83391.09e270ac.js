"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[63191],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>h});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),s=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=s(e.components);return a.createElement(l.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},y=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,u=c(e,["components","mdxType","originalType","parentName"]),p=s(n),y=r,h=p["".concat(l,".").concat(y)]||p[y]||m[y]||o;return n?a.createElement(h,i(i({ref:t},u),{},{components:n})):a.createElement(h,i({ref:t},u))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=y;var c={};for(var l in t)hasOwnProperty.call(t,l)&&(c[l]=t[l]);c.originalType=e,c[p]="string"==typeof e?e:r,i[1]=c;for(var s=2;s<o;s++)i[s]=n[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}y.displayName="MDXCreateElement"},17377:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>c,toc:()=>s});var a=n(87462),r=(n(67294),n(3905));const o={},i="Custom Trajectory Evaluator",c={unversionedId:"guides/evaluation/trajectory/custom",id:"guides/evaluation/trajectory/custom",title:"Custom Trajectory Evaluator",description:"You can make your own custom trajectory evaluators by inheriting from the AgentTrajectoryEvaluator class and overwriting the evaluateagenttrajectory (and aevaluateagentaction) method.",source:"@site/docs/guides/evaluation/trajectory/custom.md",sourceDirName:"guides/evaluation/trajectory",slug:"/guides/evaluation/trajectory/custom",permalink:"/langchain/docs/guides/evaluation/trajectory/custom",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Trajectory Evaluators",permalink:"/langchain/docs/guides/evaluation/trajectory/"},next:{title:"Agent Trajectory",permalink:"/langchain/docs/guides/evaluation/trajectory/trajectory_eval"}},l={},s=[],u=(p="CodeOutputBlock",function(e){return console.warn("Component "+p+" was not imported, exported, or provided by MDXProvider as global scope"),(0,r.kt)("div",e)});var p;const m={toc:s},y="wrapper";function h(e){let{components:t,...n}=e;return(0,r.kt)(y,(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"custom-trajectory-evaluator"},"Custom Trajectory Evaluator"),(0,r.kt)("p",null,"You can make your own custom trajectory evaluators by inheriting from the ",(0,r.kt)("a",{parentName:"p",href:"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.AgentTrajectoryEvaluator.html#langchain.evaluation.schema.AgentTrajectoryEvaluator"},"AgentTrajectoryEvaluator")," class and overwriting the ",(0,r.kt)("inlineCode",{parentName:"p"},"_evaluate_agent_trajectory")," (and ",(0,r.kt)("inlineCode",{parentName:"p"},"_aevaluate_agent_action"),") method."),(0,r.kt)("p",null,"In this example, you will make a simple trajectory evaluator that uses an LLM to determine if any actions were unnecessary."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "ChatOpenAI", "source": "langchain.chat_models", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html", "title": "Custom Trajectory Evaluator"}, {"imported": "LLMChain", "source": "langchain.chains", "docs": "https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html", "title": "Custom Trajectory Evaluator"}, {"imported": "AgentAction", "source": "langchain.schema", "docs": "https://api.python.langchain.com/en/latest/schema/langchain.schema.agent.AgentAction.html", "title": "Custom Trajectory Evaluator"}, {"imported": "AgentTrajectoryEvaluator", "source": "langchain.evaluation", "docs": "https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.AgentTrajectoryEvaluator.html", "title": "Custom Trajectory Evaluator"}]--\x3e\nfrom typing import Any, Optional, Sequence, Tuple\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import LLMChain\nfrom langchain.schema import AgentAction\nfrom langchain.evaluation import AgentTrajectoryEvaluator\n\n\nclass StepNecessityEvaluator(AgentTrajectoryEvaluator):\n    """Evaluate the perplexity of a predicted string."""\n\n    def __init__(self) -> None:\n        llm = ChatOpenAI(model="gpt-4", temperature=0.0)\n        template = """Are any of the following steps unnecessary in answering {input}? Provide the verdict on a new line as a single "Y" for yes or "N" for no.\n\n        DATA\n        ------\n        Steps: {trajectory}\n        ------\n\n        Verdict:"""\n        self.chain = LLMChain.from_string(llm, template)\n\n    def _evaluate_agent_trajectory(\n        self,\n        *,\n        prediction: str,\n        input: str,\n        agent_trajectory: Sequence[Tuple[AgentAction, str]],\n        reference: Optional[str] = None,\n        **kwargs: Any,\n    ) -> dict:\n        vals = [\n            f"{i}: Action=[{action.tool}] returned observation = [{observation}]"\n            for i, (action, observation) in enumerate(agent_trajectory)\n        ]\n        trajectory = "\\n".join(vals)\n        response = self.chain.run(dict(trajectory=trajectory, input=input), **kwargs)\n        decision = response.split("\\n")[-1].strip()\n        score = 1 if decision == "Y" else 0\n        return {"score": score, "value": decision, "reasoning": response}\n')),(0,r.kt)("p",null,"The example above will return a score of 1 if the language model predicts that any of the actions were unnecessary, and it returns a score of 0 if all of them were predicted to be necessary. It returns the string 'decision' as the 'value', and includes the rest of the generated text as 'reasoning' to let you audit the decision."),(0,r.kt)("p",null,"You can call this evaluator to grade the intermediate steps of your agent's trajectory."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'evaluator = StepNecessityEvaluator()\n\nevaluator.evaluate_agent_trajectory(\n    prediction="The answer is pi",\n    input="What is today?",\n    agent_trajectory=[\n        (\n            AgentAction(tool="ask", tool_input="What is today?", log=""),\n            "tomorrow\'s yesterday",\n        ),\n        (\n            AgentAction(tool="check_tv", tool_input="Watch tv for half hour", log=""),\n            "bzzz",\n        ),\n    ],\n)\n')),(0,r.kt)(u,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    {'score': 1, 'value': 'Y', 'reasoning': 'Y'}\n"))))}h.isMDXComponent=!0}}]);