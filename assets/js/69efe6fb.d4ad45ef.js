"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[13882],{3905:(e,n,t)=>{t.d(n,{Zo:()=>p,kt:()=>g});var l=t(67294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);n&&(l=l.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,l)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,l,o=function(e,n){if(null==e)return{};var t,l,o={},a=Object.keys(e);for(l=0;l<a.length;l++)t=a[l],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(l=0;l<a.length;l++)t=a[l],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var s=l.createContext({}),m=function(e){var n=l.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},p=function(e){var n=m(e.components);return l.createElement(s.Provider,{value:n},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return l.createElement(l.Fragment,{},n)}},u=l.forwardRef((function(e,n){var t=e.components,o=e.mdxType,a=e.originalType,s=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),c=m(t),u=o,g=c["".concat(s,".").concat(u)]||c[u]||d[u]||a;return t?l.createElement(g,r(r({ref:n},p),{},{components:t})):l.createElement(g,r({ref:n},p))}));function g(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var a=t.length,r=new Array(a);r[0]=u;var i={};for(var s in n)hasOwnProperty.call(n,s)&&(i[s]=n[s]);i.originalType=e,i[c]="string"==typeof e?e:o,r[1]=i;for(var m=2;m<a;m++)r[m]=t[m];return l.createElement.apply(null,r)}return l.createElement.apply(null,t)}u.displayName="MDXCreateElement"},33944:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>r,default:()=>g,frontMatter:()=>a,metadata:()=>i,toc:()=>m});var l=t(87462),o=(t(67294),t(3905));const a={},r="Serialization",i={unversionedId:"modules/model_io/models/llms/llm_serialization",id:"modules/model_io/models/llms/llm_serialization",title:"Serialization",description:"This notebook walks through how to write and read an LLM Configuration to and from disk. This is useful if you want to save the configuration for a given LLM (e.g., the provider, the temperature, etc).",source:"@site/docs/modules/model_io/models/llms/llm_serialization.md",sourceDirName:"modules/model_io/models/llms",slug:"/modules/model_io/models/llms/llm_serialization",permalink:"/langchain/docs/modules/model_io/models/llms/llm_serialization",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Caching",permalink:"/langchain/docs/modules/model_io/models/llms/llm_caching"},next:{title:"Streaming",permalink:"/langchain/docs/modules/model_io/models/llms/streaming_llm"}},s={},m=[{value:"Loading",id:"loading",level:2},{value:"Saving",id:"saving",level:2}],p=(c="CodeOutputBlock",function(e){return console.warn("Component "+c+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var c;const d={toc:m},u="wrapper";function g(e){let{components:n,...t}=e;return(0,o.kt)(u,(0,l.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"serialization"},"Serialization"),(0,o.kt)("p",null,"This notebook walks through how to write and read an LLM Configuration to and from disk. This is useful if you want to save the configuration for a given LLM (e.g., the provider, the temperature, etc)."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "OpenAI", "source": "langchain.llms", "docs": "https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html", "title": "Serialization"}, {"imported": "load_llm", "source": "langchain.llms.loading", "docs": "https://api.python.langchain.com/en/latest/llms/langchain.llms.loading.load_llm.html", "title": "Serialization"}]--\x3e\nfrom langchain.llms import OpenAI\nfrom langchain.llms.loading import load_llm\n')),(0,o.kt)("h2",{id:"loading"},"Loading"),(0,o.kt)("p",null,"First, lets go over loading an LLM from disk. LLMs can be saved on disk in two formats: json or yaml. No matter the extension, they are loaded in the same way."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"cat llm.json\n")),(0,o.kt)(p,{lang:"bash",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'    {\n        "model_name": "text-davinci-003",\n        "temperature": 0.7,\n        "max_tokens": 256,\n        "top_p": 1.0,\n        "frequency_penalty": 0.0,\n        "presence_penalty": 0.0,\n        "n": 1,\n        "best_of": 1,\n        "request_timeout": null,\n        "_type": "openai"\n    }\n'))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'llm = load_llm("llm.json")\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"cat llm.yaml\n")),(0,o.kt)(p,{lang:"bash",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    _type: openai\n    best_of: 1\n    frequency_penalty: 0.0\n    max_tokens: 256\n    model_name: text-davinci-003\n    n: 1\n    presence_penalty: 0.0\n    request_timeout: null\n    temperature: 0.7\n    top_p: 1.0\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'llm = load_llm("llm.yaml")\n')),(0,o.kt)("h2",{id:"saving"},"Saving"),(0,o.kt)("p",null,"If you want to go from an LLM in memory to a serialized version of it, you can do so easily by calling the ",(0,o.kt)("inlineCode",{parentName:"p"},".save")," method. Again, this supports both json and yaml."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'llm.save("llm.json")\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'llm.save("llm.yaml")\n')))}g.isMDXComponent=!0}}]);