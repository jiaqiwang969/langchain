"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9977],{3905:(e,t,n)=>{n.d(t,{Zo:()=>i,kt:()=>g});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function p(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):p(p({},t),e)),n},i=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,i=l(e,["components","mdxType","originalType","parentName"]),u=c(n),m=o,g=u["".concat(s,".").concat(m)]||u[m]||d[m]||r;return n?a.createElement(g,p(p({ref:t},i),{},{components:n})):a.createElement(g,p({ref:t},i))}));function g(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,p=new Array(r);p[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[u]="string"==typeof e?e:o,p[1]=l;for(var c=2;c<r;c++)p[c]=n[c];return a.createElement.apply(null,p)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},80726:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>p,default:()=>g,frontMatter:()=>r,metadata:()=>l,toc:()=>c});var a=n(87462),o=(n(67294),n(3905));const r={},p="OpenAI Adapter",l={unversionedId:"guides/adapters/openai",id:"guides/adapters/openai",title:"OpenAI Adapter",description:"A lot of people get started with OpenAI but want to explore other models. LangChain's integrations with many model providers make this easy to do so. While LangChain has it's own message and model APIs, we've also made it as easy as possible to explore other models by exposing an adapter to adapt LangChain models to the OpenAI api.",source:"@site/docs/guides/adapters/openai.md",sourceDirName:"guides/adapters",slug:"/guides/adapters/openai",permalink:"/langchain/docs/guides/adapters/openai",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Guides",permalink:"/langchain/docs/guides"},next:{title:"Debugging",permalink:"/langchain/docs/guides/debugging"}},s={},c=[{value:"ChatCompletion.create",id:"chatcompletioncreate",level:2},{value:"ChatCompletion.stream",id:"chatcompletionstream",level:2}],i=(u="CodeOutputBlock",function(e){return console.warn("Component "+u+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var u;const d={toc:c},m="wrapper";function g(e){let{components:t,...n}=e;return(0,o.kt)(m,(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"openai-adapter"},"OpenAI Adapter"),(0,o.kt)("p",null,"A lot of people get started with OpenAI but want to explore other models. LangChain's integrations with many model providers make this easy to do so. While LangChain has it's own message and model APIs, we've also made it as easy as possible to explore other models by exposing an adapter to adapt LangChain models to the OpenAI api."),(0,o.kt)("p",null,"At the moment this only deals with output and does not return other information (token counts, stop reasons, etc)."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "openai", "source": "langchain.adapters", "docs": "https://api.python.langchain.com/en/latest/adapters/langchain.adapters.openai.openai.html", "title": "OpenAI Adapter"}]--\x3e\nimport openai\nfrom langchain.adapters import openai as lc_openai\n')),(0,o.kt)("h2",{id:"chatcompletioncreate"},"ChatCompletion.create"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'messages = [{"role": "user", "content": "hi"}]\n')),(0,o.kt)("p",null,"Original OpenAI call"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'result = openai.ChatCompletion.create(\n    messages=messages, \n    model="gpt-3.5-turbo", \n    temperature=0\n)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"result[\"choices\"][0]['message'].to_dict_recursive()\n")),(0,o.kt)(i,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}\n"))),(0,o.kt)("p",null,"LangChain OpenAI wrapper call"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'lc_result = lc_openai.ChatCompletion.create(\n    messages=messages, \n    model="gpt-3.5-turbo", \n    temperature=0\n)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"lc_result[\"choices\"][0]['message']\n")),(0,o.kt)(i,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}\n"))),(0,o.kt)("p",null,"Swapping out model providers"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'lc_result = lc_openai.ChatCompletion.create(\n    messages=messages, \n    model="claude-2", \n    temperature=0, \n    provider="ChatAnthropic"\n)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"lc_result[\"choices\"][0]['message']\n")),(0,o.kt)(i,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'role': 'assistant', 'content': ' Hello!'}\n"))),(0,o.kt)("h2",{id:"chatcompletionstream"},"ChatCompletion.stream"),(0,o.kt)("p",null,"Original OpenAI call"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'for c in openai.ChatCompletion.create(\n    messages = messages,\n    model="gpt-3.5-turbo", \n    temperature=0,\n    stream=True\n):\n    print(c["choices"][0][\'delta\'].to_dict_recursive())\n')),(0,o.kt)(i,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'role': 'assistant', 'content': ''}\n    {'content': 'Hello'}\n    {'content': '!'}\n    {'content': ' How'}\n    {'content': ' can'}\n    {'content': ' I'}\n    {'content': ' assist'}\n    {'content': ' you'}\n    {'content': ' today'}\n    {'content': '?'}\n    {}\n"))),(0,o.kt)("p",null,"LangChain OpenAI wrapper call"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'for c in lc_openai.ChatCompletion.create(\n    messages = messages,\n    model="gpt-3.5-turbo", \n    temperature=0,\n    stream=True\n):\n    print(c["choices"][0][\'delta\'])\n')),(0,o.kt)(i,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'role': 'assistant', 'content': ''}\n    {'content': 'Hello'}\n    {'content': '!'}\n    {'content': ' How'}\n    {'content': ' can'}\n    {'content': ' I'}\n    {'content': ' assist'}\n    {'content': ' you'}\n    {'content': ' today'}\n    {'content': '?'}\n    {}\n"))),(0,o.kt)("p",null,"Swapping out model providers"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'for c in lc_openai.ChatCompletion.create(\n    messages = messages,\n    model="claude-2", \n    temperature=0,\n    stream=True,\n    provider="ChatAnthropic",\n):\n    print(c["choices"][0][\'delta\'])\n')),(0,o.kt)(i,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'role': 'assistant', 'content': ' Hello'}\n    {'content': '!'}\n    {}\n"))))}g.isMDXComponent=!0}}]);