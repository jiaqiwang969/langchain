"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[66943],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>h});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),p=c(n),m=o,h=p["".concat(l,".").concat(m)]||p[m]||u[m]||r;return n?a.createElement(h,i(i({ref:t},d),{},{components:n})):a.createElement(h,i({ref:t},d))}));function h(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[p]="string"==typeof e?e:o,i[1]=s;for(var c=2;c<r;c++)i[c]=n[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},17271:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var a=n(87462),o=(n(67294),n(3905));const r={},i="Faiss",s={unversionedId:"integrations/vectorstores/faiss",id:"integrations/vectorstores/faiss",title:"Faiss",description:"Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning.",source:"@site/docs/integrations/vectorstores/faiss.md",sourceDirName:"integrations/vectorstores",slug:"/integrations/vectorstores/faiss",permalink:"/langchain/docs/integrations/vectorstores/faiss",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"Epsilla",permalink:"/langchain/docs/integrations/vectorstores/epsilla"},next:{title:"Hologres",permalink:"/langchain/docs/integrations/vectorstores/hologres"}},l={},c=[{value:"Similarity Search with score",id:"similarity-search-with-score",level:2},{value:"Saving and loading",id:"saving-and-loading",level:2},{value:"Merging",id:"merging",level:2},{value:"Similarity Search with filtering",id:"similarity-search-with-filtering",level:2},{value:"Delete",id:"delete",level:2}],d=(p="CodeOutputBlock",function(e){return console.warn("Component "+p+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var p;const u={toc:c},m="wrapper";function h(e){let{components:t,...n}=e;return(0,o.kt)(m,(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"faiss"},"Faiss"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("a",{parentName:"p",href:"https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/"},"Facebook AI Similarity Search (Faiss)")," is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning.")),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://faiss.ai/"},"Faiss documentation"),"."),(0,o.kt)("p",null,"This notebook shows how to use functionality related to the ",(0,o.kt)("inlineCode",{parentName:"p"},"FAISS")," vector database."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"pip install faiss-gpu # For CUDA 7.5+ Supported GPU's.\n# OR\npip install faiss-cpu # For CPU Installation\n")),(0,o.kt)("p",null,"We want to use OpenAIEmbeddings so we have to get the OpenAI API Key. "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"import os\nimport getpass\n\nos.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n\n# Uncomment the following line if you need to initialize FAISS with no AVX2 optimization\n# os.environ['FAISS_NO_AVX2'] = '1'\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "OpenAIEmbeddings", "source": "langchain.embeddings.openai", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html", "title": "Faiss"}, {"imported": "CharacterTextSplitter", "source": "langchain.text_splitter", "docs": "https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.CharacterTextSplitter.html", "title": "Faiss"}, {"imported": "FAISS", "source": "langchain.vectorstores", "docs": "https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.faiss.FAISS.html", "title": "Faiss"}, {"imported": "TextLoader", "source": "langchain.document_loaders", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.text.TextLoader.html", "title": "Faiss"}]--\x3e\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import FAISS\nfrom langchain.document_loaders import TextLoader\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "TextLoader", "source": "langchain.document_loaders", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.text.TextLoader.html", "title": "Faiss"}]--\x3e\nfrom langchain.document_loaders import TextLoader\n\nloader = TextLoader("../../../extras/modules/state_of_the_union.txt")\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocs = text_splitter.split_documents(documents)\n\nembeddings = OpenAIEmbeddings()\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'db = FAISS.from_documents(docs, embeddings)\n\nquery = "What did the president say about Ketanji Brown Jackson"\ndocs = db.similarity_search(query)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"print(docs[0].page_content)\n")),(0,o.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \n    \n    Tonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n    \n    One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n    \n    And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.\n"))),(0,o.kt)("h2",{id:"similarity-search-with-score"},"Similarity Search with score"),(0,o.kt)("p",null,"There are some FAISS specific methods. One of them is ",(0,o.kt)("inlineCode",{parentName:"p"},"similarity_search_with_score"),", which allows you to return not only the documents but also the distance score of the query to them. The returned distance score is L2 distance. Therefore, a lower score is better."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"docs_and_scores = db.similarity_search_with_score(query)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"docs_and_scores[0]\n")),(0,o.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    (Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.', metadata={'source': '../../../state_of_the_union.txt'}),\n     0.36913747)\n"))),(0,o.kt)("p",null,"It is also possible to do a search for documents similar to a given embedding vector using ",(0,o.kt)("inlineCode",{parentName:"p"},"similarity_search_by_vector")," which accepts an embedding vector as a parameter instead of a string."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"embedding_vector = embeddings.embed_query(query)\ndocs_and_scores = db.similarity_search_by_vector(embedding_vector)\n")),(0,o.kt)("h2",{id:"saving-and-loading"},"Saving and loading"),(0,o.kt)("p",null,"You can also save and load a FAISS index. This is useful so you don't have to recreate it everytime you use it."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'db.save_local("faiss_index")\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'new_db = FAISS.load_local("faiss_index", embeddings)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"docs = new_db.similarity_search(query)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"docs[0]\n")),(0,o.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Document(page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you\u2019re at it, pass the Disclose Act so Americans can know who is funding our elections. \\n\\nTonight, I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer\u2014an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation\u2019s top legal minds, who will continue Justice Breyer\u2019s legacy of excellence.', metadata={'source': '../../../state_of_the_union.txt'})\n"))),(0,o.kt)("h1",{id:"serializing-and-de-serializing-to-bytes"},"Serializing and De-Serializing to bytes"),(0,o.kt)("p",null,"you can pickle the FAISS Index by these functions. If you use embeddings model which is of 90 mb (sentence-transformers/all-MiniLM-L6-v2 or any other model), the resultant pickle size would be more than 90 mb. the size of the model is also included in the overall size. To overcome this, use the below functions. These functions only serializes FAISS index and size would be much lesser. this can be helpful if you wish to store the index in database like sql."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"pkl = db.serialize_to_bytes() # serializes the faiss index\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"db = FAISS.deserialize_from_bytes(embeddings = embeddings, serialized = pkl) # Load the index\n")),(0,o.kt)("h2",{id:"merging"},"Merging"),(0,o.kt)("p",null,"You can also merge two FAISS vectorstores"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'db1 = FAISS.from_texts(["foo"], embeddings)\ndb2 = FAISS.from_texts(["bar"], embeddings)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"db1.docstore._dict\n")),(0,o.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'068c473b-d420-487a-806b-fb0ccea7f711': Document(page_content='foo', metadata={})}\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"db2.docstore._dict\n")),(0,o.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'807e0c63-13f6-4070-9774-5c6f0fbb9866': Document(page_content='bar', metadata={})}\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"db1.merge_from(db2)\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"db1.docstore._dict\n")),(0,o.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'068c473b-d420-487a-806b-fb0ccea7f711': Document(page_content='foo', metadata={}),\n     '807e0c63-13f6-4070-9774-5c6f0fbb9866': Document(page_content='bar', metadata={})}\n"))),(0,o.kt)("h2",{id:"similarity-search-with-filtering"},"Similarity Search with filtering"),(0,o.kt)("p",null,"FAISS vectorstore can also support filtering, since the FAISS does not natively support filtering we have to do it manually. This is done by first fetching more results than ",(0,o.kt)("inlineCode",{parentName:"p"},"k")," and then filtering them. You can filter the documents based on metadata. You can also set the ",(0,o.kt)("inlineCode",{parentName:"p"},"fetch_k")," parameter when calling any search method to set how many documents you want to fetch before filtering. Here is a small example:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "Document", "source": "langchain.schema", "docs": "https://api.python.langchain.com/en/latest/schema/langchain.schema.document.Document.html", "title": "Faiss"}]--\x3e\nfrom langchain.schema import Document\n\nlist_of_documents = [\n    Document(page_content="foo", metadata=dict(page=1)),\n    Document(page_content="bar", metadata=dict(page=1)),\n    Document(page_content="foo", metadata=dict(page=2)),\n    Document(page_content="barbar", metadata=dict(page=2)),\n    Document(page_content="foo", metadata=dict(page=3)),\n    Document(page_content="bar burr", metadata=dict(page=3)),\n    Document(page_content="foo", metadata=dict(page=4)),\n    Document(page_content="bar bruh", metadata=dict(page=4)),\n]\ndb = FAISS.from_documents(list_of_documents, embeddings)\nresults_with_scores = db.similarity_search_with_score("foo")\nfor doc, score in results_with_scores:\n    print(f"Content: {doc.page_content}, Metadata: {doc.metadata}, Score: {score}")\n')),(0,o.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Content: foo, Metadata: {'page': 1}, Score: 5.159960813797904e-15\n    Content: foo, Metadata: {'page': 2}, Score: 5.159960813797904e-15\n    Content: foo, Metadata: {'page': 3}, Score: 5.159960813797904e-15\n    Content: foo, Metadata: {'page': 4}, Score: 5.159960813797904e-15\n"))),(0,o.kt)("p",null,"Now we make the same query call but we filter for only ",(0,o.kt)("inlineCode",{parentName:"p"},"page = 1")," "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'results_with_scores = db.similarity_search_with_score("foo", filter=dict(page=1))\nfor doc, score in results_with_scores:\n    print(f"Content: {doc.page_content}, Metadata: {doc.metadata}, Score: {score}")\n')),(0,o.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Content: foo, Metadata: {'page': 1}, Score: 5.159960813797904e-15\n    Content: bar, Metadata: {'page': 1}, Score: 0.3131446838378906\n"))),(0,o.kt)("p",null,"Same thing can be done with the ",(0,o.kt)("inlineCode",{parentName:"p"},"max_marginal_relevance_search")," as well."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'results = db.max_marginal_relevance_search("foo", filter=dict(page=1))\nfor doc in results:\n    print(f"Content: {doc.page_content}, Metadata: {doc.metadata}")\n')),(0,o.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Content: foo, Metadata: {'page': 1}\n    Content: bar, Metadata: {'page': 1}\n"))),(0,o.kt)("p",null,"Here is an example of how to set ",(0,o.kt)("inlineCode",{parentName:"p"},"fetch_k")," parameter when calling ",(0,o.kt)("inlineCode",{parentName:"p"},"similarity_search"),". Usually you would want the ",(0,o.kt)("inlineCode",{parentName:"p"},"fetch_k")," parameter >> ",(0,o.kt)("inlineCode",{parentName:"p"},"k")," parameter. This is because the ",(0,o.kt)("inlineCode",{parentName:"p"},"fetch_k")," parameter is the number of documents that will be fetched before filtering. If you set ",(0,o.kt)("inlineCode",{parentName:"p"},"fetch_k")," to a low number, you might not get enough documents to filter from."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'results = db.similarity_search("foo", filter=dict(page=1), k=1, fetch_k=4)\nfor doc in results:\n    print(f"Content: {doc.page_content}, Metadata: {doc.metadata}")\n')),(0,o.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    Content: foo, Metadata: {'page': 1}\n"))),(0,o.kt)("h2",{id:"delete"},"Delete"),(0,o.kt)("p",null,"You can also delete ids. Note that the ids to delete should be the ids in the docstore."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"db.delete([db.index_to_docstore_id[0]])\n")),(0,o.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    True\n"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"# Is now missing\n0 in db.index_to_docstore_id\n")),(0,o.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    False\n"))))}h.isMDXComponent=!0}}]);