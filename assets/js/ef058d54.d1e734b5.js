"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[22700],{3905:(t,e,a)=>{a.d(e,{Zo:()=>p,kt:()=>d});var n=a(67294);function l(t,e,a){return e in t?Object.defineProperty(t,e,{value:a,enumerable:!0,configurable:!0,writable:!0}):t[e]=a,t}function o(t,e){var a=Object.keys(t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(t);e&&(n=n.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),a.push.apply(a,n)}return a}function c(t){for(var e=1;e<arguments.length;e++){var a=null!=arguments[e]?arguments[e]:{};e%2?o(Object(a),!0).forEach((function(e){l(t,e,a[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(a,e))}))}return t}function r(t,e){if(null==t)return{};var a,n,l=function(t,e){if(null==t)return{};var a,n,l={},o=Object.keys(t);for(n=0;n<o.length;n++)a=o[n],e.indexOf(a)>=0||(l[a]=t[a]);return l}(t,e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(t);for(n=0;n<o.length;n++)a=o[n],e.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(t,a)&&(l[a]=t[a])}return l}var s=n.createContext({}),i=function(t){var e=n.useContext(s),a=e;return t&&(a="function"==typeof t?t(e):c(c({},e),t)),a},p=function(t){var e=i(t.components);return n.createElement(s.Provider,{value:e},t.children)},h="mdxType",m={inlineCode:"code",wrapper:function(t){var e=t.children;return n.createElement(n.Fragment,{},e)}},u=n.forwardRef((function(t,e){var a=t.components,l=t.mdxType,o=t.originalType,s=t.parentName,p=r(t,["components","mdxType","originalType","parentName"]),h=i(a),u=l,d=h["".concat(s,".").concat(u)]||h[u]||m[u]||o;return a?n.createElement(d,c(c({ref:e},p),{},{components:a})):n.createElement(d,c({ref:e},p))}));function d(t,e){var a=arguments,l=e&&e.mdxType;if("string"==typeof t||l){var o=a.length,c=new Array(o);c[0]=u;var r={};for(var s in e)hasOwnProperty.call(e,s)&&(r[s]=e[s]);r.originalType=t,r[h]="string"==typeof t?t:l,c[1]=r;for(var i=2;i<o;i++)c[i]=a[i];return n.createElement.apply(null,c)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},28699:(t,e,a)=>{a.r(e),a.d(e,{assets:()=>s,contentTitle:()=>c,default:()=>m,frontMatter:()=>o,metadata:()=>r,toc:()=>i});var n=a(87462),l=(a(67294),a(3905));const o={},c="Context",r={unversionedId:"integrations/callbacks/context",id:"integrations/callbacks/context",title:"Context",description:"Context - User Analytics for LLM Powered Products",source:"@site/docs/integrations/callbacks/context.md",sourceDirName:"integrations/callbacks",slug:"/integrations/callbacks/context",permalink:"/langchain/docs/integrations/callbacks/context",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"Argilla",permalink:"/langchain/docs/integrations/callbacks/argilla"},next:{title:"Infino",permalink:"/langchain/docs/integrations/callbacks/infino"}},s={},i=[{value:"Installation and Setup",id:"installation-and-setup",level:2},{value:"Getting API Credentials",id:"getting-api-credentials",level:3},{value:"Setup Context",id:"setup-context",level:3},{value:"Usage",id:"usage",level:2},{value:"Using the Context callback within a chat model",id:"using-the-context-callback-within-a-chat-model",level:3},{value:"Example",id:"example",level:4},{value:"Using the Context callback within Chains",id:"using-the-context-callback-within-chains",level:3},{value:"Example",id:"example-1",level:4}],p={toc:i},h="wrapper";function m(t){let{components:e,...a}=t;return(0,l.kt)(h,(0,n.Z)({},p,a,{components:e,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"context"},"Context"),(0,l.kt)("p",null,(0,l.kt)("img",{parentName:"p",src:"https://with.context.ai/langchain.png",alt:"Context - User Analytics for LLM Powered Products"})),(0,l.kt)("p",null,(0,l.kt)("a",{parentName:"p",href:"https://context.ai/"},"Context")," provides user analytics for LLM powered products and features."),(0,l.kt)("p",null,"With Context, you can start understanding your users and improving their experiences in less than 30 minutes."),(0,l.kt)("p",null,"In this guide we will show you how to integrate with Context."),(0,l.kt)("h2",{id:"installation-and-setup"},"Installation and Setup"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"$ pip install context-python --upgrade\n")),(0,l.kt)("h3",{id:"getting-api-credentials"},"Getting API Credentials"),(0,l.kt)("p",null,"To get your Context API token:"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"Go to the settings page within your Context account (",(0,l.kt)("a",{parentName:"li",href:"https://with.context.ai/settings"},"https://with.context.ai/settings"),")."),(0,l.kt)("li",{parentName:"ol"},"Generate a new API Token."),(0,l.kt)("li",{parentName:"ol"},"Store this token somewhere secure.")),(0,l.kt)("h3",{id:"setup-context"},"Setup Context"),(0,l.kt)("p",null,"To use the ",(0,l.kt)("inlineCode",{parentName:"p"},"ContextCallbackHandler"),", import the handler from Langchain and instantiate it with your Context API token."),(0,l.kt)("p",null,"Ensure you have installed the ",(0,l.kt)("inlineCode",{parentName:"p"},"context-python")," package before using the handler."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "ContextCallbackHandler", "source": "langchain.callbacks", "docs": "https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.context_callback.ContextCallbackHandler.html", "title": "Context"}]--\x3e\nimport os\n\nfrom langchain.callbacks import ContextCallbackHandler\n\ntoken = os.environ["CONTEXT_API_TOKEN"]\n\ncontext_callback = ContextCallbackHandler(token)\n')),(0,l.kt)("h2",{id:"usage"},"Usage"),(0,l.kt)("h3",{id:"using-the-context-callback-within-a-chat-model"},"Using the Context callback within a chat model"),(0,l.kt)("p",null,"The Context callback handler can be used to directly record transcripts between users and AI assistants."),(0,l.kt)("h4",{id:"example"},"Example"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "ChatOpenAI", "source": "langchain.chat_models", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html", "title": "Context"}, {"imported": "SystemMessage", "source": "langchain.schema", "docs": "https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.SystemMessage.html", "title": "Context"}, {"imported": "HumanMessage", "source": "langchain.schema", "docs": "https://api.python.langchain.com/en/latest/schema/langchain.schema.messages.HumanMessage.html", "title": "Context"}, {"imported": "ContextCallbackHandler", "source": "langchain.callbacks", "docs": "https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.context_callback.ContextCallbackHandler.html", "title": "Context"}]--\x3e\nimport os\n\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema import (\n    SystemMessage,\n    HumanMessage,\n)\nfrom langchain.callbacks import ContextCallbackHandler\n\ntoken = os.environ["CONTEXT_API_TOKEN"]\n\nchat = ChatOpenAI(\n    headers={"user_id": "123"}, temperature=0, callbacks=[ContextCallbackHandler(token)]\n)\n\nmessages = [\n    SystemMessage(\n        content="You are a helpful assistant that translates English to French."\n    ),\n    HumanMessage(content="I love programming."),\n]\n\nprint(chat(messages))\n')),(0,l.kt)("h3",{id:"using-the-context-callback-within-chains"},"Using the Context callback within Chains"),(0,l.kt)("p",null,"The Context callback handler can also be used to record the inputs and outputs of chains. Note that intermediate steps of the chain are not recorded - only the starting inputs and final outputs."),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Note:")," Ensure that you pass the same context object to the chat model and the chain."),(0,l.kt)("p",null,"Wrong:"),(0,l.kt)("blockquote",null,(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},"chat = ChatOpenAI(temperature=0.9, callbacks=[ContextCallbackHandler(token)])\nchain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[ContextCallbackHandler(token)])\n"))),(0,l.kt)("p",null,"Correct:"),(0,l.kt)("blockquote",null,(0,l.kt)("pre",{parentName:"blockquote"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},"handler = ContextCallbackHandler(token)\nchat = ChatOpenAI(temperature=0.9, callbacks=[callback])\nchain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])\n"))),(0,l.kt)("h4",{id:"example-1"},"Example"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "ChatOpenAI", "source": "langchain.chat_models", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html", "title": "Context"}, {"imported": "PromptTemplate", "source": "langchain.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html", "title": "Context"}, {"imported": "ChatPromptTemplate", "source": "langchain.prompts.chat", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain.prompts.chat.ChatPromptTemplate.html", "title": "Context"}, {"imported": "HumanMessagePromptTemplate", "source": "langchain.prompts.chat", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain.prompts.chat.HumanMessagePromptTemplate.html", "title": "Context"}, {"imported": "ContextCallbackHandler", "source": "langchain.callbacks", "docs": "https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.context_callback.ContextCallbackHandler.html", "title": "Context"}]--\x3e\nimport os\n\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain import LLMChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain.prompts.chat import (\n    ChatPromptTemplate,\n    HumanMessagePromptTemplate,\n)\nfrom langchain.callbacks import ContextCallbackHandler\n\ntoken = os.environ["CONTEXT_API_TOKEN"]\n\nhuman_message_prompt = HumanMessagePromptTemplate(\n    prompt=PromptTemplate(\n        template="What is a good name for a company that makes {product}?",\n        input_variables=["product"],\n    )\n)\nchat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\ncallback = ContextCallbackHandler(token)\nchat = ChatOpenAI(temperature=0.9, callbacks=[callback])\nchain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])\nprint(chain.run("colorful socks"))\n')))}m.isMDXComponent=!0}}]);