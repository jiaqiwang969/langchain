"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5260],{3905:(e,t,r)=>{r.d(t,{Zo:()=>s,kt:()=>d});var n=r(67294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function l(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function o(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},i=Object.keys(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var p=n.createContext({}),m=function(e){var t=n.useContext(p),r=t;return e&&(r="function"==typeof e?e(t):l(l({},t),e)),r},s=function(e){var t=m(e.components);return n.createElement(p.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},h=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,i=e.originalType,p=e.parentName,s=o(e,["components","mdxType","originalType","parentName"]),c=m(r),h=a,d=c["".concat(p,".").concat(h)]||c[h]||u[h]||i;return r?n.createElement(d,l(l({ref:t},s),{},{components:r})):n.createElement(d,l({ref:t},s))}));function d(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=r.length,l=new Array(i);l[0]=h;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o[c]="string"==typeof e?e:a,l[1]=o;for(var m=2;m<i;m++)l[m]=r[m];return n.createElement.apply(null,l)}return n.createElement.apply(null,r)}h.displayName="MDXCreateElement"},89932:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>u,frontMatter:()=>i,metadata:()=>o,toc:()=>m});var n=r(87462),a=(r(67294),r(3905));const i={},l="CerebriumAI",o={unversionedId:"integrations/llms/cerebriumai",id:"integrations/llms/cerebriumai",title:"CerebriumAI",description:"Cerebrium is an AWS Sagemaker alternative. It also provides API access to several LLM models.",source:"@site/docs/integrations/llms/cerebriumai.md",sourceDirName:"integrations/llms",slug:"/integrations/llms/cerebriumai",permalink:"/langchain/docs/integrations/llms/cerebriumai",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"Bittensor",permalink:"/langchain/docs/integrations/llms/bittensor"},next:{title:"ChatGLM",permalink:"/langchain/docs/integrations/llms/chatglm"}},p={},m=[{value:"Install cerebrium",id:"install-cerebrium",level:2},{value:"Imports",id:"imports",level:2},{value:"Set the Environment API Key",id:"set-the-environment-api-key",level:2},{value:"Create the CerebriumAI instance",id:"create-the-cerebriumai-instance",level:2},{value:"Create a Prompt Template",id:"create-a-prompt-template",level:2},{value:"Initiate the LLMChain",id:"initiate-the-llmchain",level:2},{value:"Run the LLMChain",id:"run-the-llmchain",level:2}],s={toc:m},c="wrapper";function u(e){let{components:t,...r}=e;return(0,a.kt)(c,(0,n.Z)({},s,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"cerebriumai"},"CerebriumAI"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"Cerebrium")," is an AWS Sagemaker alternative. It also provides API access to ",(0,a.kt)("a",{parentName:"p",href:"https://docs.cerebrium.ai/cerebrium/prebuilt-models/deployment"},"several LLM models"),"."),(0,a.kt)("p",null,"This notebook goes over how to use Langchain with ",(0,a.kt)("a",{parentName:"p",href:"https://docs.cerebrium.ai/introduction"},"CerebriumAI"),"."),(0,a.kt)("h2",{id:"install-cerebrium"},"Install cerebrium"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"cerebrium")," package is required to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"CerebriumAI")," API. Install ",(0,a.kt)("inlineCode",{parentName:"p"},"cerebrium")," using ",(0,a.kt)("inlineCode",{parentName:"p"},"pip3 install cerebrium"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"# Install the package\npip3 install cerebrium\n")),(0,a.kt)("h2",{id:"imports"},"Imports"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "CerebriumAI", "source": "langchain.llms", "docs": "https://api.python.langchain.com/en/latest/llms/langchain.llms.cerebriumai.CerebriumAI.html", "title": "CerebriumAI"}]--\x3e\nimport os\nfrom langchain.llms import CerebriumAI\nfrom langchain import PromptTemplate, LLMChain\n')),(0,a.kt)("h2",{id:"set-the-environment-api-key"},"Set the Environment API Key"),(0,a.kt)("p",null,"Make sure to get your API key from CerebriumAI. See ",(0,a.kt)("a",{parentName:"p",href:"https://dashboard.cerebrium.ai/login"},"here"),". You are given a 1 hour free of serverless GPU compute to test different models."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'os.environ["CEREBRIUMAI_API_KEY"] = "YOUR_KEY_HERE"\n')),(0,a.kt)("h2",{id:"create-the-cerebriumai-instance"},"Create the CerebriumAI instance"),(0,a.kt)("p",null,"You can specify different parameters such as the model endpoint url, max length, temperature, etc. You must provide an endpoint url."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'llm = CerebriumAI(endpoint_url="YOUR ENDPOINT URL HERE")\n')),(0,a.kt)("h2",{id:"create-a-prompt-template"},"Create a Prompt Template"),(0,a.kt)("p",null,"We will create a prompt template for Question and Answer."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'template = """Question: {question}\n\nAnswer: Let\'s think step by step."""\n\nprompt = PromptTemplate(template=template, input_variables=["question"])\n')),(0,a.kt)("h2",{id:"initiate-the-llmchain"},"Initiate the LLMChain"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"llm_chain = LLMChain(prompt=prompt, llm=llm)\n")),(0,a.kt)("h2",{id:"run-the-llmchain"},"Run the LLMChain"),(0,a.kt)("p",null,"Provide a question and run the LLMChain."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'question = "What NFL team won the Super Bowl in the year Justin Beiber was born?"\n\nllm_chain.run(question)\n')))}u.isMDXComponent=!0}}]);