"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[33889],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>y});var n=a(67294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var m=n.createContext({}),l=function(e){var t=n.useContext(m),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},p=function(e){var t=l(e.components);return n.createElement(m.Provider,{value:t},e.children)},h="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,m=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),h=l(a),c=o,y=h["".concat(m,".").concat(c)]||h[c]||u[c]||r;return a?n.createElement(y,s(s({ref:t},p),{},{components:a})):n.createElement(y,s({ref:t},p))}));function y(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,s=new Array(r);s[0]=c;var i={};for(var m in t)hasOwnProperty.call(t,m)&&(i[m]=t[m]);i.originalType=e,i[h]="string"==typeof e?e:o,s[1]=i;for(var l=2;l<r;l++)s[l]=a[l];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},61368:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>h,default:()=>f,frontMatter:()=>p,metadata:()=>u,toc:()=>y});var n=a(87462),o=(a(67294),a(3905));const r=(s="CodeOutputBlock",function(e){return console.warn("Component "+s+" was not imported, exported, or provided by MDXProvider as global scope"),(0,o.kt)("div",e)});var s;const i={toc:[{value:"What variables get returned from memory",id:"what-variables-get-returned-from-memory",level:3},{value:"Whether memory is a string or a list of messages",id:"whether-memory-is-a-string-or-a-list-of-messages",level:3},{value:"What keys are saved to memory",id:"what-keys-are-saved-to-memory",level:3},{value:"End to end example",id:"end-to-end-example",level:3},{value:"Using an LLM",id:"using-an-llm",level:4},{value:"Using a ChatModel",id:"using-a-chatmodel",level:4}]},m="wrapper";function l(e){let{components:t,...a}=e;return(0,o.kt)(m,(0,n.Z)({},i,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"Let's take a look at how to use ",(0,o.kt)("inlineCode",{parentName:"p"},"ConversationBufferMemory")," in chains.\n",(0,o.kt)("inlineCode",{parentName:"p"},"ConversationBufferMemory")," is an extremely simple form of memory that just keeps a list of chat messages in a buffer\nand passes those into the prompt template."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.memory import ConversationBufferMemory\n\nmemory = ConversationBufferMemory()\nmemory.chat_memory.add_user_message("hi!")\nmemory.chat_memory.add_ai_message("what\'s up?")\n')),(0,o.kt)("p",null,"When using memory in a chain, there are a few key concepts to understand.\nNote that here we cover general concepts that are useful for most types of memory.\nEach individual memory type may very well have its own parameters and concepts that are necessary to understand."),(0,o.kt)("h3",{id:"what-variables-get-returned-from-memory"},"What variables get returned from memory"),(0,o.kt)("p",null,"Before going into the chain, various variables are read from memory.\nThese have specific names which need to align with the variables the chain expects.\nYou can see what these variables are by calling ",(0,o.kt)("inlineCode",{parentName:"p"},"memory.load_memory_variables({})"),".\nNote that the empty dictionary that we pass in is just a placeholder for real variables.\nIf the memory type you are using is dependent upon the input variables, you may need to pass some in."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"memory.load_memory_variables({})\n")),(0,o.kt)(r,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'history': \"Human: hi!\\nAI: what's up?\"}\n"))),(0,o.kt)("p",null,"In this case, you can see that ",(0,o.kt)("inlineCode",{parentName:"p"},"load_memory_variables")," returns a single key, ",(0,o.kt)("inlineCode",{parentName:"p"},"history"),".\nThis means that your chain (and likely your prompt) should expect an input named ",(0,o.kt)("inlineCode",{parentName:"p"},"history"),".\nYou can usually control this variable through parameters on the memory class.\nFor example, if you want the memory variables to be returned in the key ",(0,o.kt)("inlineCode",{parentName:"p"},"chat_history")," you can do:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'memory = ConversationBufferMemory(memory_key="chat_history")\nmemory.chat_memory.add_user_message("hi!")\nmemory.chat_memory.add_ai_message("what\'s up?")\n')),(0,o.kt)(r,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'chat_history': \"Human: hi!\\nAI: what's up?\"}\n"))),(0,o.kt)("p",null,"The parameter name to control these keys may vary per memory type, but it's important to understand that (1) this is controllable, and (2) how to control it."),(0,o.kt)("h3",{id:"whether-memory-is-a-string-or-a-list-of-messages"},"Whether memory is a string or a list of messages"),(0,o.kt)("p",null,"One of the most common types of memory involves returning a list of chat messages.\nThese can either be returned as a single string, all concatenated together (useful when they will be passed into LLMs)\nor a list of ChatMessages (useful when passed into ChatModels)."),(0,o.kt)("p",null,"By default, they are returned as a single string.\nIn order to return as a list of messages, you can set ",(0,o.kt)("inlineCode",{parentName:"p"},"return_messages=True")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'memory = ConversationBufferMemory(return_messages=True)\nmemory.chat_memory.add_user_message("hi!")\nmemory.chat_memory.add_ai_message("what\'s up?")\n')),(0,o.kt)(r,{lang:"python",mdxType:"CodeOutputBlock"},(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"    {'history': [HumanMessage(content='hi!', additional_kwargs={}, example=False),\n  AIMessage(content='what's up?', additional_kwargs={}, example=False)]}\n"))),(0,o.kt)("h3",{id:"what-keys-are-saved-to-memory"},"What keys are saved to memory"),(0,o.kt)("p",null,"Often times chains take in or return multiple input/output keys.\nIn these cases, how can we know which keys we want to save to the chat message history?\nThis is generally controllable by ",(0,o.kt)("inlineCode",{parentName:"p"},"input_key")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"output_key")," parameters on the memory types.\nThese default to ",(0,o.kt)("inlineCode",{parentName:"p"},"None")," - and if there is only one input/output key it is known to just use that.\nHowever, if there are multiple input/output keys then you MUST specify the name of which one to use."),(0,o.kt)("h3",{id:"end-to-end-example"},"End to end example"),(0,o.kt)("p",null,"Finally, let's take a look at using this in a chain.\nWe'll use an ",(0,o.kt)("inlineCode",{parentName:"p"},"LLMChain"),", and show working with both an LLM and a ChatModel."),(0,o.kt)("h4",{id:"using-an-llm"},"Using an LLM"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.memory import ConversationBufferMemory\n\n\nllm = OpenAI(temperature=0)\n# Notice that "chat_history" is present in the prompt template\ntemplate = """You are a nice chatbot having a conversation with a human.\n\nPrevious conversation:\n{chat_history}\n\nNew human question: {question}\nResponse:"""\nprompt = PromptTemplate.from_template(template)\n# Notice that we need to align the `memory_key`\nmemory = ConversationBufferMemory(memory_key="chat_history")\nconversation = LLMChain(\n    llm=llm,\n    prompt=prompt,\n    verbose=True,\n    memory=memory\n)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory\nconversation({"question": "hi"})\n')),(0,o.kt)("h4",{id:"using-a-chatmodel"},"Using a ChatModel"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'from langchain.chat_models import ChatOpenAI\nfrom langchain.prompts import (\n    ChatPromptTemplate,\n    MessagesPlaceholder,\n    SystemMessagePromptTemplate,\n    HumanMessagePromptTemplate,\n)\nfrom langchain.chains import LLMChain\nfrom langchain.memory import ConversationBufferMemory\n\n\nllm = ChatOpenAI()\nprompt = ChatPromptTemplate(\n    messages=[\n        SystemMessagePromptTemplate.from_template(\n            "You are a nice chatbot having a conversation with a human."\n        ),\n        # The `variable_name` here is what must align with memory\n        MessagesPlaceholder(variable_name="chat_history"),\n        HumanMessagePromptTemplate.from_template("{question}")\n    ]\n)\n# Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n# Notice that `"chat_history"` aligns with the MessagesPlaceholder name.\nmemory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)\nconversation = LLMChain(\n    llm=llm,\n    prompt=prompt,\n    verbose=True,\n    memory=memory\n)\n')),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory\nconversation({"question": "hi"})\n')))}l.isMDXComponent=!0;const p={sidebar_position:3},h="Memory",u={unversionedId:"modules/memory/index",id:"modules/memory/index",title:"Memory",description:"Most LLM applications have a conversational interface. An essential component of a conversation is being able to refer to information introduced earlier in the conversation.",source:"@site/docs/modules/memory/index.mdx",sourceDirName:"modules/memory",slug:"/modules/memory/",permalink:"/langchain/docs/modules/memory/",draft:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"docs",previous:{title:"Map re-rank",permalink:"/langchain/docs/modules/chains/document/map_rerank"},next:{title:"Chat Messages",permalink:"/langchain/docs/modules/memory/chat_messages/"}},c={},y=[{value:"Building memory into a system",id:"building-memory-into-a-system",level:2},{value:"Storing: List of chat messages",id:"storing-list-of-chat-messages",level:3},{value:"Querying: Data structures and algorithms on top of chat messages",id:"querying-data-structures-and-algorithms-on-top-of-chat-messages",level:3},{value:"Get started",id:"get-started",level:2},{value:"Next steps",id:"next-steps",level:2}],d={toc:y},g="wrapper";function f(e){let{components:t,...r}=e;return(0,o.kt)(g,(0,n.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"memory"},"Memory"),(0,o.kt)("p",null,"Most LLM applications have a conversational interface. An essential component of a conversation is being able to refer to information introduced earlier in the conversation.\nAt bare minimum, a conversational system should be able to access some window of past messages directly.\nA more complex system will need to have a world model that it is constantly updating, which allows it to do things like maintain information about entities and their relationships."),(0,o.kt)("p",null,'We call this ability to store information about past interactions "memory".\nLangChain provides a lot of utilities for adding memory to a system.\nThese utilities can be used by themselves or incorporated seamlessly into a chain.'),(0,o.kt)("p",null,"A memory system needs to support two basic actions: reading and writing.\nRecall that every chain defines some core execution logic that expects certain inputs.\nSome of these inputs come directly from the user, but some of these inputs can come from memory.\nA chain will interact with its memory system twice in a given run."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"AFTER receiving the initial user inputs but BEFORE executing the core logic, a chain will READ from its memory system and augment the user inputs."),(0,o.kt)("li",{parentName:"ol"},"AFTER executing the core logic but BEFORE returning the answer, a chain will WRITE the inputs and outputs of the current run to memory, so that they can be referred to in future runs.")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"memory-diagram",src:a(33554).Z,width:"2880",height:"1472"})),(0,o.kt)("h2",{id:"building-memory-into-a-system"},"Building memory into a system"),(0,o.kt)("p",null,"The two core design decisions in any memory system are:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"How state is stored"),(0,o.kt)("li",{parentName:"ul"},"How state is queried")),(0,o.kt)("h3",{id:"storing-list-of-chat-messages"},"Storing: List of chat messages"),(0,o.kt)("p",null,"Underlying any memory is a history of all chat interactions.\nEven if these are not all used directly, they need to be stored in some form.\nOne of the key parts of the LangChain memory module is a series of integrations for storing these chat messages,\nfrom in-memory lists to persistent databases."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/docs/modules/memory/chat_messages/"},"Chat message storage"),": How to work with Chat Messages, and the various integrations offered.")),(0,o.kt)("h3",{id:"querying-data-structures-and-algorithms-on-top-of-chat-messages"},"Querying: Data structures and algorithms on top of chat messages"),(0,o.kt)("p",null,"Keeping a list of chat messages is fairly straight-forward.\nWhat is less straight-forward are the data structures and algorithms built on top of chat messages that serve a view of those messages that is most useful."),(0,o.kt)("p",null,"A very simply memory system might just return the most recent messages each run. A slightly more complex memory system might return a succinct summary of the past K messages.\nAn even more sophisticated system might extract entities from stored messages and only return information about entities referenced in the current run."),(0,o.kt)("p",null,"Each application can have different requirements for how memory is queried. The memory module should make it easy to both get started with simple memory systems and write your own custom systems if needed."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"/docs/modules/memory/types/"},"Memory types"),": The various data structures and algorithms that make up the memory types LangChain supports")),(0,o.kt)("h2",{id:"get-started"},"Get started"),(0,o.kt)("p",null,"Let's take a look at what Memory actually looks like in LangChain.\nHere we'll cover the basics of interacting with an arbitrary memory class."),(0,o.kt)(l,{mdxType:"GetStarted"}),(0,o.kt)("h2",{id:"next-steps"},"Next steps"),(0,o.kt)("p",null,"And that's it for getting started!\nPlease see the other sections for walkthroughs of more advanced topics,\nlike custom memory, multiple memories, and more."))}f.isMDXComponent=!0},33554:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/memory_diagram-0627c68230aa438f9b5419064d63cbbc.png"}}]);