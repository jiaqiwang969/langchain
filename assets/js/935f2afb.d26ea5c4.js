"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[80053],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docs":[{"type":"category","label":"Get started","collapsed":false,"collapsible":false,"items":[{"type":"link","label":"Introduction","href":"/langchain/docs/get_started/introduction","docId":"get_started/introduction"},{"type":"link","label":"Installation","href":"/langchain/docs/get_started/installation","docId":"get_started/installation"},{"type":"link","label":"Quickstart","href":"/langchain/docs/get_started/quickstart","docId":"get_started/quickstart"}],"href":"/langchain/docs/get_started"},{"type":"category","label":"Modules","collapsed":false,"collapsible":false,"items":[{"type":"category","label":"Model I/\u200bO","collapsible":true,"collapsed":true,"customProps":{"description":"Interface with language models"},"items":[{"type":"category","label":"Prompts","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Prompt templates","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Connecting to a Feature Store","href":"/langchain/docs/modules/model_io/prompts/prompt_templates/connecting_to_a_feature_store","docId":"modules/model_io/prompts/prompt_templates/connecting_to_a_feature_store"},{"type":"link","label":"Custom prompt template","href":"/langchain/docs/modules/model_io/prompts/prompt_templates/custom_prompt_template","docId":"modules/model_io/prompts/prompt_templates/custom_prompt_template"},{"type":"link","label":"Few-shot prompt templates","href":"/langchain/docs/modules/model_io/prompts/prompt_templates/few_shot_examples","docId":"modules/model_io/prompts/prompt_templates/few_shot_examples"},{"type":"link","label":"Few-shot examples for chat models","href":"/langchain/docs/modules/model_io/prompts/prompt_templates/few_shot_examples_chat","docId":"modules/model_io/prompts/prompt_templates/few_shot_examples_chat"},{"type":"link","label":"Format template output","href":"/langchain/docs/modules/model_io/prompts/prompt_templates/format_output","docId":"modules/model_io/prompts/prompt_templates/format_output"},{"type":"link","label":"Template formats","href":"/langchain/docs/modules/model_io/prompts/prompt_templates/formats","docId":"modules/model_io/prompts/prompt_templates/formats"},{"type":"link","label":"Types of MessagePromptTemplate","href":"/langchain/docs/modules/model_io/prompts/prompt_templates/msg_prompt_templates","docId":"modules/model_io/prompts/prompt_templates/msg_prompt_templates"},{"type":"link","label":"Partial prompt templates","href":"/langchain/docs/modules/model_io/prompts/prompt_templates/partial","docId":"modules/model_io/prompts/prompt_templates/partial"},{"type":"link","label":"Composition","href":"/langchain/docs/modules/model_io/prompts/prompt_templates/prompt_composition","docId":"modules/model_io/prompts/prompt_templates/prompt_composition"},{"type":"link","label":"Serialization","href":"/langchain/docs/modules/model_io/prompts/prompt_templates/prompt_serialization","docId":"modules/model_io/prompts/prompt_templates/prompt_serialization"},{"type":"link","label":"Prompt pipelining","href":"/langchain/docs/modules/model_io/prompts/prompt_templates/prompts_pipelining","docId":"modules/model_io/prompts/prompt_templates/prompts_pipelining"},{"type":"link","label":"Validate template","href":"/langchain/docs/modules/model_io/prompts/prompt_templates/validate","docId":"modules/model_io/prompts/prompt_templates/validate"}],"href":"/langchain/docs/modules/model_io/prompts/prompt_templates/"},{"type":"category","label":"Example selectors","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Custom example selector","href":"/langchain/docs/modules/model_io/prompts/example_selectors/custom_example_selector","docId":"modules/model_io/prompts/example_selectors/custom_example_selector"},{"type":"link","label":"Select by length","href":"/langchain/docs/modules/model_io/prompts/example_selectors/length_based","docId":"modules/model_io/prompts/example_selectors/length_based"},{"type":"link","label":"Select by maximal marginal relevance (MMR)","href":"/langchain/docs/modules/model_io/prompts/example_selectors/mmr","docId":"modules/model_io/prompts/example_selectors/mmr"},{"type":"link","label":"Select by n-gram overlap","href":"/langchain/docs/modules/model_io/prompts/example_selectors/ngram_overlap","docId":"modules/model_io/prompts/example_selectors/ngram_overlap"},{"type":"link","label":"Select by similarity","href":"/langchain/docs/modules/model_io/prompts/example_selectors/similarity","docId":"modules/model_io/prompts/example_selectors/similarity"}],"href":"/langchain/docs/modules/model_io/prompts/example_selectors/"}],"href":"/langchain/docs/modules/model_io/prompts/"},{"type":"category","label":"Language models","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"LLMs","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Async API","href":"/langchain/docs/modules/model_io/models/llms/async_llm","docId":"modules/model_io/models/llms/async_llm"},{"type":"link","label":"Custom LLM","href":"/langchain/docs/modules/model_io/models/llms/custom_llm","docId":"modules/model_io/models/llms/custom_llm"},{"type":"link","label":"Fake LLM","href":"/langchain/docs/modules/model_io/models/llms/fake_llm","docId":"modules/model_io/models/llms/fake_llm"},{"type":"link","label":"Human input LLM","href":"/langchain/docs/modules/model_io/models/llms/human_input_llm","docId":"modules/model_io/models/llms/human_input_llm"},{"type":"link","label":"Caching","href":"/langchain/docs/modules/model_io/models/llms/llm_caching","docId":"modules/model_io/models/llms/llm_caching"},{"type":"link","label":"Serialization","href":"/langchain/docs/modules/model_io/models/llms/llm_serialization","docId":"modules/model_io/models/llms/llm_serialization"},{"type":"link","label":"Streaming","href":"/langchain/docs/modules/model_io/models/llms/streaming_llm","docId":"modules/model_io/models/llms/streaming_llm"},{"type":"link","label":"Tracking token usage","href":"/langchain/docs/modules/model_io/models/llms/token_usage_tracking","docId":"modules/model_io/models/llms/token_usage_tracking"}],"href":"/langchain/docs/modules/model_io/models/llms/"},{"type":"category","label":"Chat models","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Caching","href":"/langchain/docs/modules/model_io/models/chat/chat_model_caching","docId":"modules/model_io/models/chat/chat_model_caching"},{"type":"link","label":"Human input chat model","href":"/langchain/docs/modules/model_io/models/chat/human_input_chat_model","docId":"modules/model_io/models/chat/human_input_chat_model"},{"type":"link","label":"LLMChain","href":"/langchain/docs/modules/model_io/models/chat/llm_chain","docId":"modules/model_io/models/chat/llm_chain"},{"type":"link","label":"Prompts","href":"/langchain/docs/modules/model_io/models/chat/prompts","docId":"modules/model_io/models/chat/prompts"},{"type":"link","label":"Streaming","href":"/langchain/docs/modules/model_io/models/chat/streaming","docId":"modules/model_io/models/chat/streaming"}],"href":"/langchain/docs/modules/model_io/models/chat/"}],"href":"/langchain/docs/modules/model_io/models/"},{"type":"category","label":"Output parsers","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"List parser","href":"/langchain/docs/modules/model_io/output_parsers/comma_separated","docId":"modules/model_io/output_parsers/comma_separated"},{"type":"link","label":"Datetime parser","href":"/langchain/docs/modules/model_io/output_parsers/datetime","docId":"modules/model_io/output_parsers/datetime"},{"type":"link","label":"Enum parser","href":"/langchain/docs/modules/model_io/output_parsers/enum","docId":"modules/model_io/output_parsers/enum"},{"type":"link","label":"Auto-fixing parser","href":"/langchain/docs/modules/model_io/output_parsers/output_fixing_parser","docId":"modules/model_io/output_parsers/output_fixing_parser"},{"type":"link","label":"Pydantic (JSON) parser","href":"/langchain/docs/modules/model_io/output_parsers/pydantic","docId":"modules/model_io/output_parsers/pydantic"},{"type":"link","label":"Retry parser","href":"/langchain/docs/modules/model_io/output_parsers/retry","docId":"modules/model_io/output_parsers/retry"},{"type":"link","label":"Structured output parser","href":"/langchain/docs/modules/model_io/output_parsers/structured","docId":"modules/model_io/output_parsers/structured"}],"href":"/langchain/docs/modules/model_io/output_parsers/"}],"href":"/langchain/docs/modules/model_io/"},{"type":"category","label":"Retrieval","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Document loaders","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"CSV","href":"/langchain/docs/modules/data_connection/document_loaders/csv","docId":"modules/data_connection/document_loaders/csv"},{"type":"link","label":"File Directory","href":"/langchain/docs/modules/data_connection/document_loaders/file_directory","docId":"modules/data_connection/document_loaders/file_directory"},{"type":"link","label":"HTML","href":"/langchain/docs/modules/data_connection/document_loaders/html","docId":"modules/data_connection/document_loaders/html"},{"type":"link","label":"JSON","href":"/langchain/docs/modules/data_connection/document_loaders/json","docId":"modules/data_connection/document_loaders/json"},{"type":"link","label":"Markdown","href":"/langchain/docs/modules/data_connection/document_loaders/markdown","docId":"modules/data_connection/document_loaders/markdown"},{"type":"link","label":"PDF","href":"/langchain/docs/modules/data_connection/document_loaders/pdf","docId":"modules/data_connection/document_loaders/pdf"}],"href":"/langchain/docs/modules/data_connection/document_loaders/"},{"type":"category","label":"Document transformers","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Text splitters","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Split by character","href":"/langchain/docs/modules/data_connection/document_transformers/text_splitters/character_text_splitter","docId":"modules/data_connection/document_transformers/text_splitters/character_text_splitter"},{"type":"link","label":"Split code","href":"/langchain/docs/modules/data_connection/document_transformers/text_splitters/code_splitter","docId":"modules/data_connection/document_transformers/text_splitters/code_splitter"},{"type":"link","label":"MarkdownHeaderTextSplitter","href":"/langchain/docs/modules/data_connection/document_transformers/text_splitters/markdown_header_metadata","docId":"modules/data_connection/document_transformers/text_splitters/markdown_header_metadata"},{"type":"link","label":"Recursively split by character","href":"/langchain/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter","docId":"modules/data_connection/document_transformers/text_splitters/recursive_text_splitter"},{"type":"link","label":"Split by tokens","href":"/langchain/docs/modules/data_connection/document_transformers/text_splitters/split_by_token","docId":"modules/data_connection/document_transformers/text_splitters/split_by_token"}]},{"type":"category","label":"Post retrieval","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Lost in the middle: The problem with long contexts","href":"/langchain/docs/modules/data_connection/document_transformers/post_retrieval/long_context_reorder","docId":"modules/data_connection/document_transformers/post_retrieval/long_context_reorder"}]}],"href":"/langchain/docs/modules/data_connection/document_transformers/"},{"type":"category","label":"Text embedding models","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Caching","href":"/langchain/docs/modules/data_connection/text_embedding/caching_embeddings","docId":"modules/data_connection/text_embedding/caching_embeddings"}],"href":"/langchain/docs/modules/data_connection/text_embedding/"},{"type":"link","label":"Vector stores","href":"/langchain/docs/modules/data_connection/vectorstores/","docId":"modules/data_connection/vectorstores/index"},{"type":"category","label":"Retrievers","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"MultiQueryRetriever","href":"/langchain/docs/modules/data_connection/retrievers/MultiQueryRetriever","docId":"modules/data_connection/retrievers/MultiQueryRetriever"},{"type":"link","label":"Contextual compression","href":"/langchain/docs/modules/data_connection/retrievers/contextual_compression/","docId":"modules/data_connection/retrievers/contextual_compression/index"},{"type":"link","label":"Ensemble Retriever","href":"/langchain/docs/modules/data_connection/retrievers/ensemble","docId":"modules/data_connection/retrievers/ensemble"},{"type":"link","label":"MultiVector Retriever","href":"/langchain/docs/modules/data_connection/retrievers/multi_vector","docId":"modules/data_connection/retrievers/multi_vector"},{"type":"link","label":"Parent Document Retriever","href":"/langchain/docs/modules/data_connection/retrievers/parent_document_retriever","docId":"modules/data_connection/retrievers/parent_document_retriever"},{"type":"category","label":"Self-querying","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Deep Lake self-querying","href":"/langchain/docs/modules/data_connection/retrievers/self_query/activeloop_deeplake_self_query","docId":"modules/data_connection/retrievers/self_query/activeloop_deeplake_self_query"},{"type":"link","label":"Chroma self-querying","href":"/langchain/docs/modules/data_connection/retrievers/self_query/chroma_self_query","docId":"modules/data_connection/retrievers/self_query/chroma_self_query"},{"type":"link","label":"DashVector self-querying","href":"/langchain/docs/modules/data_connection/retrievers/self_query/dashvector","docId":"modules/data_connection/retrievers/self_query/dashvector"},{"type":"link","label":"Elasticsearch self-querying","href":"/langchain/docs/modules/data_connection/retrievers/self_query/elasticsearch_self_query","docId":"modules/data_connection/retrievers/self_query/elasticsearch_self_query"},{"type":"link","label":"Self-querying with Milvus","href":"/langchain/docs/modules/data_connection/retrievers/self_query/milvus_self_query","docId":"modules/data_connection/retrievers/self_query/milvus_self_query"},{"type":"link","label":"Self-querying with MyScale","href":"/langchain/docs/modules/data_connection/retrievers/self_query/myscale_self_query","docId":"modules/data_connection/retrievers/self_query/myscale_self_query"},{"type":"link","label":"Self-querying with Pinecone","href":"/langchain/docs/modules/data_connection/retrievers/self_query/pinecone","docId":"modules/data_connection/retrievers/self_query/pinecone"},{"type":"link","label":"Qdrant self-querying","href":"/langchain/docs/modules/data_connection/retrievers/self_query/qdrant_self_query","docId":"modules/data_connection/retrievers/self_query/qdrant_self_query"},{"type":"link","label":"Weaviate self-querying","href":"/langchain/docs/modules/data_connection/retrievers/self_query/weaviate_self_query","docId":"modules/data_connection/retrievers/self_query/weaviate_self_query"}],"href":"/langchain/docs/modules/data_connection/retrievers/self_query/"},{"type":"link","label":"Time-weighted vector store retriever","href":"/langchain/docs/modules/data_connection/retrievers/time_weighted_vectorstore","docId":"modules/data_connection/retrievers/time_weighted_vectorstore"},{"type":"link","label":"Vector store-backed retriever","href":"/langchain/docs/modules/data_connection/retrievers/vectorstore","docId":"modules/data_connection/retrievers/vectorstore"},{"type":"link","label":"WebResearchRetriever","href":"/langchain/docs/modules/data_connection/retrievers/web_research","docId":"modules/data_connection/retrievers/web_research"}],"href":"/langchain/docs/modules/data_connection/retrievers/"},{"type":"link","label":"Indexing","href":"/langchain/docs/modules/data_connection/indexing","docId":"modules/data_connection/indexing"}],"href":"/langchain/docs/modules/data_connection/"},{"type":"category","label":"Chains","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"How to","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Async API","href":"/langchain/docs/modules/chains/how_to/async_chain","docId":"modules/chains/how_to/async_chain"},{"type":"link","label":"Different call methods","href":"/langchain/docs/modules/chains/how_to/call_methods","docId":"modules/chains/how_to/call_methods"},{"type":"link","label":"Custom chain","href":"/langchain/docs/modules/chains/how_to/custom_chain","docId":"modules/chains/how_to/custom_chain"},{"type":"link","label":"Debugging chains","href":"/langchain/docs/modules/chains/how_to/debugging","docId":"modules/chains/how_to/debugging"},{"type":"link","label":"Loading from LangChainHub","href":"/langchain/docs/modules/chains/how_to/from_hub","docId":"modules/chains/how_to/from_hub"},{"type":"link","label":"Adding memory (state)","href":"/langchain/docs/modules/chains/how_to/memory","docId":"modules/chains/how_to/memory"},{"type":"link","label":"Using OpenAI functions","href":"/langchain/docs/modules/chains/how_to/openai_functions","docId":"modules/chains/how_to/openai_functions"},{"type":"link","label":"Serialization","href":"/langchain/docs/modules/chains/how_to/serialization","docId":"modules/chains/how_to/serialization"}],"href":"/langchain/docs/modules/chains/how_to/"},{"type":"category","label":"Foundational","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"LLM","href":"/langchain/docs/modules/chains/foundational/llm_chain","docId":"modules/chains/foundational/llm_chain"},{"type":"link","label":"Router","href":"/langchain/docs/modules/chains/foundational/router","docId":"modules/chains/foundational/router"},{"type":"link","label":"Sequential","href":"/langchain/docs/modules/chains/foundational/sequential_chains","docId":"modules/chains/foundational/sequential_chains"},{"type":"link","label":"Transformation","href":"/langchain/docs/modules/chains/foundational/transformation","docId":"modules/chains/foundational/transformation"}],"href":"/langchain/docs/modules/chains/foundational/"},{"type":"category","label":"Documents","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Stuff","href":"/langchain/docs/modules/chains/document/stuff","docId":"modules/chains/document/stuff"},{"type":"link","label":"Refine","href":"/langchain/docs/modules/chains/document/refine","docId":"modules/chains/document/refine"},{"type":"link","label":"Map reduce","href":"/langchain/docs/modules/chains/document/map_reduce","docId":"modules/chains/document/map_reduce"},{"type":"link","label":"Map re-rank","href":"/langchain/docs/modules/chains/document/map_rerank","docId":"modules/chains/document/map_rerank"}],"href":"/langchain/docs/modules/chains/document/"}],"href":"/langchain/docs/modules/chains/"},{"type":"category","label":"Memory","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Chat Messages","href":"/langchain/docs/modules/memory/chat_messages/","docId":"modules/memory/chat_messages/index"},{"type":"category","label":"Memory types","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Conversation Buffer","href":"/langchain/docs/modules/memory/types/buffer","docId":"modules/memory/types/buffer"},{"type":"link","label":"Conversation Buffer Window","href":"/langchain/docs/modules/memory/types/buffer_window","docId":"modules/memory/types/buffer_window"},{"type":"link","label":"Entity","href":"/langchain/docs/modules/memory/types/entity_summary_memory","docId":"modules/memory/types/entity_summary_memory"},{"type":"link","label":"Conversation Knowledge Graph","href":"/langchain/docs/modules/memory/types/kg","docId":"modules/memory/types/kg"},{"type":"link","label":"Conversation Summary","href":"/langchain/docs/modules/memory/types/summary","docId":"modules/memory/types/summary"},{"type":"link","label":"Conversation Summary Buffer","href":"/langchain/docs/modules/memory/types/summary_buffer","docId":"modules/memory/types/summary_buffer"},{"type":"link","label":"Conversation Token Buffer","href":"/langchain/docs/modules/memory/types/token_buffer","docId":"modules/memory/types/token_buffer"},{"type":"link","label":"Backed by a Vector Store","href":"/langchain/docs/modules/memory/types/vectorstore_retriever_memory","docId":"modules/memory/types/vectorstore_retriever_memory"}],"href":"/langchain/docs/modules/memory/types/"},{"type":"link","label":"Memory in LLMChain","href":"/langchain/docs/modules/memory/adding_memory","docId":"modules/memory/adding_memory"},{"type":"link","label":"Memory in the Multi-Input Chain","href":"/langchain/docs/modules/memory/adding_memory_chain_multiple_inputs","docId":"modules/memory/adding_memory_chain_multiple_inputs"},{"type":"link","label":"Memory in Agent","href":"/langchain/docs/modules/memory/agent_with_memory","docId":"modules/memory/agent_with_memory"},{"type":"link","label":"Message Memory in Agent backed by a database","href":"/langchain/docs/modules/memory/agent_with_memory_in_db","docId":"modules/memory/agent_with_memory_in_db"},{"type":"link","label":"Customizing Conversational Memory","href":"/langchain/docs/modules/memory/conversational_customization","docId":"modules/memory/conversational_customization"},{"type":"link","label":"Custom Memory","href":"/langchain/docs/modules/memory/custom_memory","docId":"modules/memory/custom_memory"},{"type":"link","label":"Multiple Memory classes","href":"/langchain/docs/modules/memory/multiple_memory","docId":"modules/memory/multiple_memory"}],"href":"/langchain/docs/modules/memory/"},{"type":"category","label":"Agents","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Agent types","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Conversational","href":"/langchain/docs/modules/agents/agent_types/chat_conversation_agent","docId":"modules/agents/agent_types/chat_conversation_agent"},{"type":"link","label":"OpenAI functions","href":"/langchain/docs/modules/agents/agent_types/openai_functions_agent","docId":"modules/agents/agent_types/openai_functions_agent"},{"type":"link","label":"OpenAI Multi Functions Agent","href":"/langchain/docs/modules/agents/agent_types/openai_multi_functions_agent","docId":"modules/agents/agent_types/openai_multi_functions_agent"},{"type":"link","label":"Plan-and-execute","href":"/langchain/docs/modules/agents/agent_types/plan_and_execute","docId":"modules/agents/agent_types/plan_and_execute"},{"type":"link","label":"ReAct","href":"/langchain/docs/modules/agents/agent_types/react","docId":"modules/agents/agent_types/react"},{"type":"link","label":"ReAct document store","href":"/langchain/docs/modules/agents/agent_types/react_docstore","docId":"modules/agents/agent_types/react_docstore"},{"type":"link","label":"Self-ask with search","href":"/langchain/docs/modules/agents/agent_types/self_ask_with_search","docId":"modules/agents/agent_types/self_ask_with_search"},{"type":"link","label":"Structured tool chat","href":"/langchain/docs/modules/agents/agent_types/structured_chat","docId":"modules/agents/agent_types/structured_chat"},{"type":"link","label":"XML Agent","href":"/langchain/docs/modules/agents/agent_types/xml_agent","docId":"modules/agents/agent_types/xml_agent"}],"href":"/langchain/docs/modules/agents/agent_types/"},{"type":"category","label":"How-to","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Add Memory to OpenAI Functions Agent","href":"/langchain/docs/modules/agents/how_to/add_memory_openai_functions","docId":"modules/agents/how_to/add_memory_openai_functions"},{"type":"link","label":"Running Agent as an Iterator","href":"/langchain/docs/modules/agents/how_to/agent_iter","docId":"modules/agents/how_to/agent_iter"},{"type":"link","label":"Combine agents and vector stores","href":"/langchain/docs/modules/agents/how_to/agent_vectorstore","docId":"modules/agents/how_to/agent_vectorstore"},{"type":"link","label":"Async API","href":"/langchain/docs/modules/agents/how_to/async_agent","docId":"modules/agents/how_to/async_agent"},{"type":"link","label":"Create ChatGPT clone","href":"/langchain/docs/modules/agents/how_to/chatgpt_clone","docId":"modules/agents/how_to/chatgpt_clone"},{"type":"link","label":"Custom functions with OpenAI Functions Agent","href":"/langchain/docs/modules/agents/how_to/custom-functions-with-openai-functions-agent","docId":"modules/agents/how_to/custom-functions-with-openai-functions-agent"},{"type":"link","label":"Custom agent","href":"/langchain/docs/modules/agents/how_to/custom_agent","docId":"modules/agents/how_to/custom_agent"},{"type":"link","label":"Custom agent with tool retrieval","href":"/langchain/docs/modules/agents/how_to/custom_agent_with_tool_retrieval","docId":"modules/agents/how_to/custom_agent_with_tool_retrieval"},{"type":"link","label":"Custom LLM agent","href":"/langchain/docs/modules/agents/how_to/custom_llm_agent","docId":"modules/agents/how_to/custom_llm_agent"},{"type":"link","label":"Custom LLM Agent (with a ChatModel)","href":"/langchain/docs/modules/agents/how_to/custom_llm_chat_agent","docId":"modules/agents/how_to/custom_llm_chat_agent"},{"type":"link","label":"Custom MRKL agent","href":"/langchain/docs/modules/agents/how_to/custom_mrkl_agent","docId":"modules/agents/how_to/custom_mrkl_agent"},{"type":"link","label":"Custom multi-action agent","href":"/langchain/docs/modules/agents/how_to/custom_multi_action_agent","docId":"modules/agents/how_to/custom_multi_action_agent"},{"type":"link","label":"Handle parsing errors","href":"/langchain/docs/modules/agents/how_to/handle_parsing_errors","docId":"modules/agents/how_to/handle_parsing_errors"},{"type":"link","label":"Access intermediate steps","href":"/langchain/docs/modules/agents/how_to/intermediate_steps","docId":"modules/agents/how_to/intermediate_steps"},{"type":"link","label":"Cap the max number of iterations","href":"/langchain/docs/modules/agents/how_to/max_iterations","docId":"modules/agents/how_to/max_iterations"},{"type":"link","label":"Timeouts for agents","href":"/langchain/docs/modules/agents/how_to/max_time_limit","docId":"modules/agents/how_to/max_time_limit"},{"type":"link","label":"Replicating MRKL","href":"/langchain/docs/modules/agents/how_to/mrkl","docId":"modules/agents/how_to/mrkl"},{"type":"link","label":"Shared memory across agents and tools","href":"/langchain/docs/modules/agents/how_to/sharedmemory_for_tools","docId":"modules/agents/how_to/sharedmemory_for_tools"},{"type":"link","label":"Streaming final agent output","href":"/langchain/docs/modules/agents/how_to/streaming_stdout_final_only","docId":"modules/agents/how_to/streaming_stdout_final_only"},{"type":"link","label":"Use ToolKits with OpenAI Functions","href":"/langchain/docs/modules/agents/how_to/use_toolkits_with_openai_functions","docId":"modules/agents/how_to/use_toolkits_with_openai_functions"}]},{"type":"category","label":"Tools","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Defining Custom Tools","href":"/langchain/docs/modules/agents/tools/custom_tools","docId":"modules/agents/tools/custom_tools"},{"type":"link","label":"Human-in-the-loop Tool Validation","href":"/langchain/docs/modules/agents/tools/human_approval","docId":"modules/agents/tools/human_approval"},{"type":"link","label":"Multi-Input Tools","href":"/langchain/docs/modules/agents/tools/multi_input_tool","docId":"modules/agents/tools/multi_input_tool"},{"type":"link","label":"Tool Input Schema","href":"/langchain/docs/modules/agents/tools/tool_input_validation","docId":"modules/agents/tools/tool_input_validation"},{"type":"link","label":"Tools as OpenAI Functions","href":"/langchain/docs/modules/agents/tools/tools_as_openai_functions","docId":"modules/agents/tools/tools_as_openai_functions"}],"href":"/langchain/docs/modules/agents/tools/"},{"type":"link","label":"Toolkits","href":"/langchain/docs/modules/agents/toolkits/","docId":"modules/agents/toolkits/index"}],"href":"/langchain/docs/modules/agents/"},{"type":"category","label":"Callbacks","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Async callbacks","href":"/langchain/docs/modules/callbacks/async_callbacks","docId":"modules/callbacks/async_callbacks"},{"type":"link","label":"Custom callback handlers","href":"/langchain/docs/modules/callbacks/custom_callbacks","docId":"modules/callbacks/custom_callbacks"},{"type":"link","label":"Callbacks for custom chains","href":"/langchain/docs/modules/callbacks/custom_chain","docId":"modules/callbacks/custom_chain"},{"type":"link","label":"Logging to file","href":"/langchain/docs/modules/callbacks/filecallbackhandler","docId":"modules/callbacks/filecallbackhandler"},{"type":"link","label":"Multiple callback handlers","href":"/langchain/docs/modules/callbacks/multiple_callbacks","docId":"modules/callbacks/multiple_callbacks"},{"type":"link","label":"Tags","href":"/langchain/docs/modules/callbacks/tags","docId":"modules/callbacks/tags"},{"type":"link","label":"Token counting","href":"/langchain/docs/modules/callbacks/token_counting","docId":"modules/callbacks/token_counting"}],"href":"/langchain/docs/modules/callbacks/"},{"type":"link","label":"Modules","href":"/langchain/docs/modules/","className":"hidden","docId":"modules/index"}],"href":"/langchain/docs/modules/"},{"type":"category","label":"LangChain Expression Language","collapsed":true,"items":[{"type":"link","label":"Cookbook","href":"/langchain/docs/expression_language/cookbook","docId":"expression_language/cookbook"},{"type":"link","label":"LangChain Expression Language (LCEL)","href":"/langchain/docs/expression_language/","className":"hidden","docId":"expression_language/index"},{"type":"link","label":"Interface","href":"/langchain/docs/expression_language/interface","docId":"expression_language/interface"}],"collapsible":true,"href":"/langchain/docs/expression_language/"},{"type":"category","label":"Guides","collapsed":true,"items":[{"type":"category","label":"Adapters","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"OpenAI Adapter","href":"/langchain/docs/guides/adapters/openai","docId":"guides/adapters/openai"}]},{"type":"link","label":"Debugging","href":"/langchain/docs/guides/debugging","docId":"guides/debugging"},{"type":"category","label":"Deployment","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Template repos","href":"/langchain/docs/guides/deployments/template_repos","docId":"guides/deployments/template_repos"}],"href":"/langchain/docs/guides/deployments/"},{"type":"category","label":"Evaluation","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"String Evaluators","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Criteria Evaluation","href":"/langchain/docs/guides/evaluation/string/criteria_eval_chain","docId":"guides/evaluation/string/criteria_eval_chain"},{"type":"link","label":"Custom String Evaluator","href":"/langchain/docs/guides/evaluation/string/custom","docId":"guides/evaluation/string/custom"},{"type":"link","label":"Embedding Distance","href":"/langchain/docs/guides/evaluation/string/embedding_distance","docId":"guides/evaluation/string/embedding_distance"},{"type":"link","label":"String Distance","href":"/langchain/docs/guides/evaluation/string/string_distance","docId":"guides/evaluation/string/string_distance"}],"href":"/langchain/docs/guides/evaluation/string/"},{"type":"category","label":"Comparison Evaluators","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Custom Pairwise Evaluator","href":"/langchain/docs/guides/evaluation/comparison/custom","docId":"guides/evaluation/comparison/custom"},{"type":"link","label":"Pairwise Embedding Distance","href":"/langchain/docs/guides/evaluation/comparison/pairwise_embedding_distance","docId":"guides/evaluation/comparison/pairwise_embedding_distance"},{"type":"link","label":"Pairwise String Comparison","href":"/langchain/docs/guides/evaluation/comparison/pairwise_string","docId":"guides/evaluation/comparison/pairwise_string"}],"href":"/langchain/docs/guides/evaluation/comparison/"},{"type":"category","label":"Trajectory Evaluators","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Custom Trajectory Evaluator","href":"/langchain/docs/guides/evaluation/trajectory/custom","docId":"guides/evaluation/trajectory/custom"},{"type":"link","label":"Agent Trajectory","href":"/langchain/docs/guides/evaluation/trajectory/trajectory_eval","docId":"guides/evaluation/trajectory/trajectory_eval"}],"href":"/langchain/docs/guides/evaluation/trajectory/"},{"type":"category","label":"Examples","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Comparing Chain Outputs","href":"/langchain/docs/guides/evaluation/examples/comparisons","docId":"guides/evaluation/examples/comparisons"}],"href":"/langchain/docs/guides/evaluation/examples/"}],"href":"/langchain/docs/guides/evaluation/"},{"type":"link","label":"Fallbacks","href":"/langchain/docs/guides/fallbacks","docId":"guides/fallbacks"},{"type":"category","label":"LangSmith","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"LangSmith Walkthrough","href":"/langchain/docs/guides/langsmith/walkthrough","docId":"guides/langsmith/walkthrough"}],"href":"/langchain/docs/guides/langsmith/"},{"type":"link","label":"Run LLMs locally","href":"/langchain/docs/guides/local_llms","docId":"guides/local_llms"},{"type":"link","label":"Model comparison","href":"/langchain/docs/guides/model_laboratory","docId":"guides/model_laboratory"},{"type":"category","label":"Privacy","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Data anonymization with Microsoft Presidio","href":"/langchain/docs/guides/privacy/presidio_data_anonymization","docId":"guides/privacy/presidio_data_anonymization"},{"type":"link","label":"Reversible data anonymization with Microsoft Presidio","href":"/langchain/docs/guides/privacy/presidio_reversible_anonymization","docId":"guides/privacy/presidio_reversible_anonymization"}]},{"type":"link","label":"Pydantic compatibility","href":"/langchain/docs/guides/pydantic_compatibility","docId":"guides/pydantic_compatibility"},{"type":"category","label":"Moderation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Amazon Comprehend Moderation Chain","href":"/langchain/docs/guides/safety/amazon_comprehend_chain","docId":"guides/safety/amazon_comprehend_chain"},{"type":"link","label":"Self-critique chain with constitutional AI","href":"/langchain/docs/guides/safety/constitutional_chain","docId":"guides/safety/constitutional_chain"},{"type":"link","label":"Removing logical fallacies from model output","href":"/langchain/docs/guides/safety/logical_fallacy_chain","docId":"guides/safety/logical_fallacy_chain"},{"type":"link","label":"Moderation","href":"/langchain/docs/guides/safety/moderation","docId":"guides/safety/moderation"}],"href":"/langchain/docs/guides/safety/"}],"collapsible":true,"href":"/langchain/docs/guides"},{"type":"category","label":"Additional resources","collapsed":true,"items":[{"type":"link","label":"Dependents","href":"/langchain/docs/additional_resources/dependents","docId":"additional_resources/dependents"},{"type":"link","label":"Tutorials","href":"/langchain/docs/additional_resources/tutorials","docId":"additional_resources/tutorials"},{"type":"link","label":"YouTube videos","href":"/langchain/docs/additional_resources/youtube","docId":"additional_resources/youtube"},{"type":"link","label":"Gallery","href":"https://github.com/kyrolabs/awesome-langchain"}],"collapsible":true,"href":"/langchain/docs/additional_resources"},{"type":"link","label":"Community navigator","href":"/langchain/docs/community","docId":"community"}],"integrations":[{"type":"category","label":"Integrations","collapsible":false,"items":[{"type":"category","label":"Callbacks","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Argilla","href":"/langchain/docs/integrations/callbacks/argilla","docId":"integrations/callbacks/argilla"},{"type":"link","label":"Context","href":"/langchain/docs/integrations/callbacks/context","docId":"integrations/callbacks/context"},{"type":"link","label":"Infino","href":"/langchain/docs/integrations/callbacks/infino","docId":"integrations/callbacks/infino"},{"type":"link","label":"Label Studio","href":"/langchain/docs/integrations/callbacks/labelstudio","docId":"integrations/callbacks/labelstudio"},{"type":"link","label":"LLMonitor","href":"/langchain/docs/integrations/callbacks/llmonitor","docId":"integrations/callbacks/llmonitor"},{"type":"link","label":"PromptLayer","href":"/langchain/docs/integrations/callbacks/promptlayer","docId":"integrations/callbacks/promptlayer"},{"type":"link","label":"Streamlit","href":"/langchain/docs/integrations/callbacks/streamlit","docId":"integrations/callbacks/streamlit"}],"href":"/langchain/docs/integrations/callbacks/"},{"type":"category","label":"Chat models","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Anthropic","href":"/langchain/docs/integrations/chat/anthropic","docId":"integrations/chat/anthropic"},{"type":"link","label":"Anthropic Functions","href":"/langchain/docs/integrations/chat/anthropic_functions","docId":"integrations/chat/anthropic_functions"},{"type":"link","label":"Anyscale","href":"/langchain/docs/integrations/chat/anyscale","docId":"integrations/chat/anyscale"},{"type":"link","label":"Azure","href":"/langchain/docs/integrations/chat/azure_chat_openai","docId":"integrations/chat/azure_chat_openai"},{"type":"link","label":"AzureML Chat Online Endpoint","href":"/langchain/docs/integrations/chat/azureml_chat_endpoint","docId":"integrations/chat/azureml_chat_endpoint"},{"type":"link","label":"Bedrock Chat","href":"/langchain/docs/integrations/chat/bedrock","docId":"integrations/chat/bedrock"},{"type":"link","label":"ERNIE-Bot Chat","href":"/langchain/docs/integrations/chat/ernie","docId":"integrations/chat/ernie"},{"type":"link","label":"Google Cloud Platform Vertex AI PaLM","href":"/langchain/docs/integrations/chat/google_vertex_ai_palm","docId":"integrations/chat/google_vertex_ai_palm"},{"type":"link","label":"JinaChat","href":"/langchain/docs/integrations/chat/jinachat","docId":"integrations/chat/jinachat"},{"type":"link","label":"\ud83d\ude85 LiteLLM","href":"/langchain/docs/integrations/chat/litellm","docId":"integrations/chat/litellm"},{"type":"link","label":"Llama API","href":"/langchain/docs/integrations/chat/llama_api","docId":"integrations/chat/llama_api"},{"type":"link","label":"Ollama","href":"/langchain/docs/integrations/chat/ollama","docId":"integrations/chat/ollama"},{"type":"link","label":"OpenAI","href":"/langchain/docs/integrations/chat/openai","docId":"integrations/chat/openai"},{"type":"link","label":"PromptLayer ChatOpenAI","href":"/langchain/docs/integrations/chat/promptlayer_chatopenai","docId":"integrations/chat/promptlayer_chatopenai"}],"href":"/langchain/docs/integrations/chat/"},{"type":"category","label":"Chat loaders","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Discord","href":"/langchain/docs/integrations/chat_loaders/discord","docId":"integrations/chat_loaders/discord"},{"type":"link","label":"Facebook Messenger","href":"/langchain/docs/integrations/chat_loaders/facebook","docId":"integrations/chat_loaders/facebook"},{"type":"link","label":"GMail","href":"/langchain/docs/integrations/chat_loaders/gmail","docId":"integrations/chat_loaders/gmail"},{"type":"link","label":"iMessage","href":"/langchain/docs/integrations/chat_loaders/imessage","docId":"integrations/chat_loaders/imessage"},{"type":"link","label":"Slack","href":"/langchain/docs/integrations/chat_loaders/slack","docId":"integrations/chat_loaders/slack"},{"type":"link","label":"Telegram","href":"/langchain/docs/integrations/chat_loaders/telegram","docId":"integrations/chat_loaders/telegram"},{"type":"link","label":"Twitter (via Apify)","href":"/langchain/docs/integrations/chat_loaders/twitter","docId":"integrations/chat_loaders/twitter"},{"type":"link","label":"WhatsApp","href":"/langchain/docs/integrations/chat_loaders/whatsapp","docId":"integrations/chat_loaders/whatsapp"}],"href":"/langchain/docs/integrations/chat_loaders/"},{"type":"category","label":"Document loaders","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Etherscan Loader","href":"/langchain/docs/integrations/document_loaders/Etherscan","docId":"integrations/document_loaders/Etherscan"},{"type":"link","label":"acreom","href":"/langchain/docs/integrations/document_loaders/acreom","docId":"integrations/document_loaders/acreom"},{"type":"link","label":"Airbyte CDK","href":"/langchain/docs/integrations/document_loaders/airbyte_cdk","docId":"integrations/document_loaders/airbyte_cdk"},{"type":"link","label":"Airbyte Gong","href":"/langchain/docs/integrations/document_loaders/airbyte_gong","docId":"integrations/document_loaders/airbyte_gong"},{"type":"link","label":"Airbyte Hubspot","href":"/langchain/docs/integrations/document_loaders/airbyte_hubspot","docId":"integrations/document_loaders/airbyte_hubspot"},{"type":"link","label":"Airbyte JSON","href":"/langchain/docs/integrations/document_loaders/airbyte_json","docId":"integrations/document_loaders/airbyte_json"},{"type":"link","label":"Airbyte Salesforce","href":"/langchain/docs/integrations/document_loaders/airbyte_salesforce","docId":"integrations/document_loaders/airbyte_salesforce"},{"type":"link","label":"Airbyte Shopify","href":"/langchain/docs/integrations/document_loaders/airbyte_shopify","docId":"integrations/document_loaders/airbyte_shopify"},{"type":"link","label":"Airbyte Stripe","href":"/langchain/docs/integrations/document_loaders/airbyte_stripe","docId":"integrations/document_loaders/airbyte_stripe"},{"type":"link","label":"Airbyte Typeform","href":"/langchain/docs/integrations/document_loaders/airbyte_typeform","docId":"integrations/document_loaders/airbyte_typeform"},{"type":"link","label":"Airbyte Zendesk Support","href":"/langchain/docs/integrations/document_loaders/airbyte_zendesk_support","docId":"integrations/document_loaders/airbyte_zendesk_support"},{"type":"link","label":"Airtable","href":"/langchain/docs/integrations/document_loaders/airtable","docId":"integrations/document_loaders/airtable"},{"type":"link","label":"Alibaba Cloud MaxCompute","href":"/langchain/docs/integrations/document_loaders/alibaba_cloud_maxcompute","docId":"integrations/document_loaders/alibaba_cloud_maxcompute"},{"type":"link","label":"Apify Dataset","href":"/langchain/docs/integrations/document_loaders/apify_dataset","docId":"integrations/document_loaders/apify_dataset"},{"type":"link","label":"ArcGIS","href":"/langchain/docs/integrations/document_loaders/arcgis","docId":"integrations/document_loaders/arcgis"},{"type":"link","label":"Arxiv","href":"/langchain/docs/integrations/document_loaders/arxiv","docId":"integrations/document_loaders/arxiv"},{"type":"link","label":"AssemblyAI Audio Transcripts","href":"/langchain/docs/integrations/document_loaders/assemblyai","docId":"integrations/document_loaders/assemblyai"},{"type":"link","label":"Async Chromium","href":"/langchain/docs/integrations/document_loaders/async_chromium","docId":"integrations/document_loaders/async_chromium"},{"type":"link","label":"AsyncHtmlLoader","href":"/langchain/docs/integrations/document_loaders/async_html","docId":"integrations/document_loaders/async_html"},{"type":"link","label":"AWS S3 Directory","href":"/langchain/docs/integrations/document_loaders/aws_s3_directory","docId":"integrations/document_loaders/aws_s3_directory"},{"type":"link","label":"AWS S3 File","href":"/langchain/docs/integrations/document_loaders/aws_s3_file","docId":"integrations/document_loaders/aws_s3_file"},{"type":"link","label":"AZLyrics","href":"/langchain/docs/integrations/document_loaders/azlyrics","docId":"integrations/document_loaders/azlyrics"},{"type":"link","label":"Azure Blob Storage Container","href":"/langchain/docs/integrations/document_loaders/azure_blob_storage_container","docId":"integrations/document_loaders/azure_blob_storage_container"},{"type":"link","label":"Azure Blob Storage File","href":"/langchain/docs/integrations/document_loaders/azure_blob_storage_file","docId":"integrations/document_loaders/azure_blob_storage_file"},{"type":"link","label":"Azure Document Intelligence","href":"/langchain/docs/integrations/document_loaders/azure_document_intelligence","docId":"integrations/document_loaders/azure_document_intelligence"},{"type":"link","label":"BibTeX","href":"/langchain/docs/integrations/document_loaders/bibtex","docId":"integrations/document_loaders/bibtex"},{"type":"link","label":"BiliBili","href":"/langchain/docs/integrations/document_loaders/bilibili","docId":"integrations/document_loaders/bilibili"},{"type":"link","label":"Blackboard","href":"/langchain/docs/integrations/document_loaders/blackboard","docId":"integrations/document_loaders/blackboard"},{"type":"link","label":"Blockchain","href":"/langchain/docs/integrations/document_loaders/blockchain","docId":"integrations/document_loaders/blockchain"},{"type":"link","label":"Brave Search","href":"/langchain/docs/integrations/document_loaders/brave_search","docId":"integrations/document_loaders/brave_search"},{"type":"link","label":"Browserless","href":"/langchain/docs/integrations/document_loaders/browserless","docId":"integrations/document_loaders/browserless"},{"type":"link","label":"ChatGPT Data","href":"/langchain/docs/integrations/document_loaders/chatgpt_loader","docId":"integrations/document_loaders/chatgpt_loader"},{"type":"link","label":"College Confidential","href":"/langchain/docs/integrations/document_loaders/college_confidential","docId":"integrations/document_loaders/college_confidential"},{"type":"link","label":"Concurrent Loader","href":"/langchain/docs/integrations/document_loaders/concurrent","docId":"integrations/document_loaders/concurrent"},{"type":"link","label":"Confluence","href":"/langchain/docs/integrations/document_loaders/confluence","docId":"integrations/document_loaders/confluence"},{"type":"link","label":"CoNLL-U","href":"/langchain/docs/integrations/document_loaders/conll-u","docId":"integrations/document_loaders/conll-u"},{"type":"link","label":"Copy Paste","href":"/langchain/docs/integrations/document_loaders/copypaste","docId":"integrations/document_loaders/copypaste"},{"type":"link","label":"CSV","href":"/langchain/docs/integrations/document_loaders/csv","docId":"integrations/document_loaders/csv"},{"type":"link","label":"Cube Semantic Layer","href":"/langchain/docs/integrations/document_loaders/cube_semantic","docId":"integrations/document_loaders/cube_semantic"},{"type":"link","label":"Datadog Logs","href":"/langchain/docs/integrations/document_loaders/datadog_logs","docId":"integrations/document_loaders/datadog_logs"},{"type":"link","label":"Diffbot","href":"/langchain/docs/integrations/document_loaders/diffbot","docId":"integrations/document_loaders/diffbot"},{"type":"link","label":"Discord","href":"/langchain/docs/integrations/document_loaders/discord","docId":"integrations/document_loaders/discord"},{"type":"link","label":"Docugami","href":"/langchain/docs/integrations/document_loaders/docugami","docId":"integrations/document_loaders/docugami"},{"type":"link","label":"Dropbox","href":"/langchain/docs/integrations/document_loaders/dropbox","docId":"integrations/document_loaders/dropbox"},{"type":"link","label":"DuckDB","href":"/langchain/docs/integrations/document_loaders/duckdb","docId":"integrations/document_loaders/duckdb"},{"type":"link","label":"Email","href":"/langchain/docs/integrations/document_loaders/email","docId":"integrations/document_loaders/email"},{"type":"link","label":"Embaas","href":"/langchain/docs/integrations/document_loaders/embaas","docId":"integrations/document_loaders/embaas"},{"type":"link","label":"EPub","href":"/langchain/docs/integrations/document_loaders/epub","docId":"integrations/document_loaders/epub"},{"type":"link","label":"EverNote","href":"/langchain/docs/integrations/document_loaders/evernote","docId":"integrations/document_loaders/evernote"},{"type":"category","label":"example_data","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Notebook","href":"/langchain/docs/integrations/document_loaders/example_data/notebook","docId":"integrations/document_loaders/example_data/notebook"}]},{"type":"link","label":"Microsoft Excel","href":"/langchain/docs/integrations/document_loaders/excel","docId":"integrations/document_loaders/excel"},{"type":"link","label":"Facebook Chat","href":"/langchain/docs/integrations/document_loaders/facebook_chat","docId":"integrations/document_loaders/facebook_chat"},{"type":"link","label":"Fauna","href":"/langchain/docs/integrations/document_loaders/fauna","docId":"integrations/document_loaders/fauna"},{"type":"link","label":"Figma","href":"/langchain/docs/integrations/document_loaders/figma","docId":"integrations/document_loaders/figma"},{"type":"link","label":"Geopandas","href":"/langchain/docs/integrations/document_loaders/geopandas","docId":"integrations/document_loaders/geopandas"},{"type":"link","label":"Git","href":"/langchain/docs/integrations/document_loaders/git","docId":"integrations/document_loaders/git"},{"type":"link","label":"GitBook","href":"/langchain/docs/integrations/document_loaders/gitbook","docId":"integrations/document_loaders/gitbook"},{"type":"link","label":"GitHub","href":"/langchain/docs/integrations/document_loaders/github","docId":"integrations/document_loaders/github"},{"type":"link","label":"Google BigQuery","href":"/langchain/docs/integrations/document_loaders/google_bigquery","docId":"integrations/document_loaders/google_bigquery"},{"type":"link","label":"Google Cloud Storage Directory","href":"/langchain/docs/integrations/document_loaders/google_cloud_storage_directory","docId":"integrations/document_loaders/google_cloud_storage_directory"},{"type":"link","label":"Google Cloud Storage File","href":"/langchain/docs/integrations/document_loaders/google_cloud_storage_file","docId":"integrations/document_loaders/google_cloud_storage_file"},{"type":"link","label":"Google Drive","href":"/langchain/docs/integrations/document_loaders/google_drive","docId":"integrations/document_loaders/google_drive"},{"type":"link","label":"Grobid","href":"/langchain/docs/integrations/document_loaders/grobid","docId":"integrations/document_loaders/grobid"},{"type":"link","label":"Gutenberg","href":"/langchain/docs/integrations/document_loaders/gutenberg","docId":"integrations/document_loaders/gutenberg"},{"type":"link","label":"Hacker News","href":"/langchain/docs/integrations/document_loaders/hacker_news","docId":"integrations/document_loaders/hacker_news"},{"type":"link","label":"Huawei OBS Directory","href":"/langchain/docs/integrations/document_loaders/huawei_obs_directory","docId":"integrations/document_loaders/huawei_obs_directory"},{"type":"link","label":"Huawei OBS File","href":"/langchain/docs/integrations/document_loaders/huawei_obs_file","docId":"integrations/document_loaders/huawei_obs_file"},{"type":"link","label":"HuggingFace dataset","href":"/langchain/docs/integrations/document_loaders/hugging_face_dataset","docId":"integrations/document_loaders/hugging_face_dataset"},{"type":"link","label":"iFixit","href":"/langchain/docs/integrations/document_loaders/ifixit","docId":"integrations/document_loaders/ifixit"},{"type":"link","label":"Images","href":"/langchain/docs/integrations/document_loaders/image","docId":"integrations/document_loaders/image"},{"type":"link","label":"Image captions","href":"/langchain/docs/integrations/document_loaders/image_captions","docId":"integrations/document_loaders/image_captions"},{"type":"link","label":"IMSDb","href":"/langchain/docs/integrations/document_loaders/imsdb","docId":"integrations/document_loaders/imsdb"},{"type":"link","label":"Iugu","href":"/langchain/docs/integrations/document_loaders/iugu","docId":"integrations/document_loaders/iugu"},{"type":"link","label":"Joplin","href":"/langchain/docs/integrations/document_loaders/joplin","docId":"integrations/document_loaders/joplin"},{"type":"link","label":"Jupyter Notebook","href":"/langchain/docs/integrations/document_loaders/jupyter_notebook","docId":"integrations/document_loaders/jupyter_notebook"},{"type":"link","label":"LarkSuite (FeiShu)","href":"/langchain/docs/integrations/document_loaders/larksuite","docId":"integrations/document_loaders/larksuite"},{"type":"link","label":"Mastodon","href":"/langchain/docs/integrations/document_loaders/mastodon","docId":"integrations/document_loaders/mastodon"},{"type":"link","label":"MediaWikiDump","href":"/langchain/docs/integrations/document_loaders/mediawikidump","docId":"integrations/document_loaders/mediawikidump"},{"type":"link","label":"MergeDocLoader","href":"/langchain/docs/integrations/document_loaders/merge_doc_loader","docId":"integrations/document_loaders/merge_doc_loader"},{"type":"link","label":"mhtml","href":"/langchain/docs/integrations/document_loaders/mhtml","docId":"integrations/document_loaders/mhtml"},{"type":"link","label":"Microsoft OneDrive","href":"/langchain/docs/integrations/document_loaders/microsoft_onedrive","docId":"integrations/document_loaders/microsoft_onedrive"},{"type":"link","label":"Microsoft PowerPoint","href":"/langchain/docs/integrations/document_loaders/microsoft_powerpoint","docId":"integrations/document_loaders/microsoft_powerpoint"},{"type":"link","label":"Microsoft SharePoint","href":"/langchain/docs/integrations/document_loaders/microsoft_sharepoint","docId":"integrations/document_loaders/microsoft_sharepoint"},{"type":"link","label":"Microsoft Word","href":"/langchain/docs/integrations/document_loaders/microsoft_word","docId":"integrations/document_loaders/microsoft_word"},{"type":"link","label":"Modern Treasury","href":"/langchain/docs/integrations/document_loaders/modern_treasury","docId":"integrations/document_loaders/modern_treasury"},{"type":"link","label":"News URL","href":"/langchain/docs/integrations/document_loaders/news","docId":"integrations/document_loaders/news"},{"type":"link","label":"Notion DB 1/2","href":"/langchain/docs/integrations/document_loaders/notion","docId":"integrations/document_loaders/notion"},{"type":"link","label":"Notion DB 2/2","href":"/langchain/docs/integrations/document_loaders/notiondb","docId":"integrations/document_loaders/notiondb"},{"type":"link","label":"Nuclia Understanding API document loader","href":"/langchain/docs/integrations/document_loaders/nuclia","docId":"integrations/document_loaders/nuclia"},{"type":"link","label":"Obsidian","href":"/langchain/docs/integrations/document_loaders/obsidian","docId":"integrations/document_loaders/obsidian"},{"type":"link","label":"Open Document Format (ODT)","href":"/langchain/docs/integrations/document_loaders/odt","docId":"integrations/document_loaders/odt"},{"type":"link","label":"Open City Data","href":"/langchain/docs/integrations/document_loaders/open_city_data","docId":"integrations/document_loaders/open_city_data"},{"type":"link","label":"Org-mode","href":"/langchain/docs/integrations/document_loaders/org_mode","docId":"integrations/document_loaders/org_mode"},{"type":"link","label":"Pandas DataFrame","href":"/langchain/docs/integrations/document_loaders/pandas_dataframe","docId":"integrations/document_loaders/pandas_dataframe"},{"type":"link","label":"Amazon Textract","href":"/langchain/docs/integrations/document_loaders/pdf-amazonTextractPDFLoader","docId":"integrations/document_loaders/pdf-amazonTextractPDFLoader"},{"type":"link","label":"Polars DataFrame","href":"/langchain/docs/integrations/document_loaders/polars_dataframe","docId":"integrations/document_loaders/polars_dataframe"},{"type":"link","label":"Psychic","href":"/langchain/docs/integrations/document_loaders/psychic","docId":"integrations/document_loaders/psychic"},{"type":"link","label":"PubMed","href":"/langchain/docs/integrations/document_loaders/pubmed","docId":"integrations/document_loaders/pubmed"},{"type":"link","label":"PySpark DataFrame Loader","href":"/langchain/docs/integrations/document_loaders/pyspark_dataframe","docId":"integrations/document_loaders/pyspark_dataframe"},{"type":"link","label":"ReadTheDocs Documentation","href":"/langchain/docs/integrations/document_loaders/readthedocs_documentation","docId":"integrations/document_loaders/readthedocs_documentation"},{"type":"link","label":"Recursive URL Loader","href":"/langchain/docs/integrations/document_loaders/recursive_url_loader","docId":"integrations/document_loaders/recursive_url_loader"},{"type":"link","label":"Reddit","href":"/langchain/docs/integrations/document_loaders/reddit","docId":"integrations/document_loaders/reddit"},{"type":"link","label":"Roam","href":"/langchain/docs/integrations/document_loaders/roam","docId":"integrations/document_loaders/roam"},{"type":"link","label":"Rockset","href":"/langchain/docs/integrations/document_loaders/rockset","docId":"integrations/document_loaders/rockset"},{"type":"link","label":"RSS Feeds","href":"/langchain/docs/integrations/document_loaders/rss","docId":"integrations/document_loaders/rss"},{"type":"link","label":"RST","href":"/langchain/docs/integrations/document_loaders/rst","docId":"integrations/document_loaders/rst"},{"type":"link","label":"Sitemap","href":"/langchain/docs/integrations/document_loaders/sitemap","docId":"integrations/document_loaders/sitemap"},{"type":"link","label":"Slack","href":"/langchain/docs/integrations/document_loaders/slack","docId":"integrations/document_loaders/slack"},{"type":"link","label":"Snowflake","href":"/langchain/docs/integrations/document_loaders/snowflake","docId":"integrations/document_loaders/snowflake"},{"type":"link","label":"Source Code","href":"/langchain/docs/integrations/document_loaders/source_code","docId":"integrations/document_loaders/source_code"},{"type":"link","label":"Spreedly","href":"/langchain/docs/integrations/document_loaders/spreedly","docId":"integrations/document_loaders/spreedly"},{"type":"link","label":"Stripe","href":"/langchain/docs/integrations/document_loaders/stripe","docId":"integrations/document_loaders/stripe"},{"type":"link","label":"Subtitle","href":"/langchain/docs/integrations/document_loaders/subtitle","docId":"integrations/document_loaders/subtitle"},{"type":"link","label":"Telegram","href":"/langchain/docs/integrations/document_loaders/telegram","docId":"integrations/document_loaders/telegram"},{"type":"link","label":"Tencent COS Directory","href":"/langchain/docs/integrations/document_loaders/tencent_cos_directory","docId":"integrations/document_loaders/tencent_cos_directory"},{"type":"link","label":"Tencent COS File","href":"/langchain/docs/integrations/document_loaders/tencent_cos_file","docId":"integrations/document_loaders/tencent_cos_file"},{"type":"link","label":"TensorFlow Datasets","href":"/langchain/docs/integrations/document_loaders/tensorflow_datasets","docId":"integrations/document_loaders/tensorflow_datasets"},{"type":"link","label":"2Markdown","href":"/langchain/docs/integrations/document_loaders/tomarkdown","docId":"integrations/document_loaders/tomarkdown"},{"type":"link","label":"TOML","href":"/langchain/docs/integrations/document_loaders/toml","docId":"integrations/document_loaders/toml"},{"type":"link","label":"Trello","href":"/langchain/docs/integrations/document_loaders/trello","docId":"integrations/document_loaders/trello"},{"type":"link","label":"TSV","href":"/langchain/docs/integrations/document_loaders/tsv","docId":"integrations/document_loaders/tsv"},{"type":"link","label":"Twitter","href":"/langchain/docs/integrations/document_loaders/twitter","docId":"integrations/document_loaders/twitter"},{"type":"link","label":"Unstructured File","href":"/langchain/docs/integrations/document_loaders/unstructured_file","docId":"integrations/document_loaders/unstructured_file"},{"type":"link","label":"URL","href":"/langchain/docs/integrations/document_loaders/url","docId":"integrations/document_loaders/url"},{"type":"link","label":"Weather","href":"/langchain/docs/integrations/document_loaders/weather","docId":"integrations/document_loaders/weather"},{"type":"link","label":"WebBaseLoader","href":"/langchain/docs/integrations/document_loaders/web_base","docId":"integrations/document_loaders/web_base"},{"type":"link","label":"WhatsApp Chat","href":"/langchain/docs/integrations/document_loaders/whatsapp_chat","docId":"integrations/document_loaders/whatsapp_chat"},{"type":"link","label":"Wikipedia","href":"/langchain/docs/integrations/document_loaders/wikipedia","docId":"integrations/document_loaders/wikipedia"},{"type":"link","label":"XML","href":"/langchain/docs/integrations/document_loaders/xml","docId":"integrations/document_loaders/xml"},{"type":"link","label":"Xorbits Pandas DataFrame","href":"/langchain/docs/integrations/document_loaders/xorbits","docId":"integrations/document_loaders/xorbits"},{"type":"link","label":"Loading documents from a YouTube url","href":"/langchain/docs/integrations/document_loaders/youtube_audio","docId":"integrations/document_loaders/youtube_audio"},{"type":"link","label":"YouTube transcripts","href":"/langchain/docs/integrations/document_loaders/youtube_transcript","docId":"integrations/document_loaders/youtube_transcript"}],"href":"/langchain/docs/integrations/document_loaders/"},{"type":"category","label":"Document transformers","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Beautiful Soup","href":"/langchain/docs/integrations/document_transformers/beautiful_soup","docId":"integrations/document_transformers/beautiful_soup"},{"type":"link","label":"docai","href":"/langchain/docs/integrations/document_transformers/docai","docId":"integrations/document_transformers/docai"},{"type":"link","label":"Doctran Extract Properties","href":"/langchain/docs/integrations/document_transformers/doctran_extract_properties","docId":"integrations/document_transformers/doctran_extract_properties"},{"type":"link","label":"Doctran Interrogate Documents","href":"/langchain/docs/integrations/document_transformers/doctran_interrogate_document","docId":"integrations/document_transformers/doctran_interrogate_document"},{"type":"link","label":"Doctran Translate Documents","href":"/langchain/docs/integrations/document_transformers/doctran_translate_document","docId":"integrations/document_transformers/doctran_translate_document"},{"type":"link","label":"html2text","href":"/langchain/docs/integrations/document_transformers/html2text","docId":"integrations/document_transformers/html2text"},{"type":"link","label":"Nuclia Understanding API document transformer","href":"/langchain/docs/integrations/document_transformers/nuclia_transformer","docId":"integrations/document_transformers/nuclia_transformer"},{"type":"link","label":"OpenAI Functions Metadata Tagger","href":"/langchain/docs/integrations/document_transformers/openai_metadata_tagger","docId":"integrations/document_transformers/openai_metadata_tagger"}],"href":"/langchain/docs/integrations/document_transformers/"},{"type":"category","label":"LLMs","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"AI21","href":"/langchain/docs/integrations/llms/ai21","docId":"integrations/llms/ai21"},{"type":"link","label":"Aleph Alpha","href":"/langchain/docs/integrations/llms/aleph_alpha","docId":"integrations/llms/aleph_alpha"},{"type":"link","label":"Amazon API Gateway","href":"/langchain/docs/integrations/llms/amazon_api_gateway","docId":"integrations/llms/amazon_api_gateway"},{"type":"link","label":"Anyscale","href":"/langchain/docs/integrations/llms/anyscale","docId":"integrations/llms/anyscale"},{"type":"link","label":"Azure ML","href":"/langchain/docs/integrations/llms/azure_ml","docId":"integrations/llms/azure_ml"},{"type":"link","label":"Azure OpenAI","href":"/langchain/docs/integrations/llms/azure_openai","docId":"integrations/llms/azure_openai"},{"type":"link","label":"Banana","href":"/langchain/docs/integrations/llms/banana","docId":"integrations/llms/banana"},{"type":"link","label":"Baseten","href":"/langchain/docs/integrations/llms/baseten","docId":"integrations/llms/baseten"},{"type":"link","label":"Beam","href":"/langchain/docs/integrations/llms/beam","docId":"integrations/llms/beam"},{"type":"link","label":"Bedrock","href":"/langchain/docs/integrations/llms/bedrock","docId":"integrations/llms/bedrock"},{"type":"link","label":"Bittensor","href":"/langchain/docs/integrations/llms/bittensor","docId":"integrations/llms/bittensor"},{"type":"link","label":"CerebriumAI","href":"/langchain/docs/integrations/llms/cerebriumai","docId":"integrations/llms/cerebriumai"},{"type":"link","label":"ChatGLM","href":"/langchain/docs/integrations/llms/chatglm","docId":"integrations/llms/chatglm"},{"type":"link","label":"Clarifai","href":"/langchain/docs/integrations/llms/clarifai","docId":"integrations/llms/clarifai"},{"type":"link","label":"Cohere","href":"/langchain/docs/integrations/llms/cohere","docId":"integrations/llms/cohere"},{"type":"link","label":"C Transformers","href":"/langchain/docs/integrations/llms/ctransformers","docId":"integrations/llms/ctransformers"},{"type":"link","label":"Databricks","href":"/langchain/docs/integrations/llms/databricks","docId":"integrations/llms/databricks"},{"type":"link","label":"DeepInfra","href":"/langchain/docs/integrations/llms/deepinfra","docId":"integrations/llms/deepinfra"},{"type":"link","label":"DeepSparse","href":"/langchain/docs/integrations/llms/deepsparse","docId":"integrations/llms/deepsparse"},{"type":"link","label":"Eden AI","href":"/langchain/docs/integrations/llms/edenai","docId":"integrations/llms/edenai"},{"type":"link","label":"Fireworks","href":"/langchain/docs/integrations/llms/fireworks","docId":"integrations/llms/fireworks"},{"type":"link","label":"ForefrontAI","href":"/langchain/docs/integrations/llms/forefrontai","docId":"integrations/llms/forefrontai"},{"type":"link","label":"Google Vertex AI PaLM","href":"/langchain/docs/integrations/llms/google_vertex_ai_palm","docId":"integrations/llms/google_vertex_ai_palm"},{"type":"link","label":"GooseAI","href":"/langchain/docs/integrations/llms/gooseai","docId":"integrations/llms/gooseai"},{"type":"link","label":"GPT4All","href":"/langchain/docs/integrations/llms/gpt4all","docId":"integrations/llms/gpt4all"},{"type":"link","label":"Hugging Face Hub","href":"/langchain/docs/integrations/llms/huggingface_hub","docId":"integrations/llms/huggingface_hub"},{"type":"link","label":"Hugging Face Local Pipelines","href":"/langchain/docs/integrations/llms/huggingface_pipelines","docId":"integrations/llms/huggingface_pipelines"},{"type":"link","label":"Huggingface TextGen Inference","href":"/langchain/docs/integrations/llms/huggingface_textgen_inference","docId":"integrations/llms/huggingface_textgen_inference"},{"type":"link","label":"JSONFormer","href":"/langchain/docs/integrations/llms/jsonformer_experimental","docId":"integrations/llms/jsonformer_experimental"},{"type":"link","label":"KoboldAI API","href":"/langchain/docs/integrations/llms/koboldai","docId":"integrations/llms/koboldai"},{"type":"link","label":"Llama.cpp","href":"/langchain/docs/integrations/llms/llamacpp","docId":"integrations/llms/llamacpp"},{"type":"link","label":"LLM Caching integrations","href":"/langchain/docs/integrations/llms/llm_caching","docId":"integrations/llms/llm_caching"},{"type":"link","label":"Manifest","href":"/langchain/docs/integrations/llms/manifest","docId":"integrations/llms/manifest"},{"type":"link","label":"Minimax","href":"/langchain/docs/integrations/llms/minimax","docId":"integrations/llms/minimax"},{"type":"link","label":"Modal","href":"/langchain/docs/integrations/llms/modal","docId":"integrations/llms/modal"},{"type":"link","label":"MosaicML","href":"/langchain/docs/integrations/llms/mosaicml","docId":"integrations/llms/mosaicml"},{"type":"link","label":"NLP Cloud","href":"/langchain/docs/integrations/llms/nlpcloud","docId":"integrations/llms/nlpcloud"},{"type":"link","label":"OctoAI","href":"/langchain/docs/integrations/llms/octoai","docId":"integrations/llms/octoai"},{"type":"link","label":"Ollama","href":"/langchain/docs/integrations/llms/ollama","docId":"integrations/llms/ollama"},{"type":"link","label":"OpaquePrompts","href":"/langchain/docs/integrations/llms/opaqueprompts","docId":"integrations/llms/opaqueprompts"},{"type":"link","label":"OpenAI","href":"/langchain/docs/integrations/llms/openai","docId":"integrations/llms/openai"},{"type":"link","label":"OpenLLM","href":"/langchain/docs/integrations/llms/openllm","docId":"integrations/llms/openllm"},{"type":"link","label":"OpenLM","href":"/langchain/docs/integrations/llms/openlm","docId":"integrations/llms/openlm"},{"type":"link","label":"Petals","href":"/langchain/docs/integrations/llms/petals","docId":"integrations/llms/petals"},{"type":"link","label":"PipelineAI","href":"/langchain/docs/integrations/llms/pipelineai","docId":"integrations/llms/pipelineai"},{"type":"link","label":"Predibase","href":"/langchain/docs/integrations/llms/predibase","docId":"integrations/llms/predibase"},{"type":"link","label":"Prediction Guard","href":"/langchain/docs/integrations/llms/predictionguard","docId":"integrations/llms/predictionguard"},{"type":"link","label":"PromptLayer OpenAI","href":"/langchain/docs/integrations/llms/promptlayer_openai","docId":"integrations/llms/promptlayer_openai"},{"type":"link","label":"RELLM","href":"/langchain/docs/integrations/llms/rellm_experimental","docId":"integrations/llms/rellm_experimental"},{"type":"link","label":"Replicate","href":"/langchain/docs/integrations/llms/replicate","docId":"integrations/llms/replicate"},{"type":"link","label":"Runhouse","href":"/langchain/docs/integrations/llms/runhouse","docId":"integrations/llms/runhouse"},{"type":"link","label":"SageMakerEndpoint","href":"/langchain/docs/integrations/llms/sagemaker","docId":"integrations/llms/sagemaker"},{"type":"link","label":"StochasticAI","href":"/langchain/docs/integrations/llms/stochasticai","docId":"integrations/llms/stochasticai"},{"type":"link","label":"Nebula (Symbl.ai)","href":"/langchain/docs/integrations/llms/symblai_nebula","docId":"integrations/llms/symblai_nebula"},{"type":"link","label":"TextGen","href":"/langchain/docs/integrations/llms/textgen","docId":"integrations/llms/textgen"},{"type":"link","label":"Titan Takeoff","href":"/langchain/docs/integrations/llms/titan_takeoff","docId":"integrations/llms/titan_takeoff"},{"type":"link","label":"Tongyi Qwen","href":"/langchain/docs/integrations/llms/tongyi","docId":"integrations/llms/tongyi"},{"type":"link","label":"vLLM","href":"/langchain/docs/integrations/llms/vllm","docId":"integrations/llms/vllm"},{"type":"link","label":"Writer","href":"/langchain/docs/integrations/llms/writer","docId":"integrations/llms/writer"},{"type":"link","label":"Xorbits Inference (Xinference)","href":"/langchain/docs/integrations/llms/xinference","docId":"integrations/llms/xinference"}],"href":"/langchain/docs/integrations/llms/"},{"type":"category","label":"Memory","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Cassandra Chat Message History","href":"/langchain/docs/integrations/memory/cassandra_chat_message_history","docId":"integrations/memory/cassandra_chat_message_history"},{"type":"link","label":"Dynamodb Chat Message History","href":"/langchain/docs/integrations/memory/dynamodb_chat_message_history","docId":"integrations/memory/dynamodb_chat_message_history"},{"type":"link","label":"Entity Memory with SQLite storage","href":"/langchain/docs/integrations/memory/entity_memory_with_sqlite","docId":"integrations/memory/entity_memory_with_sqlite"},{"type":"link","label":"Momento Chat Message History","href":"/langchain/docs/integrations/memory/momento_chat_message_history","docId":"integrations/memory/momento_chat_message_history"},{"type":"link","label":"Mongodb Chat Message History","href":"/langchain/docs/integrations/memory/mongodb_chat_message_history","docId":"integrations/memory/mongodb_chat_message_history"},{"type":"link","label":"Mot\xf6rhead Memory","href":"/langchain/docs/integrations/memory/motorhead_memory","docId":"integrations/memory/motorhead_memory"},{"type":"link","label":"Mot\xf6rhead Memory (Managed)","href":"/langchain/docs/integrations/memory/motorhead_memory_managed","docId":"integrations/memory/motorhead_memory_managed"},{"type":"link","label":"Postgres Chat Message History","href":"/langchain/docs/integrations/memory/postgres_chat_message_history","docId":"integrations/memory/postgres_chat_message_history"},{"type":"link","label":"Redis Chat Message History","href":"/langchain/docs/integrations/memory/redis_chat_message_history","docId":"integrations/memory/redis_chat_message_history"},{"type":"link","label":"Rockset Chat Message History","href":"/langchain/docs/integrations/memory/rockset_chat_message_history","docId":"integrations/memory/rockset_chat_message_history"},{"type":"link","label":"SQL Chat Message History","href":"/langchain/docs/integrations/memory/sql_chat_message_history","docId":"integrations/memory/sql_chat_message_history"},{"type":"link","label":"Streamlit Chat Message History","href":"/langchain/docs/integrations/memory/streamlit_chat_message_history","docId":"integrations/memory/streamlit_chat_message_history"},{"type":"link","label":"Xata chat memory","href":"/langchain/docs/integrations/memory/xata_chat_message_history","docId":"integrations/memory/xata_chat_message_history"},{"type":"link","label":"Zep Memory","href":"/langchain/docs/integrations/memory/zep_memory","docId":"integrations/memory/zep_memory"}],"href":"/langchain/docs/integrations/memory/"},{"type":"category","label":"Retrievers","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Amazon Kendra","href":"/langchain/docs/integrations/retrievers/amazon_kendra_retriever","docId":"integrations/retrievers/amazon_kendra_retriever"},{"type":"link","label":"Arxiv","href":"/langchain/docs/integrations/retrievers/arxiv","docId":"integrations/retrievers/arxiv"},{"type":"link","label":"Azure Cognitive Search","href":"/langchain/docs/integrations/retrievers/azure_cognitive_search","docId":"integrations/retrievers/azure_cognitive_search"},{"type":"link","label":"BM25","href":"/langchain/docs/integrations/retrievers/bm25","docId":"integrations/retrievers/bm25"},{"type":"link","label":"Chaindesk","href":"/langchain/docs/integrations/retrievers/chaindesk","docId":"integrations/retrievers/chaindesk"},{"type":"link","label":"ChatGPT Plugin","href":"/langchain/docs/integrations/retrievers/chatgpt-plugin","docId":"integrations/retrievers/chatgpt-plugin"},{"type":"link","label":"Cohere Reranker","href":"/langchain/docs/integrations/retrievers/cohere-reranker","docId":"integrations/retrievers/cohere-reranker"},{"type":"link","label":"DocArray Retriever","href":"/langchain/docs/integrations/retrievers/docarray_retriever","docId":"integrations/retrievers/docarray_retriever"},{"type":"link","label":"ElasticSearch BM25","href":"/langchain/docs/integrations/retrievers/elastic_search_bm25","docId":"integrations/retrievers/elastic_search_bm25"},{"type":"link","label":"Google Cloud Enterprise Search","href":"/langchain/docs/integrations/retrievers/google_cloud_enterprise_search","docId":"integrations/retrievers/google_cloud_enterprise_search"},{"type":"link","label":"Google Drive Retriever","href":"/langchain/docs/integrations/retrievers/google_drive","docId":"integrations/retrievers/google_drive"},{"type":"link","label":"kNN","href":"/langchain/docs/integrations/retrievers/knn","docId":"integrations/retrievers/knn"},{"type":"link","label":"LOTR (Merger Retriever)","href":"/langchain/docs/integrations/retrievers/merger_retriever","docId":"integrations/retrievers/merger_retriever"},{"type":"link","label":"Metal","href":"/langchain/docs/integrations/retrievers/metal","docId":"integrations/retrievers/metal"},{"type":"link","label":"Pinecone Hybrid Search","href":"/langchain/docs/integrations/retrievers/pinecone_hybrid_search","docId":"integrations/retrievers/pinecone_hybrid_search"},{"type":"link","label":"PubMed","href":"/langchain/docs/integrations/retrievers/pubmed","docId":"integrations/retrievers/pubmed"},{"type":"link","label":"RePhraseQueryRetriever","href":"/langchain/docs/integrations/retrievers/re_phrase","docId":"integrations/retrievers/re_phrase"},{"type":"link","label":"SVM","href":"/langchain/docs/integrations/retrievers/svm","docId":"integrations/retrievers/svm"},{"type":"link","label":"TF-IDF","href":"/langchain/docs/integrations/retrievers/tf_idf","docId":"integrations/retrievers/tf_idf"},{"type":"link","label":"Vespa","href":"/langchain/docs/integrations/retrievers/vespa","docId":"integrations/retrievers/vespa"},{"type":"link","label":"Weaviate Hybrid Search","href":"/langchain/docs/integrations/retrievers/weaviate-hybrid","docId":"integrations/retrievers/weaviate-hybrid"},{"type":"link","label":"Wikipedia","href":"/langchain/docs/integrations/retrievers/wikipedia","docId":"integrations/retrievers/wikipedia"},{"type":"link","label":"Zep","href":"/langchain/docs/integrations/retrievers/zep_memorystore","docId":"integrations/retrievers/zep_memorystore"}],"href":"/langchain/docs/integrations/retrievers/"},{"type":"category","label":"Text embedding models","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"AwaEmbedding","href":"/langchain/docs/integrations/text_embedding/Awa","docId":"integrations/text_embedding/Awa"},{"type":"link","label":"Aleph Alpha","href":"/langchain/docs/integrations/text_embedding/aleph_alpha","docId":"integrations/text_embedding/aleph_alpha"},{"type":"link","label":"AzureOpenAI","href":"/langchain/docs/integrations/text_embedding/azureopenai","docId":"integrations/text_embedding/azureopenai"},{"type":"link","label":"Bedrock Embeddings","href":"/langchain/docs/integrations/text_embedding/bedrock","docId":"integrations/text_embedding/bedrock"},{"type":"link","label":"BGE Hugging Face Embeddings","href":"/langchain/docs/integrations/text_embedding/bge_huggingface","docId":"integrations/text_embedding/bge_huggingface"},{"type":"link","label":"Clarifai","href":"/langchain/docs/integrations/text_embedding/clarifai","docId":"integrations/text_embedding/clarifai"},{"type":"link","label":"Cohere","href":"/langchain/docs/integrations/text_embedding/cohere","docId":"integrations/text_embedding/cohere"},{"type":"link","label":"DashScope","href":"/langchain/docs/integrations/text_embedding/dashscope","docId":"integrations/text_embedding/dashscope"},{"type":"link","label":"DeepInfra","href":"/langchain/docs/integrations/text_embedding/deepinfra","docId":"integrations/text_embedding/deepinfra"},{"type":"link","label":"EDEN AI","href":"/langchain/docs/integrations/text_embedding/edenai","docId":"integrations/text_embedding/edenai"},{"type":"link","label":"Elasticsearch","href":"/langchain/docs/integrations/text_embedding/elasticsearch","docId":"integrations/text_embedding/elasticsearch"},{"type":"link","label":"Embaas","href":"/langchain/docs/integrations/text_embedding/embaas","docId":"integrations/text_embedding/embaas"},{"type":"link","label":"ERNIE Embedding-V1","href":"/langchain/docs/integrations/text_embedding/ernie","docId":"integrations/text_embedding/ernie"},{"type":"link","label":"Fake Embeddings","href":"/langchain/docs/integrations/text_embedding/fake","docId":"integrations/text_embedding/fake"},{"type":"link","label":"Google Cloud Platform Vertex AI PaLM","href":"/langchain/docs/integrations/text_embedding/google_vertex_ai_palm","docId":"integrations/text_embedding/google_vertex_ai_palm"},{"type":"link","label":"GPT4All","href":"/langchain/docs/integrations/text_embedding/gpt4all","docId":"integrations/text_embedding/gpt4all"},{"type":"link","label":"Hugging Face","href":"/langchain/docs/integrations/text_embedding/huggingfacehub","docId":"integrations/text_embedding/huggingfacehub"},{"type":"link","label":"InstructEmbeddings","href":"/langchain/docs/integrations/text_embedding/instruct_embeddings","docId":"integrations/text_embedding/instruct_embeddings"},{"type":"link","label":"Jina","href":"/langchain/docs/integrations/text_embedding/jina","docId":"integrations/text_embedding/jina"},{"type":"link","label":"Llama-cpp","href":"/langchain/docs/integrations/text_embedding/llamacpp","docId":"integrations/text_embedding/llamacpp"},{"type":"link","label":"LocalAI","href":"/langchain/docs/integrations/text_embedding/localai","docId":"integrations/text_embedding/localai"},{"type":"link","label":"MiniMax","href":"/langchain/docs/integrations/text_embedding/minimax","docId":"integrations/text_embedding/minimax"},{"type":"link","label":"ModelScope","href":"/langchain/docs/integrations/text_embedding/modelscope_hub","docId":"integrations/text_embedding/modelscope_hub"},{"type":"link","label":"MosaicML embeddings","href":"/langchain/docs/integrations/text_embedding/mosaicml","docId":"integrations/text_embedding/mosaicml"},{"type":"link","label":"NLP Cloud","href":"/langchain/docs/integrations/text_embedding/nlp_cloud","docId":"integrations/text_embedding/nlp_cloud"},{"type":"link","label":"OpenAI","href":"/langchain/docs/integrations/text_embedding/openai","docId":"integrations/text_embedding/openai"},{"type":"link","label":"SageMaker Endpoint Embeddings","href":"/langchain/docs/integrations/text_embedding/sagemaker-endpoint","docId":"integrations/text_embedding/sagemaker-endpoint"},{"type":"link","label":"Self Hosted Embeddings","href":"/langchain/docs/integrations/text_embedding/self-hosted","docId":"integrations/text_embedding/self-hosted"},{"type":"link","label":"Sentence Transformers Embeddings","href":"/langchain/docs/integrations/text_embedding/sentence_transformers","docId":"integrations/text_embedding/sentence_transformers"},{"type":"link","label":"Spacy Embedding","href":"/langchain/docs/integrations/text_embedding/spacy_embedding","docId":"integrations/text_embedding/spacy_embedding"},{"type":"link","label":"TensorflowHub","href":"/langchain/docs/integrations/text_embedding/tensorflowhub","docId":"integrations/text_embedding/tensorflowhub"},{"type":"link","label":"Xorbits inference (Xinference)","href":"/langchain/docs/integrations/text_embedding/xinference","docId":"integrations/text_embedding/xinference"}],"href":"/langchain/docs/integrations/text_embedding/"},{"type":"category","label":"Agents & Toolkits","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"AINetwork","href":"/langchain/docs/integrations/toolkits/ainetwork","docId":"integrations/toolkits/ainetwork"},{"type":"link","label":"Airbyte Question Answering","href":"/langchain/docs/integrations/toolkits/airbyte_structured_qa","docId":"integrations/toolkits/airbyte_structured_qa"},{"type":"link","label":"Amadeus","href":"/langchain/docs/integrations/toolkits/amadeus","docId":"integrations/toolkits/amadeus"},{"type":"link","label":"Azure Cognitive Services","href":"/langchain/docs/integrations/toolkits/azure_cognitive_services","docId":"integrations/toolkits/azure_cognitive_services"},{"type":"link","label":"CSV","href":"/langchain/docs/integrations/toolkits/csv","docId":"integrations/toolkits/csv"},{"type":"link","label":"Document Comparison","href":"/langchain/docs/integrations/toolkits/document_comparison_toolkit","docId":"integrations/toolkits/document_comparison_toolkit"},{"type":"link","label":"Github","href":"/langchain/docs/integrations/toolkits/github","docId":"integrations/toolkits/github"},{"type":"link","label":"Gmail","href":"/langchain/docs/integrations/toolkits/gmail","docId":"integrations/toolkits/gmail"},{"type":"link","label":"Google Drive tool","href":"/langchain/docs/integrations/toolkits/google_drive","docId":"integrations/toolkits/google_drive"},{"type":"link","label":"Jira","href":"/langchain/docs/integrations/toolkits/jira","docId":"integrations/toolkits/jira"},{"type":"link","label":"JSON","href":"/langchain/docs/integrations/toolkits/json","docId":"integrations/toolkits/json"},{"type":"link","label":"MultiOn","href":"/langchain/docs/integrations/toolkits/multion","docId":"integrations/toolkits/multion"},{"type":"link","label":"Office365","href":"/langchain/docs/integrations/toolkits/office365","docId":"integrations/toolkits/office365"},{"type":"link","label":"OpenAPI","href":"/langchain/docs/integrations/toolkits/openapi","docId":"integrations/toolkits/openapi"},{"type":"link","label":"Natural Language APIs","href":"/langchain/docs/integrations/toolkits/openapi_nla","docId":"integrations/toolkits/openapi_nla"},{"type":"link","label":"Pandas Dataframe","href":"/langchain/docs/integrations/toolkits/pandas","docId":"integrations/toolkits/pandas"},{"type":"link","label":"PlayWright Browser","href":"/langchain/docs/integrations/toolkits/playwright","docId":"integrations/toolkits/playwright"},{"type":"link","label":"PowerBI Dataset","href":"/langchain/docs/integrations/toolkits/powerbi","docId":"integrations/toolkits/powerbi"},{"type":"link","label":"Python","href":"/langchain/docs/integrations/toolkits/python","docId":"integrations/toolkits/python"},{"type":"link","label":"Spark Dataframe","href":"/langchain/docs/integrations/toolkits/spark","docId":"integrations/toolkits/spark"},{"type":"link","label":"Spark SQL","href":"/langchain/docs/integrations/toolkits/spark_sql","docId":"integrations/toolkits/spark_sql"},{"type":"link","label":"SQL Database","href":"/langchain/docs/integrations/toolkits/sql_database","docId":"integrations/toolkits/sql_database"},{"type":"link","label":"Vectorstore","href":"/langchain/docs/integrations/toolkits/vectorstore","docId":"integrations/toolkits/vectorstore"},{"type":"link","label":"Xorbits","href":"/langchain/docs/integrations/toolkits/xorbits","docId":"integrations/toolkits/xorbits"}],"href":"/langchain/docs/integrations/toolkits/"},{"type":"category","label":"Tools","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Alpha Vantage","href":"/langchain/docs/integrations/tools/alpha_vantage","docId":"integrations/tools/alpha_vantage"},{"type":"link","label":"Apify","href":"/langchain/docs/integrations/tools/apify","docId":"integrations/tools/apify"},{"type":"link","label":"ArXiv","href":"/langchain/docs/integrations/tools/arxiv","docId":"integrations/tools/arxiv"},{"type":"link","label":"AWS Lambda","href":"/langchain/docs/integrations/tools/awslambda","docId":"integrations/tools/awslambda"},{"type":"link","label":"Shell (bash)","href":"/langchain/docs/integrations/tools/bash","docId":"integrations/tools/bash"},{"type":"link","label":"Bing Search","href":"/langchain/docs/integrations/tools/bing_search","docId":"integrations/tools/bing_search"},{"type":"link","label":"Brave Search","href":"/langchain/docs/integrations/tools/brave_search","docId":"integrations/tools/brave_search"},{"type":"link","label":"ChatGPT Plugins","href":"/langchain/docs/integrations/tools/chatgpt_plugins","docId":"integrations/tools/chatgpt_plugins"},{"type":"link","label":"Dall-E Image Generator","href":"/langchain/docs/integrations/tools/dalle_image_generator","docId":"integrations/tools/dalle_image_generator"},{"type":"link","label":"DataForSeo","href":"/langchain/docs/integrations/tools/dataforseo","docId":"integrations/tools/dataforseo"},{"type":"link","label":"DuckDuckGo Search","href":"/langchain/docs/integrations/tools/ddg","docId":"integrations/tools/ddg"},{"type":"link","label":"Eden AI","href":"/langchain/docs/integrations/tools/edenai_tools","docId":"integrations/tools/edenai_tools"},{"type":"link","label":"File System","href":"/langchain/docs/integrations/tools/filesystem","docId":"integrations/tools/filesystem"},{"type":"link","label":"Golden Query","href":"/langchain/docs/integrations/tools/golden_query","docId":"integrations/tools/golden_query"},{"type":"link","label":"Google Drive","href":"/langchain/docs/integrations/tools/google_drive","docId":"integrations/tools/google_drive"},{"type":"link","label":"Google Places","href":"/langchain/docs/integrations/tools/google_places","docId":"integrations/tools/google_places"},{"type":"link","label":"Google Search","href":"/langchain/docs/integrations/tools/google_search","docId":"integrations/tools/google_search"},{"type":"link","label":"Google Serper","href":"/langchain/docs/integrations/tools/google_serper","docId":"integrations/tools/google_serper"},{"type":"link","label":"Gradio","href":"/langchain/docs/integrations/tools/gradio_tools","docId":"integrations/tools/gradio_tools"},{"type":"link","label":"GraphQL","href":"/langchain/docs/integrations/tools/graphql","docId":"integrations/tools/graphql"},{"type":"link","label":"HuggingFace Hub Tools","href":"/langchain/docs/integrations/tools/huggingface_tools","docId":"integrations/tools/huggingface_tools"},{"type":"link","label":"Human as a tool","href":"/langchain/docs/integrations/tools/human_tools","docId":"integrations/tools/human_tools"},{"type":"link","label":"IFTTT WebHooks","href":"/langchain/docs/integrations/tools/ifttt","docId":"integrations/tools/ifttt"},{"type":"link","label":"Lemon Agent","href":"/langchain/docs/integrations/tools/lemonai","docId":"integrations/tools/lemonai"},{"type":"link","label":"Metaphor Search","href":"/langchain/docs/integrations/tools/metaphor_search","docId":"integrations/tools/metaphor_search"},{"type":"link","label":"Nuclia Understanding","href":"/langchain/docs/integrations/tools/nuclia","docId":"integrations/tools/nuclia"},{"type":"link","label":"OpenWeatherMap","href":"/langchain/docs/integrations/tools/openweathermap","docId":"integrations/tools/openweathermap"},{"type":"link","label":"PubMed","href":"/langchain/docs/integrations/tools/pubmed","docId":"integrations/tools/pubmed"},{"type":"link","label":"Requests","href":"/langchain/docs/integrations/tools/requests","docId":"integrations/tools/requests"},{"type":"link","label":"SceneXplain","href":"/langchain/docs/integrations/tools/sceneXplain","docId":"integrations/tools/sceneXplain"},{"type":"link","label":"Search Tools","href":"/langchain/docs/integrations/tools/search_tools","docId":"integrations/tools/search_tools"},{"type":"link","label":"SearxNG Search","href":"/langchain/docs/integrations/tools/searx_search","docId":"integrations/tools/searx_search"},{"type":"link","label":"SerpAPI","href":"/langchain/docs/integrations/tools/serpapi","docId":"integrations/tools/serpapi"},{"type":"link","label":"SQL Database Chain","href":"/langchain/docs/integrations/tools/sqlite","docId":"integrations/tools/sqlite"},{"type":"link","label":"Twilio","href":"/langchain/docs/integrations/tools/twilio","docId":"integrations/tools/twilio"},{"type":"link","label":"Wikipedia","href":"/langchain/docs/integrations/tools/wikipedia","docId":"integrations/tools/wikipedia"},{"type":"link","label":"Wolfram Alpha","href":"/langchain/docs/integrations/tools/wolfram_alpha","docId":"integrations/tools/wolfram_alpha"},{"type":"link","label":"Yahoo Finance News","href":"/langchain/docs/integrations/tools/yahoo_finance_news","docId":"integrations/tools/yahoo_finance_news"},{"type":"link","label":"YouTube","href":"/langchain/docs/integrations/tools/youtube","docId":"integrations/tools/youtube"},{"type":"link","label":"Zapier Natural Language Actions","href":"/langchain/docs/integrations/tools/zapier","docId":"integrations/tools/zapier"}],"href":"/langchain/docs/integrations/tools/"},{"type":"category","label":"Vector stores","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Activeloop Deep Lake","href":"/langchain/docs/integrations/vectorstores/activeloop_deeplake","docId":"integrations/vectorstores/activeloop_deeplake"},{"type":"link","label":"Alibaba Cloud OpenSearch","href":"/langchain/docs/integrations/vectorstores/alibabacloud_opensearch","docId":"integrations/vectorstores/alibabacloud_opensearch"},{"type":"link","label":"AnalyticDB","href":"/langchain/docs/integrations/vectorstores/analyticdb","docId":"integrations/vectorstores/analyticdb"},{"type":"link","label":"Annoy","href":"/langchain/docs/integrations/vectorstores/annoy","docId":"integrations/vectorstores/annoy"},{"type":"link","label":"Atlas","href":"/langchain/docs/integrations/vectorstores/atlas","docId":"integrations/vectorstores/atlas"},{"type":"link","label":"AwaDB","href":"/langchain/docs/integrations/vectorstores/awadb","docId":"integrations/vectorstores/awadb"},{"type":"link","label":"Azure Cognitive Search","href":"/langchain/docs/integrations/vectorstores/azuresearch","docId":"integrations/vectorstores/azuresearch"},{"type":"link","label":"BagelDB","href":"/langchain/docs/integrations/vectorstores/bageldb","docId":"integrations/vectorstores/bageldb"},{"type":"link","label":"Cassandra","href":"/langchain/docs/integrations/vectorstores/cassandra","docId":"integrations/vectorstores/cassandra"},{"type":"link","label":"Chroma","href":"/langchain/docs/integrations/vectorstores/chroma","docId":"integrations/vectorstores/chroma"},{"type":"link","label":"ClickHouse","href":"/langchain/docs/integrations/vectorstores/clickhouse","docId":"integrations/vectorstores/clickhouse"},{"type":"link","label":"DashVector","href":"/langchain/docs/integrations/vectorstores/dashvector","docId":"integrations/vectorstores/dashvector"},{"type":"link","label":"Dingo","href":"/langchain/docs/integrations/vectorstores/dingo","docId":"integrations/vectorstores/dingo"},{"type":"link","label":"DocArray HnswSearch","href":"/langchain/docs/integrations/vectorstores/docarray_hnsw","docId":"integrations/vectorstores/docarray_hnsw"},{"type":"link","label":"DocArray InMemorySearch","href":"/langchain/docs/integrations/vectorstores/docarray_in_memory","docId":"integrations/vectorstores/docarray_in_memory"},{"type":"link","label":"Elasticsearch","href":"/langchain/docs/integrations/vectorstores/elasticsearch","docId":"integrations/vectorstores/elasticsearch"},{"type":"link","label":"Epsilla","href":"/langchain/docs/integrations/vectorstores/epsilla","docId":"integrations/vectorstores/epsilla"},{"type":"link","label":"Faiss","href":"/langchain/docs/integrations/vectorstores/faiss","docId":"integrations/vectorstores/faiss"},{"type":"link","label":"Hologres","href":"/langchain/docs/integrations/vectorstores/hologres","docId":"integrations/vectorstores/hologres"},{"type":"link","label":"LanceDB","href":"/langchain/docs/integrations/vectorstores/lancedb","docId":"integrations/vectorstores/lancedb"},{"type":"link","label":"Marqo","href":"/langchain/docs/integrations/vectorstores/marqo","docId":"integrations/vectorstores/marqo"},{"type":"link","label":"Google Vertex AI MatchingEngine","href":"/langchain/docs/integrations/vectorstores/matchingengine","docId":"integrations/vectorstores/matchingengine"},{"type":"link","label":"Meilisearch","href":"/langchain/docs/integrations/vectorstores/meilisearch","docId":"integrations/vectorstores/meilisearch"},{"type":"link","label":"Milvus","href":"/langchain/docs/integrations/vectorstores/milvus","docId":"integrations/vectorstores/milvus"},{"type":"link","label":"MongoDB Atlas","href":"/langchain/docs/integrations/vectorstores/mongodb_atlas","docId":"integrations/vectorstores/mongodb_atlas"},{"type":"link","label":"MyScale","href":"/langchain/docs/integrations/vectorstores/myscale","docId":"integrations/vectorstores/myscale"},{"type":"link","label":"Neo4j Vector Index","href":"/langchain/docs/integrations/vectorstores/neo4jvector","docId":"integrations/vectorstores/neo4jvector"},{"type":"link","label":"nucliadb_vectorstore","href":"/langchain/docs/integrations/vectorstores/nucliadb_vectorstore","docId":"integrations/vectorstores/nucliadb_vectorstore"},{"type":"link","label":"OpenSearch","href":"/langchain/docs/integrations/vectorstores/opensearch","docId":"integrations/vectorstores/opensearch"},{"type":"link","label":"Postgres Embedding","href":"/langchain/docs/integrations/vectorstores/pgembedding","docId":"integrations/vectorstores/pgembedding"},{"type":"link","label":"PGVector","href":"/langchain/docs/integrations/vectorstores/pgvector","docId":"integrations/vectorstores/pgvector"},{"type":"link","label":"Pinecone","href":"/langchain/docs/integrations/vectorstores/pinecone","docId":"integrations/vectorstores/pinecone"},{"type":"link","label":"Qdrant","href":"/langchain/docs/integrations/vectorstores/qdrant","docId":"integrations/vectorstores/qdrant"},{"type":"link","label":"Redis","href":"/langchain/docs/integrations/vectorstores/redis","docId":"integrations/vectorstores/redis"},{"type":"link","label":"Rockset","href":"/langchain/docs/integrations/vectorstores/rockset","docId":"integrations/vectorstores/rockset"},{"type":"link","label":"ScaNN","href":"/langchain/docs/integrations/vectorstores/scann","docId":"integrations/vectorstores/scann"},{"type":"link","label":"SingleStoreDB","href":"/langchain/docs/integrations/vectorstores/singlestoredb","docId":"integrations/vectorstores/singlestoredb"},{"type":"link","label":"scikit-learn","href":"/langchain/docs/integrations/vectorstores/sklearn","docId":"integrations/vectorstores/sklearn"},{"type":"link","label":"sqlite-vss","href":"/langchain/docs/integrations/vectorstores/sqlitevss","docId":"integrations/vectorstores/sqlitevss"},{"type":"link","label":"StarRocks","href":"/langchain/docs/integrations/vectorstores/starrocks","docId":"integrations/vectorstores/starrocks"},{"type":"link","label":"Supabase (Postgres)","href":"/langchain/docs/integrations/vectorstores/supabase","docId":"integrations/vectorstores/supabase"},{"type":"link","label":"Tair","href":"/langchain/docs/integrations/vectorstores/tair","docId":"integrations/vectorstores/tair"},{"type":"link","label":"Tencent Cloud VectorDB","href":"/langchain/docs/integrations/vectorstores/tencentvectordb","docId":"integrations/vectorstores/tencentvectordb"},{"type":"link","label":"Tigris","href":"/langchain/docs/integrations/vectorstores/tigris","docId":"integrations/vectorstores/tigris"},{"type":"link","label":"Typesense","href":"/langchain/docs/integrations/vectorstores/typesense","docId":"integrations/vectorstores/typesense"},{"type":"link","label":"USearch","href":"/langchain/docs/integrations/vectorstores/usearch","docId":"integrations/vectorstores/usearch"},{"type":"link","label":"Vectara","href":"/langchain/docs/integrations/vectorstores/vectara","docId":"integrations/vectorstores/vectara"},{"type":"link","label":"Weaviate","href":"/langchain/docs/integrations/vectorstores/weaviate","docId":"integrations/vectorstores/weaviate"},{"type":"link","label":"Xata","href":"/langchain/docs/integrations/vectorstores/xata","docId":"integrations/vectorstores/xata"},{"type":"link","label":"Zep","href":"/langchain/docs/integrations/vectorstores/zep","docId":"integrations/vectorstores/zep"},{"type":"link","label":"Zilliz","href":"/langchain/docs/integrations/vectorstores/zilliz","docId":"integrations/vectorstores/zilliz"}],"href":"/langchain/docs/integrations/vectorstores/"},{"type":"category","label":"Grouped by provider","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Activeloop Deep Lake","href":"/langchain/docs/integrations/providers/activeloop_deeplake","docId":"integrations/providers/activeloop_deeplake"},{"type":"link","label":"AI21 Labs","href":"/langchain/docs/integrations/providers/ai21","docId":"integrations/providers/ai21"},{"type":"link","label":"Aim","href":"/langchain/docs/integrations/providers/aim_tracking","docId":"integrations/providers/aim_tracking"},{"type":"link","label":"AINetwork","href":"/langchain/docs/integrations/providers/ainetwork","docId":"integrations/providers/ainetwork"},{"type":"link","label":"Airbyte","href":"/langchain/docs/integrations/providers/airbyte","docId":"integrations/providers/airbyte"},{"type":"link","label":"Airtable","href":"/langchain/docs/integrations/providers/airtable","docId":"integrations/providers/airtable"},{"type":"link","label":"Aleph Alpha","href":"/langchain/docs/integrations/providers/aleph_alpha","docId":"integrations/providers/aleph_alpha"},{"type":"link","label":"Alibaba Cloud Opensearch","href":"/langchain/docs/integrations/providers/alibabacloud_opensearch","docId":"integrations/providers/alibabacloud_opensearch"},{"type":"link","label":"Amazon API Gateway","href":"/langchain/docs/integrations/providers/amazon_api_gateway","docId":"integrations/providers/amazon_api_gateway"},{"type":"link","label":"AnalyticDB","href":"/langchain/docs/integrations/providers/analyticdb","docId":"integrations/providers/analyticdb"},{"type":"link","label":"Annoy","href":"/langchain/docs/integrations/providers/annoy","docId":"integrations/providers/annoy"},{"type":"link","label":"Anyscale","href":"/langchain/docs/integrations/providers/anyscale","docId":"integrations/providers/anyscale"},{"type":"link","label":"Apify","href":"/langchain/docs/integrations/providers/apify","docId":"integrations/providers/apify"},{"type":"link","label":"ArangoDB","href":"/langchain/docs/integrations/providers/arangodb","docId":"integrations/providers/arangodb"},{"type":"link","label":"Argilla","href":"/langchain/docs/integrations/providers/argilla","docId":"integrations/providers/argilla"},{"type":"link","label":"Arthur","href":"/langchain/docs/integrations/providers/arthur_tracking","docId":"integrations/providers/arthur_tracking"},{"type":"link","label":"Arxiv","href":"/langchain/docs/integrations/providers/arxiv","docId":"integrations/providers/arxiv"},{"type":"link","label":"Atlas","href":"/langchain/docs/integrations/providers/atlas","docId":"integrations/providers/atlas"},{"type":"link","label":"AwaDB","href":"/langchain/docs/integrations/providers/awadb","docId":"integrations/providers/awadb"},{"type":"link","label":"AWS S3 Directory","href":"/langchain/docs/integrations/providers/aws_s3","docId":"integrations/providers/aws_s3"},{"type":"link","label":"AZLyrics","href":"/langchain/docs/integrations/providers/azlyrics","docId":"integrations/providers/azlyrics"},{"type":"link","label":"Azure Blob Storage","href":"/langchain/docs/integrations/providers/azure_blob_storage","docId":"integrations/providers/azure_blob_storage"},{"type":"link","label":"Azure Cognitive Search","href":"/langchain/docs/integrations/providers/azure_cognitive_search_","docId":"integrations/providers/azure_cognitive_search_"},{"type":"link","label":"Azure OpenAI","href":"/langchain/docs/integrations/providers/azure_openai","docId":"integrations/providers/azure_openai"},{"type":"link","label":"BagelDB","href":"/langchain/docs/integrations/providers/bageldb","docId":"integrations/providers/bageldb"},{"type":"link","label":"Banana","href":"/langchain/docs/integrations/providers/bananadev","docId":"integrations/providers/bananadev"},{"type":"link","label":"Baseten","href":"/langchain/docs/integrations/providers/baseten","docId":"integrations/providers/baseten"},{"type":"link","label":"Beam","href":"/langchain/docs/integrations/providers/beam","docId":"integrations/providers/beam"},{"type":"link","label":"Bedrock","href":"/langchain/docs/integrations/providers/bedrock","docId":"integrations/providers/bedrock"},{"type":"link","label":"BiliBili","href":"/langchain/docs/integrations/providers/bilibili","docId":"integrations/providers/bilibili"},{"type":"link","label":"NIBittensor","href":"/langchain/docs/integrations/providers/bittensor","docId":"integrations/providers/bittensor"},{"type":"link","label":"Blackboard","href":"/langchain/docs/integrations/providers/blackboard","docId":"integrations/providers/blackboard"},{"type":"link","label":"Brave Search","href":"/langchain/docs/integrations/providers/brave_search","docId":"integrations/providers/brave_search"},{"type":"link","label":"Cassandra","href":"/langchain/docs/integrations/providers/cassandra","docId":"integrations/providers/cassandra"},{"type":"link","label":"CerebriumAI","href":"/langchain/docs/integrations/providers/cerebriumai","docId":"integrations/providers/cerebriumai"},{"type":"link","label":"Chaindesk","href":"/langchain/docs/integrations/providers/chaindesk","docId":"integrations/providers/chaindesk"},{"type":"link","label":"Chroma","href":"/langchain/docs/integrations/providers/chroma","docId":"integrations/providers/chroma"},{"type":"link","label":"Clarifai","href":"/langchain/docs/integrations/providers/clarifai","docId":"integrations/providers/clarifai"},{"type":"link","label":"ClearML","href":"/langchain/docs/integrations/providers/clearml_tracking","docId":"integrations/providers/clearml_tracking"},{"type":"link","label":"ClickHouse","href":"/langchain/docs/integrations/providers/clickhouse","docId":"integrations/providers/clickhouse"},{"type":"link","label":"CnosDB","href":"/langchain/docs/integrations/providers/cnosdb","docId":"integrations/providers/cnosdb"},{"type":"link","label":"Cohere","href":"/langchain/docs/integrations/providers/cohere","docId":"integrations/providers/cohere"},{"type":"link","label":"College Confidential","href":"/langchain/docs/integrations/providers/college_confidential","docId":"integrations/providers/college_confidential"},{"type":"link","label":"Comet","href":"/langchain/docs/integrations/providers/comet_tracking","docId":"integrations/providers/comet_tracking"},{"type":"link","label":"Confluence","href":"/langchain/docs/integrations/providers/confluence","docId":"integrations/providers/confluence"},{"type":"link","label":"C Transformers","href":"/langchain/docs/integrations/providers/ctransformers","docId":"integrations/providers/ctransformers"},{"type":"link","label":"DashVector","href":"/langchain/docs/integrations/providers/dashvector","docId":"integrations/providers/dashvector"},{"type":"link","label":"Databricks","href":"/langchain/docs/integrations/providers/databricks","docId":"integrations/providers/databricks"},{"type":"link","label":"Datadog Tracing","href":"/langchain/docs/integrations/providers/datadog","docId":"integrations/providers/datadog"},{"type":"link","label":"Datadog Logs","href":"/langchain/docs/integrations/providers/datadog_logs","docId":"integrations/providers/datadog_logs"},{"type":"link","label":"DataForSEO","href":"/langchain/docs/integrations/providers/dataforseo","docId":"integrations/providers/dataforseo"},{"type":"link","label":"DeepInfra","href":"/langchain/docs/integrations/providers/deepinfra","docId":"integrations/providers/deepinfra"},{"type":"link","label":"DeepSparse","href":"/langchain/docs/integrations/providers/deepsparse","docId":"integrations/providers/deepsparse"},{"type":"link","label":"Diffbot","href":"/langchain/docs/integrations/providers/diffbot","docId":"integrations/providers/diffbot"},{"type":"link","label":"Dingo","href":"/langchain/docs/integrations/providers/dingo","docId":"integrations/providers/dingo"},{"type":"link","label":"Discord","href":"/langchain/docs/integrations/providers/discord","docId":"integrations/providers/discord"},{"type":"link","label":"DocArray","href":"/langchain/docs/integrations/providers/docarray","docId":"integrations/providers/docarray"},{"type":"link","label":"Docugami","href":"/langchain/docs/integrations/providers/docugami","docId":"integrations/providers/docugami"},{"type":"link","label":"DuckDB","href":"/langchain/docs/integrations/providers/duckdb","docId":"integrations/providers/duckdb"},{"type":"link","label":"Elasticsearch","href":"/langchain/docs/integrations/providers/elasticsearch","docId":"integrations/providers/elasticsearch"},{"type":"link","label":"Epsilla","href":"/langchain/docs/integrations/providers/epsilla","docId":"integrations/providers/epsilla"},{"type":"link","label":"EverNote","href":"/langchain/docs/integrations/providers/evernote","docId":"integrations/providers/evernote"},{"type":"link","label":"Facebook Chat","href":"/langchain/docs/integrations/providers/facebook_chat","docId":"integrations/providers/facebook_chat"},{"type":"link","label":"Facebook Faiss","href":"/langchain/docs/integrations/providers/facebook_faiss","docId":"integrations/providers/facebook_faiss"},{"type":"link","label":"Figma","href":"/langchain/docs/integrations/providers/figma","docId":"integrations/providers/figma"},{"type":"link","label":"Fireworks","href":"/langchain/docs/integrations/providers/fireworks","docId":"integrations/providers/fireworks"},{"type":"link","label":"Flyte","href":"/langchain/docs/integrations/providers/flyte","docId":"integrations/providers/flyte"},{"type":"link","label":"ForefrontAI","href":"/langchain/docs/integrations/providers/forefrontai","docId":"integrations/providers/forefrontai"},{"type":"link","label":"Git","href":"/langchain/docs/integrations/providers/git","docId":"integrations/providers/git"},{"type":"link","label":"GitBook","href":"/langchain/docs/integrations/providers/gitbook","docId":"integrations/providers/gitbook"},{"type":"link","label":"Golden","href":"/langchain/docs/integrations/providers/golden","docId":"integrations/providers/golden"},{"type":"link","label":"Google BigQuery","href":"/langchain/docs/integrations/providers/google_bigquery","docId":"integrations/providers/google_bigquery"},{"type":"link","label":"Google Cloud Storage","href":"/langchain/docs/integrations/providers/google_cloud_storage","docId":"integrations/providers/google_cloud_storage"},{"type":"link","label":"Google Drive","href":"/langchain/docs/integrations/providers/google_drive","docId":"integrations/providers/google_drive"},{"type":"link","label":"Google Search","href":"/langchain/docs/integrations/providers/google_search","docId":"integrations/providers/google_search"},{"type":"link","label":"Google Serper","href":"/langchain/docs/integrations/providers/google_serper","docId":"integrations/providers/google_serper"},{"type":"link","label":"Google Vertex AI MatchingEngine","href":"/langchain/docs/integrations/providers/google_vertex_ai_matchingengine","docId":"integrations/providers/google_vertex_ai_matchingengine"},{"type":"link","label":"GooseAI","href":"/langchain/docs/integrations/providers/gooseai","docId":"integrations/providers/gooseai"},{"type":"link","label":"GPT4All","href":"/langchain/docs/integrations/providers/gpt4all","docId":"integrations/providers/gpt4all"},{"type":"link","label":"Graphsignal","href":"/langchain/docs/integrations/providers/graphsignal","docId":"integrations/providers/graphsignal"},{"type":"link","label":"Grobid","href":"/langchain/docs/integrations/providers/grobid","docId":"integrations/providers/grobid"},{"type":"link","label":"Gutenberg","href":"/langchain/docs/integrations/providers/gutenberg","docId":"integrations/providers/gutenberg"},{"type":"link","label":"Hacker News","href":"/langchain/docs/integrations/providers/hacker_news","docId":"integrations/providers/hacker_news"},{"type":"link","label":"Hazy Research","href":"/langchain/docs/integrations/providers/hazy_research","docId":"integrations/providers/hazy_research"},{"type":"link","label":"Helicone","href":"/langchain/docs/integrations/providers/helicone","docId":"integrations/providers/helicone"},{"type":"link","label":"Hologres","href":"/langchain/docs/integrations/providers/hologres","docId":"integrations/providers/hologres"},{"type":"link","label":"Hugging Face","href":"/langchain/docs/integrations/providers/huggingface","docId":"integrations/providers/huggingface"},{"type":"link","label":"iFixit","href":"/langchain/docs/integrations/providers/ifixit","docId":"integrations/providers/ifixit"},{"type":"link","label":"IMSDb","href":"/langchain/docs/integrations/providers/imsdb","docId":"integrations/providers/imsdb"},{"type":"link","label":"Infino","href":"/langchain/docs/integrations/providers/infino","docId":"integrations/providers/infino"},{"type":"link","label":"Jina","href":"/langchain/docs/integrations/providers/jina","docId":"integrations/providers/jina"},{"type":"link","label":"LanceDB","href":"/langchain/docs/integrations/providers/lancedb","docId":"integrations/providers/lancedb"},{"type":"link","label":"LangChain Decorators \u2728","href":"/langchain/docs/integrations/providers/langchain_decorators","docId":"integrations/providers/langchain_decorators"},{"type":"link","label":"Llama.cpp","href":"/langchain/docs/integrations/providers/llamacpp","docId":"integrations/providers/llamacpp"},{"type":"link","label":"Log10","href":"/langchain/docs/integrations/providers/log10","docId":"integrations/providers/log10"},{"type":"link","label":"Marqo","href":"/langchain/docs/integrations/providers/marqo","docId":"integrations/providers/marqo"},{"type":"link","label":"MediaWikiDump","href":"/langchain/docs/integrations/providers/mediawikidump","docId":"integrations/providers/mediawikidump"},{"type":"link","label":"Meilisearch","href":"/langchain/docs/integrations/providers/meilisearch","docId":"integrations/providers/meilisearch"},{"type":"link","label":"Metal","href":"/langchain/docs/integrations/providers/metal","docId":"integrations/providers/metal"},{"type":"link","label":"Microsoft OneDrive","href":"/langchain/docs/integrations/providers/microsoft_onedrive","docId":"integrations/providers/microsoft_onedrive"},{"type":"link","label":"Microsoft PowerPoint","href":"/langchain/docs/integrations/providers/microsoft_powerpoint","docId":"integrations/providers/microsoft_powerpoint"},{"type":"link","label":"Microsoft Word","href":"/langchain/docs/integrations/providers/microsoft_word","docId":"integrations/providers/microsoft_word"},{"type":"link","label":"Milvus","href":"/langchain/docs/integrations/providers/milvus","docId":"integrations/providers/milvus"},{"type":"link","label":"Minimax","href":"/langchain/docs/integrations/providers/minimax","docId":"integrations/providers/minimax"},{"type":"link","label":"MLflow AI Gateway","href":"/langchain/docs/integrations/providers/mlflow_ai_gateway","docId":"integrations/providers/mlflow_ai_gateway"},{"type":"link","label":"MLflow","href":"/langchain/docs/integrations/providers/mlflow_tracking","docId":"integrations/providers/mlflow_tracking"},{"type":"link","label":"Modal","href":"/langchain/docs/integrations/providers/modal","docId":"integrations/providers/modal"},{"type":"link","label":"ModelScope","href":"/langchain/docs/integrations/providers/modelscope","docId":"integrations/providers/modelscope"},{"type":"link","label":"Modern Treasury","href":"/langchain/docs/integrations/providers/modern_treasury","docId":"integrations/providers/modern_treasury"},{"type":"link","label":"Momento","href":"/langchain/docs/integrations/providers/momento","docId":"integrations/providers/momento"},{"type":"link","label":"MongoDB Atlas","href":"/langchain/docs/integrations/providers/mongodb_atlas","docId":"integrations/providers/mongodb_atlas"},{"type":"link","label":"Motherduck","href":"/langchain/docs/integrations/providers/motherduck","docId":"integrations/providers/motherduck"},{"type":"link","label":"MyScale","href":"/langchain/docs/integrations/providers/myscale","docId":"integrations/providers/myscale"},{"type":"link","label":"Neo4j","href":"/langchain/docs/integrations/providers/neo4j","docId":"integrations/providers/neo4j"},{"type":"link","label":"NLPCloud","href":"/langchain/docs/integrations/providers/nlpcloud","docId":"integrations/providers/nlpcloud"},{"type":"link","label":"Notion DB","href":"/langchain/docs/integrations/providers/notion","docId":"integrations/providers/notion"},{"type":"link","label":"Obsidian","href":"/langchain/docs/integrations/providers/obsidian","docId":"integrations/providers/obsidian"},{"type":"link","label":"OpenAI","href":"/langchain/docs/integrations/providers/openai","docId":"integrations/providers/openai"},{"type":"link","label":"OpenLLM","href":"/langchain/docs/integrations/providers/openllm","docId":"integrations/providers/openllm"},{"type":"link","label":"OpenSearch","href":"/langchain/docs/integrations/providers/opensearch","docId":"integrations/providers/opensearch"},{"type":"link","label":"OpenWeatherMap","href":"/langchain/docs/integrations/providers/openweathermap","docId":"integrations/providers/openweathermap"},{"type":"link","label":"Petals","href":"/langchain/docs/integrations/providers/petals","docId":"integrations/providers/petals"},{"type":"link","label":"Postgres Embedding","href":"/langchain/docs/integrations/providers/pg_embedding","docId":"integrations/providers/pg_embedding"},{"type":"link","label":"PGVector","href":"/langchain/docs/integrations/providers/pgvector","docId":"integrations/providers/pgvector"},{"type":"link","label":"Pinecone","href":"/langchain/docs/integrations/providers/pinecone","docId":"integrations/providers/pinecone"},{"type":"link","label":"PipelineAI","href":"/langchain/docs/integrations/providers/pipelineai","docId":"integrations/providers/pipelineai"},{"type":"category","label":"Portkey","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"logging_tracing_portkey","href":"/langchain/docs/integrations/providers/portkey/logging_tracing_portkey","docId":"integrations/providers/portkey/logging_tracing_portkey"}],"href":"/langchain/docs/integrations/providers/portkey/"},{"type":"link","label":"Predibase","href":"/langchain/docs/integrations/providers/predibase","docId":"integrations/providers/predibase"},{"type":"link","label":"Prediction Guard","href":"/langchain/docs/integrations/providers/predictionguard","docId":"integrations/providers/predictionguard"},{"type":"link","label":"PromptLayer","href":"/langchain/docs/integrations/providers/promptlayer","docId":"integrations/providers/promptlayer"},{"type":"link","label":"Psychic","href":"/langchain/docs/integrations/providers/psychic","docId":"integrations/providers/psychic"},{"type":"link","label":"PubMed","href":"/langchain/docs/integrations/providers/pubmed","docId":"integrations/providers/pubmed"},{"type":"link","label":"Qdrant","href":"/langchain/docs/integrations/providers/qdrant","docId":"integrations/providers/qdrant"},{"type":"link","label":"Ray Serve","href":"/langchain/docs/integrations/providers/ray_serve","docId":"integrations/providers/ray_serve"},{"type":"link","label":"Rebuff","href":"/langchain/docs/integrations/providers/rebuff","docId":"integrations/providers/rebuff"},{"type":"link","label":"Reddit","href":"/langchain/docs/integrations/providers/reddit","docId":"integrations/providers/reddit"},{"type":"link","label":"Redis","href":"/langchain/docs/integrations/providers/redis","docId":"integrations/providers/redis"},{"type":"link","label":"Replicate","href":"/langchain/docs/integrations/providers/replicate","docId":"integrations/providers/replicate"},{"type":"link","label":"Roam","href":"/langchain/docs/integrations/providers/roam","docId":"integrations/providers/roam"},{"type":"link","label":"Rockset","href":"/langchain/docs/integrations/providers/rockset","docId":"integrations/providers/rockset"},{"type":"link","label":"Runhouse","href":"/langchain/docs/integrations/providers/runhouse","docId":"integrations/providers/runhouse"},{"type":"link","label":"RWKV-4","href":"/langchain/docs/integrations/providers/rwkv","docId":"integrations/providers/rwkv"},{"type":"link","label":"SageMaker Endpoint","href":"/langchain/docs/integrations/providers/sagemaker_endpoint","docId":"integrations/providers/sagemaker_endpoint"},{"type":"link","label":"SageMaker Tracking","href":"/langchain/docs/integrations/providers/sagemaker_tracking","docId":"integrations/providers/sagemaker_tracking"},{"type":"link","label":"ScaNN","href":"/langchain/docs/integrations/providers/scann","docId":"integrations/providers/scann"},{"type":"link","label":"SearxNG Search API","href":"/langchain/docs/integrations/providers/searx","docId":"integrations/providers/searx"},{"type":"link","label":"SerpAPI","href":"/langchain/docs/integrations/providers/serpapi","docId":"integrations/providers/serpapi"},{"type":"link","label":"Shale Protocol","href":"/langchain/docs/integrations/providers/shaleprotocol","docId":"integrations/providers/shaleprotocol"},{"type":"link","label":"SingleStoreDB","href":"/langchain/docs/integrations/providers/singlestoredb","docId":"integrations/providers/singlestoredb"},{"type":"link","label":"scikit-learn","href":"/langchain/docs/integrations/providers/sklearn","docId":"integrations/providers/sklearn"},{"type":"link","label":"Slack","href":"/langchain/docs/integrations/providers/slack","docId":"integrations/providers/slack"},{"type":"link","label":"spaCy","href":"/langchain/docs/integrations/providers/spacy","docId":"integrations/providers/spacy"},{"type":"link","label":"Spreedly","href":"/langchain/docs/integrations/providers/spreedly","docId":"integrations/providers/spreedly"},{"type":"link","label":"StarRocks","href":"/langchain/docs/integrations/providers/starrocks","docId":"integrations/providers/starrocks"},{"type":"link","label":"StochasticAI","href":"/langchain/docs/integrations/providers/stochasticai","docId":"integrations/providers/stochasticai"},{"type":"link","label":"Stripe","href":"/langchain/docs/integrations/providers/stripe","docId":"integrations/providers/stripe"},{"type":"link","label":"Supabase (Postgres)","href":"/langchain/docs/integrations/providers/supabase","docId":"integrations/providers/supabase"},{"type":"link","label":"Nebula","href":"/langchain/docs/integrations/providers/symblai_nebula","docId":"integrations/providers/symblai_nebula"},{"type":"link","label":"Tair","href":"/langchain/docs/integrations/providers/tair","docId":"integrations/providers/tair"},{"type":"link","label":"Telegram","href":"/langchain/docs/integrations/providers/telegram","docId":"integrations/providers/telegram"},{"type":"link","label":"TencentVectorDB","href":"/langchain/docs/integrations/providers/tencentvectordb","docId":"integrations/providers/tencentvectordb"},{"type":"link","label":"TensorFlow Datasets","href":"/langchain/docs/integrations/providers/tensorflow_datasets","docId":"integrations/providers/tensorflow_datasets"},{"type":"link","label":"Tigris","href":"/langchain/docs/integrations/providers/tigris","docId":"integrations/providers/tigris"},{"type":"link","label":"2Markdown","href":"/langchain/docs/integrations/providers/tomarkdown","docId":"integrations/providers/tomarkdown"},{"type":"link","label":"Trello","href":"/langchain/docs/integrations/providers/trello","docId":"integrations/providers/trello"},{"type":"link","label":"TruLens","href":"/langchain/docs/integrations/providers/trulens","docId":"integrations/providers/trulens"},{"type":"link","label":"Twitter","href":"/langchain/docs/integrations/providers/twitter","docId":"integrations/providers/twitter"},{"type":"link","label":"Typesense","href":"/langchain/docs/integrations/providers/typesense","docId":"integrations/providers/typesense"},{"type":"link","label":"Unstructured","href":"/langchain/docs/integrations/providers/unstructured","docId":"integrations/providers/unstructured"},{"type":"link","label":"USearch","href":"/langchain/docs/integrations/providers/usearch","docId":"integrations/providers/usearch"},{"type":"category","label":"Vectara","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Chat Over Documents with Vectara","href":"/langchain/docs/integrations/providers/vectara/vectara_chat","docId":"integrations/providers/vectara/vectara_chat"},{"type":"link","label":"Vectara Text Generation","href":"/langchain/docs/integrations/providers/vectara/vectara_text_generation","docId":"integrations/providers/vectara/vectara_text_generation"}],"href":"/langchain/docs/integrations/providers/vectara/"},{"type":"link","label":"Vespa","href":"/langchain/docs/integrations/providers/vespa","docId":"integrations/providers/vespa"},{"type":"link","label":"WandB Tracing","href":"/langchain/docs/integrations/providers/wandb_tracing","docId":"integrations/providers/wandb_tracing"},{"type":"link","label":"Weights & Biases","href":"/langchain/docs/integrations/providers/wandb_tracking","docId":"integrations/providers/wandb_tracking"},{"type":"link","label":"Weather","href":"/langchain/docs/integrations/providers/weather","docId":"integrations/providers/weather"},{"type":"link","label":"Weaviate","href":"/langchain/docs/integrations/providers/weaviate","docId":"integrations/providers/weaviate"},{"type":"link","label":"WhatsApp","href":"/langchain/docs/integrations/providers/whatsapp","docId":"integrations/providers/whatsapp"},{"type":"link","label":"WhyLabs","href":"/langchain/docs/integrations/providers/whylabs_profiling","docId":"integrations/providers/whylabs_profiling"},{"type":"link","label":"Wikipedia","href":"/langchain/docs/integrations/providers/wikipedia","docId":"integrations/providers/wikipedia"},{"type":"link","label":"Wolfram Alpha","href":"/langchain/docs/integrations/providers/wolfram_alpha","docId":"integrations/providers/wolfram_alpha"},{"type":"link","label":"Writer","href":"/langchain/docs/integrations/providers/writer","docId":"integrations/providers/writer"},{"type":"link","label":"Xata","href":"/langchain/docs/integrations/providers/xata","docId":"integrations/providers/xata"},{"type":"link","label":"Xorbits Inference (Xinference)","href":"/langchain/docs/integrations/providers/xinference","docId":"integrations/providers/xinference"},{"type":"link","label":"Yeager.ai","href":"/langchain/docs/integrations/providers/yeagerai","docId":"integrations/providers/yeagerai"},{"type":"link","label":"YouTube","href":"/langchain/docs/integrations/providers/youtube","docId":"integrations/providers/youtube"},{"type":"link","label":"Zep","href":"/langchain/docs/integrations/providers/zep","docId":"integrations/providers/zep"},{"type":"link","label":"Zilliz","href":"/langchain/docs/integrations/providers/zilliz","docId":"integrations/providers/zilliz"}],"href":"/langchain/docs/integrations/providers/"}],"collapsed":false,"href":"/langchain/docs/integrations"}],"use_cases":[{"type":"category","label":"Use cases","collapsible":false,"items":[{"type":"category","label":"Question Answering","collapsible":true,"collapsed":false,"items":[{"type":"category","label":"How to","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"QA using a Retriever","href":"/langchain/docs/use_cases/question_answering/how_to/vector_db_qa","docId":"use_cases/question_answering/how_to/vector_db_qa"},{"type":"link","label":"Store and reference chat history","href":"/langchain/docs/use_cases/question_answering/how_to/chat_vector_db","docId":"use_cases/question_answering/how_to/chat_vector_db"},{"type":"category","label":"Code understanding","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Use LangChain, GPT and Activeloop\'s Deep Lake to work with code base","href":"/langchain/docs/use_cases/question_answering/how_to/code/code-analysis-deeplake","docId":"use_cases/question_answering/how_to/code/code-analysis-deeplake"},{"type":"link","label":"Analysis of Twitter the-algorithm source code with LangChain, GPT4 and Activeloop\'s Deep Lake","href":"/langchain/docs/use_cases/question_answering/how_to/code/twitter-the-algorithm-analysis-deeplake","docId":"use_cases/question_answering/how_to/code/twitter-the-algorithm-analysis-deeplake"}],"href":"/langchain/docs/use_cases/question_answering/how_to/code/"},{"type":"link","label":"Analyze Document","href":"/langchain/docs/use_cases/question_answering/how_to/analyze_document","docId":"use_cases/question_answering/how_to/analyze_document"},{"type":"link","label":"Conversational Retrieval Agent","href":"/langchain/docs/use_cases/question_answering/how_to/conversational_retrieval_agents","docId":"use_cases/question_answering/how_to/conversational_retrieval_agents"},{"type":"link","label":"Perform context-aware text splitting","href":"/langchain/docs/use_cases/question_answering/how_to/document-context-aware-QA","docId":"use_cases/question_answering/how_to/document-context-aware-QA"},{"type":"link","label":"Retrieve as you generate with FLARE","href":"/langchain/docs/use_cases/question_answering/how_to/flare","docId":"use_cases/question_answering/how_to/flare"},{"type":"link","label":"Improve document indexing with HyDE","href":"/langchain/docs/use_cases/question_answering/how_to/hyde","docId":"use_cases/question_answering/how_to/hyde"},{"type":"link","label":"Use local LLMs","href":"/langchain/docs/use_cases/question_answering/how_to/local_retrieval_qa","docId":"use_cases/question_answering/how_to/local_retrieval_qa"},{"type":"link","label":"Dynamically select from multiple retrievers","href":"/langchain/docs/use_cases/question_answering/how_to/multi_retrieval_qa_router","docId":"use_cases/question_answering/how_to/multi_retrieval_qa_router"},{"type":"link","label":"Multiple Retrieval Sources","href":"/langchain/docs/use_cases/question_answering/how_to/multiple_retrieval","docId":"use_cases/question_answering/how_to/multiple_retrieval"},{"type":"link","label":"Cite sources","href":"/langchain/docs/use_cases/question_answering/how_to/qa_citations","docId":"use_cases/question_answering/how_to/qa_citations"},{"type":"link","label":"QA over in-memory documents","href":"/langchain/docs/use_cases/question_answering/how_to/question_answering","docId":"use_cases/question_answering/how_to/question_answering"},{"type":"link","label":"Retrieve from vector stores directly","href":"/langchain/docs/use_cases/question_answering/how_to/vector_db_text_generation","docId":"use_cases/question_answering/how_to/vector_db_text_generation"}]},{"type":"category","label":"Integration-specific","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Structure answers with OpenAI functions","href":"/langchain/docs/use_cases/question_answering/integrations/openai_functions_retrieval_qa","docId":"use_cases/question_answering/integrations/openai_functions_retrieval_qa"},{"type":"link","label":"QA using Activeloop\'s DeepLake","href":"/langchain/docs/use_cases/question_answering/integrations/semantic-search-over-chat","docId":"use_cases/question_answering/integrations/semantic-search-over-chat"}]}],"href":"/langchain/docs/use_cases/question_answering/"},{"type":"category","label":"QA over structured data","collapsible":true,"collapsed":false,"items":[{"type":"link","label":"SQL","href":"/langchain/docs/use_cases/qa_structured/sql","docId":"use_cases/qa_structured/sql"},{"type":"category","label":"Integration-specific","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Elasticsearch","href":"/langchain/docs/use_cases/qa_structured/integrations/elasticsearch","docId":"use_cases/qa_structured/integrations/elasticsearch"},{"type":"link","label":"Vector SQL Retriever with MyScale","href":"/langchain/docs/use_cases/qa_structured/integrations/myscale_vector_sql","docId":"use_cases/qa_structured/integrations/myscale_vector_sql"}]}]},{"type":"link","label":"Interacting with APIs","href":"/langchain/docs/use_cases/apis","docId":"use_cases/apis"},{"type":"link","label":"Chatbots","href":"/langchain/docs/use_cases/chatbots","docId":"use_cases/chatbots"},{"type":"link","label":"Code understanding","href":"/langchain/docs/use_cases/code_understanding","docId":"use_cases/code_understanding"},{"type":"link","label":"Extraction","href":"/langchain/docs/use_cases/extraction","docId":"use_cases/extraction"},{"type":"link","label":"Summarization","href":"/langchain/docs/use_cases/summarization","docId":"use_cases/summarization"},{"type":"link","label":"Tagging","href":"/langchain/docs/use_cases/tagging","docId":"use_cases/tagging"},{"type":"link","label":"Web scraping","href":"/langchain/docs/use_cases/web_scraping","docId":"use_cases/web_scraping"},{"type":"category","label":"More","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Agents","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Agent simulations","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"CAMEL Role-Playing Autonomous Cooperative Agents","href":"/langchain/docs/use_cases/more/agents/agent_simulations/camel_role_playing","docId":"use_cases/more/agents/agent_simulations/camel_role_playing"},{"type":"link","label":"Generative Agents in LangChain","href":"/langchain/docs/use_cases/more/agents/agent_simulations/characters","docId":"use_cases/more/agents/agent_simulations/characters"},{"type":"link","label":"Simulated Environment: Gymnasium","href":"/langchain/docs/use_cases/more/agents/agent_simulations/gymnasium","docId":"use_cases/more/agents/agent_simulations/gymnasium"},{"type":"link","label":"Multi-Player Dungeons & Dragons","href":"/langchain/docs/use_cases/more/agents/agent_simulations/multi_player_dnd","docId":"use_cases/more/agents/agent_simulations/multi_player_dnd"},{"type":"link","label":"Multi-agent authoritarian speaker selection","href":"/langchain/docs/use_cases/more/agents/agent_simulations/multiagent_authoritarian","docId":"use_cases/more/agents/agent_simulations/multiagent_authoritarian"},{"type":"link","label":"Multi-agent decentralized speaker selection","href":"/langchain/docs/use_cases/more/agents/agent_simulations/multiagent_bidding","docId":"use_cases/more/agents/agent_simulations/multiagent_bidding"},{"type":"link","label":"Multi-Agent Simulated Environment: Petting Zoo","href":"/langchain/docs/use_cases/more/agents/agent_simulations/petting_zoo","docId":"use_cases/more/agents/agent_simulations/petting_zoo"},{"type":"link","label":"Agent Debates with Tools","href":"/langchain/docs/use_cases/more/agents/agent_simulations/two_agent_debate_tools","docId":"use_cases/more/agents/agent_simulations/two_agent_debate_tools"},{"type":"link","label":"Two-Player Dungeons & Dragons","href":"/langchain/docs/use_cases/more/agents/agent_simulations/two_player_dnd","docId":"use_cases/more/agents/agent_simulations/two_player_dnd"}],"href":"/langchain/docs/use_cases/more/agents/agent_simulations/"},{"type":"category","label":"Agents","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"CAMEL Role-Playing Autonomous Cooperative Agents","href":"/langchain/docs/use_cases/more/agents/agents/camel_role_playing","docId":"use_cases/more/agents/agents/camel_role_playing"},{"type":"link","label":"Custom Agent with PlugIn Retrieval","href":"/langchain/docs/use_cases/more/agents/agents/custom_agent_with_plugin_retrieval","docId":"use_cases/more/agents/agents/custom_agent_with_plugin_retrieval"},{"type":"link","label":"Plug-and-Plai","href":"/langchain/docs/use_cases/more/agents/agents/custom_agent_with_plugin_retrieval_using_plugnplai","docId":"use_cases/more/agents/agents/custom_agent_with_plugin_retrieval_using_plugnplai"},{"type":"link","label":"SalesGPT - Your Context-Aware AI Sales Assistant With Knowledge Base","href":"/langchain/docs/use_cases/more/agents/agents/sales_agent_with_context","docId":"use_cases/more/agents/agents/sales_agent_with_context"},{"type":"link","label":"Wikibase Agent","href":"/langchain/docs/use_cases/more/agents/agents/wikibase_agent","docId":"use_cases/more/agents/agents/wikibase_agent"}],"href":"/langchain/docs/use_cases/more/agents/agents/"},{"type":"category","label":"Autonomous (long-running) agents","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"AutoGPT","href":"/langchain/docs/use_cases/more/agents/autonomous_agents/autogpt","docId":"use_cases/more/agents/autonomous_agents/autogpt"},{"type":"link","label":"BabyAGI User Guide","href":"/langchain/docs/use_cases/more/agents/autonomous_agents/baby_agi","docId":"use_cases/more/agents/autonomous_agents/baby_agi"},{"type":"link","label":"BabyAGI with Tools","href":"/langchain/docs/use_cases/more/agents/autonomous_agents/baby_agi_with_agent","docId":"use_cases/more/agents/autonomous_agents/baby_agi_with_agent"},{"type":"link","label":"HuggingGPT","href":"/langchain/docs/use_cases/more/agents/autonomous_agents/hugginggpt","docId":"use_cases/more/agents/autonomous_agents/hugginggpt"},{"type":"link","label":"marathon_times","href":"/langchain/docs/use_cases/more/agents/autonomous_agents/marathon_times","docId":"use_cases/more/agents/autonomous_agents/marathon_times"},{"type":"link","label":"Meta-Prompt","href":"/langchain/docs/use_cases/more/agents/autonomous_agents/meta_prompt","docId":"use_cases/more/agents/autonomous_agents/meta_prompt"}],"href":"/langchain/docs/use_cases/more/agents/autonomous_agents/"},{"type":"category","label":"Multi-modal","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Multi-modal outputs: Image & Text","href":"/langchain/docs/use_cases/more/agents/multi_modal/multi_modal_output_agent","docId":"use_cases/more/agents/multi_modal/multi_modal_output_agent"}]}],"href":"/langchain/docs/use_cases/more/agents/"},{"type":"category","label":"Code writing","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Causal program-aided language (CPAL) chain","href":"/langchain/docs/use_cases/more/code_writing/cpal","docId":"use_cases/more/code_writing/cpal"},{"type":"link","label":"Bash chain","href":"/langchain/docs/use_cases/more/code_writing/llm_bash","docId":"use_cases/more/code_writing/llm_bash"},{"type":"link","label":"Math chain","href":"/langchain/docs/use_cases/more/code_writing/llm_math","docId":"use_cases/more/code_writing/llm_math"},{"type":"link","label":"LLM Symbolic Math","href":"/langchain/docs/use_cases/more/code_writing/llm_symbolic_math","docId":"use_cases/more/code_writing/llm_symbolic_math"},{"type":"link","label":"Program-aided language model (PAL) chain","href":"/langchain/docs/use_cases/more/code_writing/pal","docId":"use_cases/more/code_writing/pal"}],"href":"/langchain/docs/use_cases/more/code_writing/"},{"type":"category","label":"Analyzing graph data","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Diffbot Graph Transformer","href":"/langchain/docs/use_cases/more/graph/diffbot_graphtransformer","docId":"use_cases/more/graph/diffbot_graphtransformer"},{"type":"link","label":"ArangoDB QA chain","href":"/langchain/docs/use_cases/more/graph/graph_arangodb_qa","docId":"use_cases/more/graph/graph_arangodb_qa"},{"type":"link","label":"Neo4j DB QA chain","href":"/langchain/docs/use_cases/more/graph/graph_cypher_qa","docId":"use_cases/more/graph/graph_cypher_qa"},{"type":"link","label":"FalkorDBQAChain","href":"/langchain/docs/use_cases/more/graph/graph_falkordb_qa","docId":"use_cases/more/graph/graph_falkordb_qa"},{"type":"link","label":"HugeGraph QA Chain","href":"/langchain/docs/use_cases/more/graph/graph_hugegraph_qa","docId":"use_cases/more/graph/graph_hugegraph_qa"},{"type":"link","label":"KuzuQAChain","href":"/langchain/docs/use_cases/more/graph/graph_kuzu_qa","docId":"use_cases/more/graph/graph_kuzu_qa"},{"type":"link","label":"Memgraph QA chain","href":"/langchain/docs/use_cases/more/graph/graph_memgraph_qa","docId":"use_cases/more/graph/graph_memgraph_qa"},{"type":"link","label":"NebulaGraphQAChain","href":"/langchain/docs/use_cases/more/graph/graph_nebula_qa","docId":"use_cases/more/graph/graph_nebula_qa"},{"type":"link","label":"Graph QA","href":"/langchain/docs/use_cases/more/graph/graph_qa","docId":"use_cases/more/graph/graph_qa"},{"type":"link","label":"GraphSparqlQAChain","href":"/langchain/docs/use_cases/more/graph/graph_sparql_qa","docId":"use_cases/more/graph/graph_sparql_qa"},{"type":"link","label":"Neptune Open Cypher QA Chain","href":"/langchain/docs/use_cases/more/graph/neptune_cypher_qa","docId":"use_cases/more/graph/neptune_cypher_qa"},{"type":"link","label":"Tree of Thought (ToT) example","href":"/langchain/docs/use_cases/more/graph/tot","docId":"use_cases/more/graph/tot"}],"href":"/langchain/docs/use_cases/more/graph/"},{"type":"category","label":"Self-checking","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Self-checking chain","href":"/langchain/docs/use_cases/more/self_check/llm_checker","docId":"use_cases/more/self_check/llm_checker"},{"type":"link","label":"Summarization checker chain","href":"/langchain/docs/use_cases/more/self_check/llm_summarization_checker","docId":"use_cases/more/self_check/llm_summarization_checker"},{"type":"link","label":"How to use a SmartLLMChain","href":"/langchain/docs/use_cases/more/self_check/smart_llm","docId":"use_cases/more/self_check/smart_llm"}],"href":"/langchain/docs/use_cases/more/self_check/"}]}],"collapsed":false,"href":"/langchain/docs/use_cases"}]},"docs":{"additional_resources/dependents":{"id":"additional_resources/dependents","title":"Dependents","description":"Dependents stats for langchain-ai/langchain","sidebar":"docs"},"additional_resources/tutorials":{"id":"additional_resources/tutorials","title":"Tutorials","description":"Below are links to tutorials and courses on LangChain. For written guides on common use cases for LangChain, check out the use cases guides.","sidebar":"docs"},"additional_resources/youtube":{"id":"additional_resources/youtube","title":"YouTube videos","description":"\u26d3 icon marks a new addition [last update 2023-09-05]","sidebar":"docs"},"community":{"id":"community","title":"Community navigator","description":"Hi! Thanks for being here. We\u2019re lucky to have a community of so many passionate developers building with LangChain\u2013we have so much to teach and learn from each other. Community members contribute code, host meetups, write blog posts, amplify each other\u2019s work, become each other\'s customers and collaborators, and so much more.","sidebar":"docs"},"expression_language/cookbook":{"id":"expression_language/cookbook","title":"Cookbook","description":"In this notebook we\'ll take a look at a few common types of sequences to create.","sidebar":"docs"},"expression_language/index":{"id":"expression_language/index","title":"LangChain Expression Language (LCEL)","description":"LangChain Expression Language or LCEL is a declarative way to easily compose chains together.","sidebar":"docs"},"expression_language/interface":{"id":"expression_language/interface","title":"Interface","description":"In an effort to make it as easy as possible to create custom chains, we\'ve implemented a \\"Runnable\\" protocol that most components implement. This is a standard interface with a few different methods, which makes it easy to define custom chains as well as making it possible to invoke them in a standard way. The standard interface exposed includes:","sidebar":"docs"},"get_started/installation":{"id":"get_started/installation","title":"Installation","description":"","sidebar":"docs"},"get_started/introduction":{"id":"get_started/introduction","title":"Introduction","description":"LangChain is a framework for developing applications powered by language models. It enables applications that are:","sidebar":"docs"},"get_started/quickstart":{"id":"get_started/quickstart","title":"Quickstart","description":"Installation","sidebar":"docs"},"guides/adapters/openai":{"id":"guides/adapters/openai","title":"OpenAI Adapter","description":"A lot of people get started with OpenAI but want to explore other models. LangChain\'s integrations with many model providers make this easy to do so. While LangChain has it\'s own message and model APIs, we\'ve also made it as easy as possible to explore other models by exposing an adapter to adapt LangChain models to the OpenAI api.","sidebar":"docs"},"guides/debugging":{"id":"guides/debugging","title":"Debugging","description":"If you\'re building with LLMs, at some point something will break, and you\'ll need to debug. A model call will fail, or the model output will be misformatted, or there will be some nested model calls and it won\'t be clear where along the way an incorrect output was created.","sidebar":"docs"},"guides/deployments/index":{"id":"guides/deployments/index","title":"Deployment","description":"In today\'s fast-paced technological landscape, the use of Large Language Models (LLMs) is rapidly expanding. As a result, it\'s crucial for developers to understand how to effectively deploy these models in production environments. LLM interfaces typically fall into two categories:","sidebar":"docs"},"guides/deployments/template_repos":{"id":"guides/deployments/template_repos","title":"Template repos","description":"So, you\'ve created a really cool chain - now what? How do you deploy it and make it easily shareable with the world?","sidebar":"docs"},"guides/evaluation/comparison/custom":{"id":"guides/evaluation/comparison/custom","title":"Custom Pairwise Evaluator","description":"You can make your own pairwise string evaluators by inheriting from PairwiseStringEvaluator class and overwriting the evaluatestringpairs method (and the aevaluatestringpairs method if you want to use the evaluator asynchronously).","sidebar":"docs"},"guides/evaluation/comparison/index":{"id":"guides/evaluation/comparison/index","title":"Comparison Evaluators","description":"Comparison evaluators in LangChain help measure two different chains or LLM outputs. These evaluators are helpful for comparative analyses, such as A/B testing between two language models, or comparing different versions of the same model. They can also be useful for things like generating preference scores for ai-assisted reinforcement learning.","sidebar":"docs"},"guides/evaluation/comparison/pairwise_embedding_distance":{"id":"guides/evaluation/comparison/pairwise_embedding_distance","title":"Pairwise Embedding Distance","description":"One way to measure the similarity (or dissimilarity) between two predictions on a shared or similar input is to embed the predictions and compute a vector distance between the two embeddings.[1]","sidebar":"docs"},"guides/evaluation/comparison/pairwise_string":{"id":"guides/evaluation/comparison/pairwise_string","title":"Pairwise String Comparison","description":"Often you will want to compare predictions of an LLM, Chain, or Agent for a given input. The StringComparison evaluators facilitate this so you can answer questions like:","sidebar":"docs"},"guides/evaluation/examples/comparisons":{"id":"guides/evaluation/examples/comparisons","title":"Comparing Chain Outputs","description":"Suppose you have two different prompts (or LLMs). How do you know which will generate \\"better\\" results?","sidebar":"docs"},"guides/evaluation/examples/index":{"id":"guides/evaluation/examples/index","title":"Examples","description":"\ud83d\udea7 Docs under construction \ud83d\udea7","sidebar":"docs"},"guides/evaluation/index":{"id":"guides/evaluation/index","title":"Evaluation","description":"Building applications with language models involves many moving parts. One of the most critical components is ensuring that the outcomes produced by your models are reliable and useful across a broad array of inputs, and that they work well with your application\'s other software components. Ensuring reliability usually boils down to some combination of application design, testing & evaluation, and runtime checks.","sidebar":"docs"},"guides/evaluation/string/criteria_eval_chain":{"id":"guides/evaluation/string/criteria_eval_chain","title":"Criteria Evaluation","description":"In scenarios where you wish to assess a model\'s output using a specific rubric or criteria set, the criteria evaluator proves to be a handy tool. It allows you to verify if an LLM or Chain\'s output complies with a defined set of criteria.","sidebar":"docs"},"guides/evaluation/string/custom":{"id":"guides/evaluation/string/custom","title":"Custom String Evaluator","description":"You can make your own custom string evaluators by inheriting from the StringEvaluator class and implementing the evaluatestrings (and aevaluatestrings for async support) methods.","sidebar":"docs"},"guides/evaluation/string/embedding_distance":{"id":"guides/evaluation/string/embedding_distance","title":"Embedding Distance","description":"To measure semantic similarity (or dissimilarity) between a prediction and a reference label string, you could use a vector vector distance metric the two embedded representations using the embeddingdistance evaluator.[1]","sidebar":"docs"},"guides/evaluation/string/index":{"id":"guides/evaluation/string/index","title":"String Evaluators","description":"A string evaluator is a component within LangChain designed to assess the performance of a language model by comparing its generated outputs (predictions) to a reference string or an input. This comparison is a crucial step in the evaluation of language models, providing a measure of the accuracy or quality of the generated text.","sidebar":"docs"},"guides/evaluation/string/string_distance":{"id":"guides/evaluation/string/string_distance","title":"String Distance","description":"One of the simplest ways to compare an LLM or chain\'s string output against a reference label is by using string distance measurements such as Levenshtein or postfix distance.  This can be used alongside approximate/fuzzy matching criteria for very basic unit testing.","sidebar":"docs"},"guides/evaluation/trajectory/custom":{"id":"guides/evaluation/trajectory/custom","title":"Custom Trajectory Evaluator","description":"You can make your own custom trajectory evaluators by inheriting from the AgentTrajectoryEvaluator class and overwriting the evaluateagenttrajectory (and aevaluateagentaction) method.","sidebar":"docs"},"guides/evaluation/trajectory/index":{"id":"guides/evaluation/trajectory/index","title":"Trajectory Evaluators","description":"Trajectory Evaluators in LangChain provide a more holistic approach to evaluating an agent. These evaluators assess the full sequence of actions taken by an agent and their corresponding responses, which we refer to as the \\"trajectory\\". This allows you to better measure an agent\'s effectiveness and capabilities.","sidebar":"docs"},"guides/evaluation/trajectory/trajectory_eval":{"id":"guides/evaluation/trajectory/trajectory_eval","title":"Agent Trajectory","description":"Agents can be difficult to holistically evaluate due to the breadth of actions and generation they can make. We recommend using multiple evaluation techniques appropriate to your use case. One way to evaluate an agent is to look at the whole trajectory of actions taken along with their responses.","sidebar":"docs"},"guides/fallbacks":{"id":"guides/fallbacks","title":"Fallbacks","description":"When working with language models, you may often encounter issues from the underlying APIs, whether these be rate limiting or downtime. Therefore, as you go to move your LLM applications into production it becomes more and more important to safe guard against these. That\'s why we\'ve introduced the concept of fallbacks.","sidebar":"docs"},"guides/langsmith/index":{"id":"guides/langsmith/index","title":"LangSmith","description":"LangSmith helps you trace and evaluate your language model applications and intelligent agents to help you","sidebar":"docs"},"guides/langsmith/walkthrough":{"id":"guides/langsmith/walkthrough","title":"LangSmith Walkthrough","description":"LangChain makes it easy to prototype LLM applications and Agents. However, delivering LLM applications to production can be deceptively difficult. You will likely have to heavily customize and iterate on your prompts, chains, and other components to create a high-quality product.","sidebar":"docs"},"guides/local_llms":{"id":"guides/local_llms","title":"Run LLMs locally","description":"Use case","sidebar":"docs"},"guides/model_laboratory":{"id":"guides/model_laboratory","title":"Model comparison","description":"Constructing your language model application will likely involved choosing between many different options of prompts, models, and even chains to use. When doing so, you will want to compare these different options on different inputs in an easy, flexible, and intuitive way.","sidebar":"docs"},"guides/privacy/presidio_data_anonymization":{"id":"guides/privacy/presidio_data_anonymization","title":"Data anonymization with Microsoft Presidio","description":"Open In Collab","sidebar":"docs"},"guides/privacy/presidio_reversible_anonymization":{"id":"guides/privacy/presidio_reversible_anonymization","title":"Reversible data anonymization with Microsoft Presidio","description":"Open In Collab","sidebar":"docs"},"guides/pydantic_compatibility":{"id":"guides/pydantic_compatibility","title":"Pydantic compatibility","description":"- Pydantic v2 was released in June, 2023 (https://docs.pydantic.dev/2.0/blog/pydantic-v2-final/)","sidebar":"docs"},"guides/safety/amazon_comprehend_chain":{"id":"guides/safety/amazon_comprehend_chain","title":"Amazon Comprehend Moderation Chain","description":"---","sidebar":"docs"},"guides/safety/constitutional_chain":{"id":"guides/safety/constitutional_chain","title":"Self-critique chain with constitutional AI","description":"The ConstitutionalChain is a chain that ensures the output of a language model adheres to a predefined set of constitutional principles. By incorporating specific rules and guidelines, the ConstitutionalChain filters and modifies the generated content to align with these principles, thus providing more controlled, ethical, and contextually appropriate responses. This mechanism helps maintain the integrity of the output while minimizing the risk of generating content that may violate guidelines, be offensive, or deviate from the desired context.","sidebar":"docs"},"guides/safety/index":{"id":"guides/safety/index","title":"Moderation","description":"One of the key concerns with using LLMs is that they may generate harmful or unethical text. This is an area of active research in the field. Here we present some built-in chains inspired by this research, which are intended to make the outputs of LLMs safer.","sidebar":"docs"},"guides/safety/logical_fallacy_chain":{"id":"guides/safety/logical_fallacy_chain","title":"Removing logical fallacies from model output","description":"Logical fallacies are flawed reasoning or false arguments that can undermine the validity of a model\'s outputs. Examples include circular reasoning, false","sidebar":"docs"},"guides/safety/moderation":{"id":"guides/safety/moderation","title":"Moderation","description":"This notebook walks through examples of how to use a moderation chain, and several common ways for doing so. Moderation chains are useful for detecting text that could be hateful, violent, etc. This can be useful to apply on both user input, but also on the output of a Language Model. Some API providers, like OpenAI, specifically prohibit you, or your end users, from generating some types of harmful content. To comply with this (and to just generally prevent your application from being harmful) you may often want to append a moderation chain to any LLMChains, in order to make sure any output the LLM generates is not harmful.","sidebar":"docs"},"integrations/callbacks/argilla":{"id":"integrations/callbacks/argilla","title":"Argilla","description":"Argilla - Open-source data platform for LLMs","sidebar":"integrations"},"integrations/callbacks/context":{"id":"integrations/callbacks/context","title":"Context","description":"Context - User Analytics for LLM Powered Products","sidebar":"integrations"},"integrations/callbacks/index":{"id":"integrations/callbacks/index","title":"Callbacks","description":"","sidebar":"integrations"},"integrations/callbacks/infino":{"id":"integrations/callbacks/infino","title":"Infino","description":"This example shows how one can track the following while calling OpenAI models via LangChain and Infino:","sidebar":"integrations"},"integrations/callbacks/labelstudio":{"id":"integrations/callbacks/labelstudio","title":"Label Studio","description":"Label Studio is an open-source data labeling platform that provides LangChain with flexibility when it comes to labeling data for fine-tuning large language models (LLMs). It also enables the preparation of custom training data and the collection and evaluation of responses through human feedback.","sidebar":"integrations"},"integrations/callbacks/llmonitor":{"id":"integrations/callbacks/llmonitor","title":"LLMonitor","description":"LLMonitor is an open-source observability platform that provides cost tracking, user tracking and powerful agent tracing.","sidebar":"integrations"},"integrations/callbacks/promptlayer":{"id":"integrations/callbacks/promptlayer","title":"PromptLayer","description":"PromptLayer","sidebar":"integrations"},"integrations/callbacks/streamlit":{"id":"integrations/callbacks/streamlit","title":"Streamlit","description":"Streamlit is a faster way to build and share data apps.","sidebar":"integrations"},"integrations/chat_loaders/discord":{"id":"integrations/chat_loaders/discord","title":"Discord","description":"This notebook shows how to create your own chat loader that works on copy-pasted messages (from dms) to a list of LangChain messages.","sidebar":"integrations"},"integrations/chat_loaders/facebook":{"id":"integrations/chat_loaders/facebook","title":"Facebook Messenger","description":"This notebook shows how to load data from Facebook in a format you can finetune on. The overall steps are:","sidebar":"integrations"},"integrations/chat_loaders/gmail":{"id":"integrations/chat_loaders/gmail","title":"GMail","description":"This loader goes over how to load data from GMail. There are many ways you could want to load data from GMail. This loader is currently fairly opionated in how to do so. The way it does it is it first looks for all messages that you have sent. It then looks for messages where you are responding to a previous email. It then fetches that previous email, and creates a training example of that email, followed by your email.","sidebar":"integrations"},"integrations/chat_loaders/imessage":{"id":"integrations/chat_loaders/imessage","title":"iMessage","description":"This notebook shows how to use the iMessage chat loader. This class helps convert iMessage conversations to LangChain chat messages.","sidebar":"integrations"},"integrations/chat_loaders/index":{"id":"integrations/chat_loaders/index","title":"Chat loaders","description":"Like document loaders, chat loaders are utilities designed to help load conversations from popular communication platforms such as Facebook, Slack, Discord, etc. These are loaded into memory as LangChain chat message objects. Such utilities facilitate tasks such as fine-tuning a language model to match your personal style or voice.","sidebar":"integrations"},"integrations/chat_loaders/slack":{"id":"integrations/chat_loaders/slack","title":"Slack","description":"This notebook shows how to use the Slack chat loader. This class helps map exported slack conversations to LangChain chat messages.","sidebar":"integrations"},"integrations/chat_loaders/telegram":{"id":"integrations/chat_loaders/telegram","title":"Telegram","description":"This notebook shows how to use the Telegram chat loader. This class helps map exported Telegram conversations to LangChain chat messages.","sidebar":"integrations"},"integrations/chat_loaders/twitter":{"id":"integrations/chat_loaders/twitter","title":"Twitter (via Apify)","description":"This notebook shows how to load chat messages from Twitter to finetune on. We do this by utilizing Apify.","sidebar":"integrations"},"integrations/chat_loaders/whatsapp":{"id":"integrations/chat_loaders/whatsapp","title":"WhatsApp","description":"This notebook shows how to use the WhatsApp chat loader. This class helps map exported Telegram conversations to LangChain chat messages.","sidebar":"integrations"},"integrations/chat/anthropic":{"id":"integrations/chat/anthropic","title":"Anthropic","description":"This notebook covers how to get started with Anthropic chat models.","sidebar":"integrations"},"integrations/chat/anthropic_functions":{"id":"integrations/chat/anthropic_functions","title":"Anthropic Functions","description":"This notebook shows how to use an experimental wrapper around Anthropic that gives it the same API as OpenAI Functions.","sidebar":"integrations"},"integrations/chat/anyscale":{"id":"integrations/chat/anyscale","title":"Anyscale","description":"This notebook demonstrates the use of langchain.chat_models.ChatAnyscale for Anyscale Endpoints.","sidebar":"integrations"},"integrations/chat/azure_chat_openai":{"id":"integrations/chat/azure_chat_openai","title":"Azure","description":"This notebook goes over how to connect to an Azure hosted OpenAI endpoint","sidebar":"integrations"},"integrations/chat/azureml_chat_endpoint":{"id":"integrations/chat/azureml_chat_endpoint","title":"AzureML Chat Online Endpoint","description":"AzureML is a platform used to build, train, and deploy machine learning models. Users can explore the types of models to deploy in the Model Catalog, which provides Azure Foundation Models and OpenAI Models. Azure Foundation Models include various open-source models and popular Hugging Face models. Users can also import models of their liking into AzureML.","sidebar":"integrations"},"integrations/chat/bedrock":{"id":"integrations/chat/bedrock","title":"Bedrock Chat","description":"Amazon Bedrock is a fully managed service that makes FMs from leading AI startups and Amazon available via an API, so you can choose from a wide range of FMs to find the model that is best suited for your use case","sidebar":"integrations"},"integrations/chat/ernie":{"id":"integrations/chat/ernie","title":"ERNIE-Bot Chat","description":"ERNIE-Bot is a large language model developed by Baidu, covering a huge amount of Chinese data.","sidebar":"integrations"},"integrations/chat/google_vertex_ai_palm":{"id":"integrations/chat/google_vertex_ai_palm","title":"Google Cloud Platform Vertex AI PaLM","description":"Note: This is seperate from the Google PaLM integration. Google has chosen to offer an enterprise version of PaLM through GCP, and this supports the models made available through there.","sidebar":"integrations"},"integrations/chat/index":{"id":"integrations/chat/index","title":"Chat models","description":"","sidebar":"integrations"},"integrations/chat/jinachat":{"id":"integrations/chat/jinachat","title":"JinaChat","description":"This notebook covers how to get started with JinaChat chat models.","sidebar":"integrations"},"integrations/chat/litellm":{"id":"integrations/chat/litellm","title":"\ud83d\ude85 LiteLLM","description":"LiteLLM is a library that simplifies calling Anthropic, Azure, Huggingface, Replicate, etc.","sidebar":"integrations"},"integrations/chat/llama_api":{"id":"integrations/chat/llama_api","title":"Llama API","description":"This notebook shows how to use LangChain with LlamaAPI - a hosted version of Llama2 that adds in support for function calling.","sidebar":"integrations"},"integrations/chat/ollama":{"id":"integrations/chat/ollama","title":"Ollama","description":"Ollama allows you to run open-source large language models, such as LLaMA2, locally.","sidebar":"integrations"},"integrations/chat/openai":{"id":"integrations/chat/openai","title":"OpenAI","description":"This notebook covers how to get started with OpenAI chat models.","sidebar":"integrations"},"integrations/chat/promptlayer_chatopenai":{"id":"integrations/chat/promptlayer_chatopenai","title":"PromptLayer ChatOpenAI","description":"This example showcases how to connect to PromptLayer to start recording your ChatOpenAI requests.","sidebar":"integrations"},"integrations/document_loaders/acreom":{"id":"integrations/document_loaders/acreom","title":"acreom","description":"acreom is a dev-first knowledge base with tasks running on local markdown files.","sidebar":"integrations"},"integrations/document_loaders/airbyte_cdk":{"id":"integrations/document_loaders/airbyte_cdk","title":"Airbyte CDK","description":"Airbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.","sidebar":"integrations"},"integrations/document_loaders/airbyte_gong":{"id":"integrations/document_loaders/airbyte_gong","title":"Airbyte Gong","description":"Airbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.","sidebar":"integrations"},"integrations/document_loaders/airbyte_hubspot":{"id":"integrations/document_loaders/airbyte_hubspot","title":"Airbyte Hubspot","description":"Airbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.","sidebar":"integrations"},"integrations/document_loaders/airbyte_json":{"id":"integrations/document_loaders/airbyte_json","title":"Airbyte JSON","description":"Airbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.","sidebar":"integrations"},"integrations/document_loaders/airbyte_salesforce":{"id":"integrations/document_loaders/airbyte_salesforce","title":"Airbyte Salesforce","description":"Airbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.","sidebar":"integrations"},"integrations/document_loaders/airbyte_shopify":{"id":"integrations/document_loaders/airbyte_shopify","title":"Airbyte Shopify","description":"Airbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.","sidebar":"integrations"},"integrations/document_loaders/airbyte_stripe":{"id":"integrations/document_loaders/airbyte_stripe","title":"Airbyte Stripe","description":"Airbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.","sidebar":"integrations"},"integrations/document_loaders/airbyte_typeform":{"id":"integrations/document_loaders/airbyte_typeform","title":"Airbyte Typeform","description":"Airbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.","sidebar":"integrations"},"integrations/document_loaders/airbyte_zendesk_support":{"id":"integrations/document_loaders/airbyte_zendesk_support","title":"Airbyte Zendesk Support","description":"Airbyte is a data integration platform for ELT pipelines from APIs, databases & files to warehouses & lakes. It has the largest catalog of ELT connectors to data warehouses and databases.","sidebar":"integrations"},"integrations/document_loaders/airtable":{"id":"integrations/document_loaders/airtable","title":"Airtable","description":"* Get your API key here.","sidebar":"integrations"},"integrations/document_loaders/alibaba_cloud_maxcompute":{"id":"integrations/document_loaders/alibaba_cloud_maxcompute","title":"Alibaba Cloud MaxCompute","description":"Alibaba Cloud MaxCompute (previously known as ODPS) is a general purpose, fully managed, multi-tenancy data processing platform for large-scale data warehousing. MaxCompute supports various data importing solutions and distributed computing models, enabling users to effectively query massive datasets, reduce production costs, and ensure data security.","sidebar":"integrations"},"integrations/document_loaders/apify_dataset":{"id":"integrations/document_loaders/apify_dataset","title":"Apify Dataset","description":"Apify Dataset is a scaleable append-only storage with sequential access built for storing structured web scraping results, such as a list of products or Google SERPs, and then export them to various formats like JSON, CSV, or Excel. Datasets are mainly used to save results of Apify Actors\u2014serverless cloud programs for varius web scraping, crawling, and data extraction use cases.","sidebar":"integrations"},"integrations/document_loaders/arcgis":{"id":"integrations/document_loaders/arcgis","title":"ArcGIS","description":"This notebook demonstrates the use of the langchain.document_loaders.ArcGISLoader class.","sidebar":"integrations"},"integrations/document_loaders/arxiv":{"id":"integrations/document_loaders/arxiv","title":"Arxiv","description":"arXiv is an open-access archive for 2 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics.","sidebar":"integrations"},"integrations/document_loaders/assemblyai":{"id":"integrations/document_loaders/assemblyai","title":"AssemblyAI Audio Transcripts","description":"The AssemblyAIAudioTranscriptLoader allows to transcribe audio files with the AssemblyAI API and loads the transcribed text into documents.","sidebar":"integrations"},"integrations/document_loaders/async_chromium":{"id":"integrations/document_loaders/async_chromium","title":"Async Chromium","description":"Chromium is one of the browsers supported by Playwright, a library used to control browser automation.","sidebar":"integrations"},"integrations/document_loaders/async_html":{"id":"integrations/document_loaders/async_html","title":"AsyncHtmlLoader","description":"AsyncHtmlLoader loads raw HTML from a list of urls concurrently.","sidebar":"integrations"},"integrations/document_loaders/aws_s3_directory":{"id":"integrations/document_loaders/aws_s3_directory","title":"AWS S3 Directory","description":"Amazon Simple Storage Service (Amazon S3) is an object storage service","sidebar":"integrations"},"integrations/document_loaders/aws_s3_file":{"id":"integrations/document_loaders/aws_s3_file","title":"AWS S3 File","description":"Amazon Simple Storage Service (Amazon S3) is an object storage service.","sidebar":"integrations"},"integrations/document_loaders/azlyrics":{"id":"integrations/document_loaders/azlyrics","title":"AZLyrics","description":"AZLyrics is a large, legal, every day growing collection of lyrics.","sidebar":"integrations"},"integrations/document_loaders/azure_blob_storage_container":{"id":"integrations/document_loaders/azure_blob_storage_container","title":"Azure Blob Storage Container","description":"Azure Blob Storage is Microsoft\'s object storage solution for the cloud. Blob Storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that doesn\'t adhere to a particular data model or definition, such as text or binary data.","sidebar":"integrations"},"integrations/document_loaders/azure_blob_storage_file":{"id":"integrations/document_loaders/azure_blob_storage_file","title":"Azure Blob Storage File","description":"Azure Files offers fully managed file shares in the cloud that are accessible via the industry standard Server Message Block (SMB) protocol, Network File System (NFS) protocol, and Azure Files REST API.","sidebar":"integrations"},"integrations/document_loaders/azure_document_intelligence":{"id":"integrations/document_loaders/azure_document_intelligence","title":"Azure Document Intelligence","description":"Azure Document Intelligence (formerly known as Azure Forms Recognizer) is machine-learning","sidebar":"integrations"},"integrations/document_loaders/bibtex":{"id":"integrations/document_loaders/bibtex","title":"BibTeX","description":"BibTeX is a file format and reference management system commonly used in conjunction with LaTeX typesetting. It serves as a way to organize and store bibliographic information for academic and research documents.","sidebar":"integrations"},"integrations/document_loaders/bilibili":{"id":"integrations/document_loaders/bilibili","title":"BiliBili","description":"Bilibili is one of the most beloved long-form video sites in China.","sidebar":"integrations"},"integrations/document_loaders/blackboard":{"id":"integrations/document_loaders/blackboard","title":"Blackboard","description":"Blackboard Learn (previously the Blackboard Learning Management System) is a web-based virtual learning environment and learning management system developed by Blackboard Inc. The software features course management, customizable open architecture, and scalable design that allows integration with student information systems and authentication protocols. It may be installed on local servers, hosted by Blackboard ASP Solutions, or provided as Software as a Service hosted on Amazon Web Services. Its main purposes are stated to include the addition of online elements to courses traditionally delivered face-to-face and development of completely online courses with few or no face-to-face meetings","sidebar":"integrations"},"integrations/document_loaders/blockchain":{"id":"integrations/document_loaders/blockchain","title":"Blockchain","description":"Overview","sidebar":"integrations"},"integrations/document_loaders/brave_search":{"id":"integrations/document_loaders/brave_search","title":"Brave Search","description":"Brave Search is a search engine developed by Brave Software.","sidebar":"integrations"},"integrations/document_loaders/browserless":{"id":"integrations/document_loaders/browserless","title":"Browserless","description":"Browserless is a service that allows you to run headless Chrome instances in the cloud. It\'s a great way to run browser-based automation at scale without having to worry about managing your own infrastructure.","sidebar":"integrations"},"integrations/document_loaders/chatgpt_loader":{"id":"integrations/document_loaders/chatgpt_loader","title":"ChatGPT Data","description":"ChatGPT is an artificial intelligence (AI) chatbot developed by OpenAI.","sidebar":"integrations"},"integrations/document_loaders/college_confidential":{"id":"integrations/document_loaders/college_confidential","title":"College Confidential","description":"College Confidential gives information on 3,800+ colleges and universities.","sidebar":"integrations"},"integrations/document_loaders/concurrent":{"id":"integrations/document_loaders/concurrent","title":"Concurrent Loader","description":"Works just like the GenericLoader but concurrently for those who choose to optimize their workflow.","sidebar":"integrations"},"integrations/document_loaders/confluence":{"id":"integrations/document_loaders/confluence","title":"Confluence","description":"Confluence is a wiki collaboration platform that saves and organizes all of the project-related material. Confluence is a knowledge base that primarily handles content management activities.","sidebar":"integrations"},"integrations/document_loaders/conll-u":{"id":"integrations/document_loaders/conll-u","title":"CoNLL-U","description":"CoNLL-U is revised version of the CoNLL-X format. Annotations are encoded in plain text files (UTF-8, normalized to NFC, using only the LF character as line break, including an LF character at the end of file) with three types of lines:","sidebar":"integrations"},"integrations/document_loaders/copypaste":{"id":"integrations/document_loaders/copypaste","title":"Copy Paste","description":"This notebook covers how to load a document object from something you just want to copy and paste. In this case, you don\'t even need to use a DocumentLoader, but rather can just construct the Document directly.","sidebar":"integrations"},"integrations/document_loaders/csv":{"id":"integrations/document_loaders/csv","title":"CSV","description":"A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas.","sidebar":"integrations"},"integrations/document_loaders/cube_semantic":{"id":"integrations/document_loaders/cube_semantic","title":"Cube Semantic Layer","description":"This notebook demonstrates the process of retrieving Cube\'s data model metadata in a format suitable for passing to LLMs as embeddings, thereby enhancing contextual information.","sidebar":"integrations"},"integrations/document_loaders/datadog_logs":{"id":"integrations/document_loaders/datadog_logs","title":"Datadog Logs","description":"Datadog is a monitoring and analytics platform for cloud-scale applications.","sidebar":"integrations"},"integrations/document_loaders/diffbot":{"id":"integrations/document_loaders/diffbot","title":"Diffbot","description":"Unlike traditional web scraping tools, Diffbot doesn\'t require any rules to read the content on a page.","sidebar":"integrations"},"integrations/document_loaders/discord":{"id":"integrations/document_loaders/discord","title":"Discord","description":"Discord is a VoIP and instant messaging social platform. Users have the ability to communicate with voice calls, video calls, text messaging, media and files in private chats or as part of communities called \\"servers\\". A server is a collection of persistent chat rooms and voice channels which can be accessed via invite links.","sidebar":"integrations"},"integrations/document_loaders/docugami":{"id":"integrations/document_loaders/docugami","title":"Docugami","description":"This notebook covers how to load documents from Docugami. It provides the advantages of using this system over alternative data loaders.","sidebar":"integrations"},"integrations/document_loaders/dropbox":{"id":"integrations/document_loaders/dropbox","title":"Dropbox","description":"Drobpox is a file hosting service that brings everything-traditional files, cloud content, and web shortcuts together in one place.","sidebar":"integrations"},"integrations/document_loaders/duckdb":{"id":"integrations/document_loaders/duckdb","title":"DuckDB","description":"DuckDB is an in-process SQL OLAP database management system.","sidebar":"integrations"},"integrations/document_loaders/email":{"id":"integrations/document_loaders/email","title":"Email","description":"This notebook shows how to load email (.eml) or Microsoft Outlook (.msg) files.","sidebar":"integrations"},"integrations/document_loaders/embaas":{"id":"integrations/document_loaders/embaas","title":"Embaas","description":"embaas is a fully managed NLP API service that offers features like embedding generation, document text extraction, document to embeddings and more. You can choose a variety of pre-trained models.","sidebar":"integrations"},"integrations/document_loaders/epub":{"id":"integrations/document_loaders/epub","title":"EPub","description":"EPUB is an e-book file format that uses the \\".epub\\" file extension. The term is short for electronic publication and is sometimes styled ePub. EPUB is supported by many e-readers, and compatible software is available for most smartphones, tablets, and computers.","sidebar":"integrations"},"integrations/document_loaders/Etherscan":{"id":"integrations/document_loaders/Etherscan","title":"Etherscan Loader","description":"Overview","sidebar":"integrations"},"integrations/document_loaders/evernote":{"id":"integrations/document_loaders/evernote","title":"EverNote","description":"EverNote is intended for archiving and creating notes in which photos, audio and saved web content can be embedded. Notes are stored in virtual \\"notebooks\\" and can be tagged, annotated, edited, searched, and exported.","sidebar":"integrations"},"integrations/document_loaders/example_data/notebook":{"id":"integrations/document_loaders/example_data/notebook","title":"Notebook","description":"This notebook covers how to load data from an .ipynb notebook into a format suitable by LangChain.","sidebar":"integrations"},"integrations/document_loaders/excel":{"id":"integrations/document_loaders/excel","title":"Microsoft Excel","description":"The UnstructuredExcelLoader is used to load Microsoft Excel files. The loader works with both .xlsx and .xls files. The page content will be the raw text of the Excel file. If you use the loader in \\"elements\\" mode, an HTML representation of the Excel file will be available in the document metadata under the textashtml key.","sidebar":"integrations"},"integrations/document_loaders/facebook_chat":{"id":"integrations/document_loaders/facebook_chat","title":"Facebook Chat","description":"Messenger) is an American proprietary instant messaging app and platform developed by Meta Platforms. Originally developed as Facebook Chat in 2008, the company revamped its messaging service in 2010.","sidebar":"integrations"},"integrations/document_loaders/fauna":{"id":"integrations/document_loaders/fauna","title":"Fauna","description":"Fauna is a Document Database.","sidebar":"integrations"},"integrations/document_loaders/figma":{"id":"integrations/document_loaders/figma","title":"Figma","description":"Figma is a collaborative web application for interface design.","sidebar":"integrations"},"integrations/document_loaders/geopandas":{"id":"integrations/document_loaders/geopandas","title":"Geopandas","description":"Geopandas is an open source project to make working with geospatial data in python easier.","sidebar":"integrations"},"integrations/document_loaders/git":{"id":"integrations/document_loaders/git","title":"Git","description":"Git is a distributed version control system that tracks changes in any set of computer files, usually used for coordinating work among programmers collaboratively developing source code during software development.","sidebar":"integrations"},"integrations/document_loaders/gitbook":{"id":"integrations/document_loaders/gitbook","title":"GitBook","description":"GitBook is a modern documentation platform where teams can document everything from products to internal knowledge bases and APIs.","sidebar":"integrations"},"integrations/document_loaders/github":{"id":"integrations/document_loaders/github","title":"GitHub","description":"This notebooks shows how you can load issues and pull requests (PRs) for a given repository on GitHub. We will use the LangChain Python repository as an example.","sidebar":"integrations"},"integrations/document_loaders/google_bigquery":{"id":"integrations/document_loaders/google_bigquery","title":"Google BigQuery","description":"Google BigQuery is a serverless and cost-effective enterprise data warehouse that works across clouds and scales with your data.","sidebar":"integrations"},"integrations/document_loaders/google_cloud_storage_directory":{"id":"integrations/document_loaders/google_cloud_storage_directory","title":"Google Cloud Storage Directory","description":"Google Cloud Storage is a managed service for storing unstructured data.","sidebar":"integrations"},"integrations/document_loaders/google_cloud_storage_file":{"id":"integrations/document_loaders/google_cloud_storage_file","title":"Google Cloud Storage File","description":"Google Cloud Storage is a managed service for storing unstructured data.","sidebar":"integrations"},"integrations/document_loaders/google_drive":{"id":"integrations/document_loaders/google_drive","title":"Google Drive","description":"Google Drive is a file storage and synchronization service developed by Google.","sidebar":"integrations"},"integrations/document_loaders/grobid":{"id":"integrations/document_loaders/grobid","title":"Grobid","description":"GROBID is a machine learning library for extracting, parsing, and re-structuring raw documents.","sidebar":"integrations"},"integrations/document_loaders/gutenberg":{"id":"integrations/document_loaders/gutenberg","title":"Gutenberg","description":"Project Gutenberg is an online library of free eBooks.","sidebar":"integrations"},"integrations/document_loaders/hacker_news":{"id":"integrations/document_loaders/hacker_news","title":"Hacker News","description":"Hacker News (sometimes abbreviated as HN) is a social news website focusing on computer science and entrepreneurship. It is run by the investment fund and startup incubator Y Combinator. In general, content that can be submitted is defined as \\"anything that gratifies one\'s intellectual curiosity.\\"","sidebar":"integrations"},"integrations/document_loaders/huawei_obs_directory":{"id":"integrations/document_loaders/huawei_obs_directory","title":"Huawei OBS Directory","description":"The following code demonstrates how to load objects from the Huawei OBS (Object Storage Service) as documents.","sidebar":"integrations"},"integrations/document_loaders/huawei_obs_file":{"id":"integrations/document_loaders/huawei_obs_file","title":"Huawei OBS File","description":"The following code demonstrates how to load an object from the Huawei OBS (Object Storage Service) as document.","sidebar":"integrations"},"integrations/document_loaders/hugging_face_dataset":{"id":"integrations/document_loaders/hugging_face_dataset","title":"HuggingFace dataset","description":"The Hugging Face Hub is home to over 5,000 datasets in more than 100 languages that can be used for a broad range of tasks across NLP, Computer Vision, and Audio. They used for a diverse range of tasks such as translation,","sidebar":"integrations"},"integrations/document_loaders/ifixit":{"id":"integrations/document_loaders/ifixit","title":"iFixit","description":"iFixit is the largest, open repair community on the web. The site contains nearly 100k repair manuals, 200k Questions & Answers on 42k devices, and all the data is licensed under CC-BY-NC-SA 3.0.","sidebar":"integrations"},"integrations/document_loaders/image":{"id":"integrations/document_loaders/image","title":"Images","description":"This covers how to load images such as JPG or PNG into a document format that we can use downstream.","sidebar":"integrations"},"integrations/document_loaders/image_captions":{"id":"integrations/document_loaders/image_captions","title":"Image captions","description":"By default, the loader utilizes the pre-trained Salesforce BLIP image captioning model.","sidebar":"integrations"},"integrations/document_loaders/imsdb":{"id":"integrations/document_loaders/imsdb","title":"IMSDb","description":"IMSDb is the Internet Movie Script Database.","sidebar":"integrations"},"integrations/document_loaders/index":{"id":"integrations/document_loaders/index","title":"Document loaders","description":"","sidebar":"integrations"},"integrations/document_loaders/iugu":{"id":"integrations/document_loaders/iugu","title":"Iugu","description":"Iugu is a Brazilian services and software as a service (SaaS) company. It offers payment-processing software and application programming interfaces for e-commerce websites and mobile applications.","sidebar":"integrations"},"integrations/document_loaders/joplin":{"id":"integrations/document_loaders/joplin","title":"Joplin","description":"Joplin is an open source note-taking app. Capture your thoughts and securely access them from any device.","sidebar":"integrations"},"integrations/document_loaders/jupyter_notebook":{"id":"integrations/document_loaders/jupyter_notebook","title":"Jupyter Notebook","description":"Jupyter Notebook (formerly IPython Notebook) is a web-based interactive computational environment for creating notebook documents.","sidebar":"integrations"},"integrations/document_loaders/larksuite":{"id":"integrations/document_loaders/larksuite","title":"LarkSuite (FeiShu)","description":"LarkSuite is an enterprise collaboration platform developed by ByteDance.","sidebar":"integrations"},"integrations/document_loaders/mastodon":{"id":"integrations/document_loaders/mastodon","title":"Mastodon","description":"Mastodon is a federated social media and social networking service.","sidebar":"integrations"},"integrations/document_loaders/mediawikidump":{"id":"integrations/document_loaders/mediawikidump","title":"MediaWikiDump","description":"MediaWiki XML Dumps contain the content of a wiki (wiki pages with all their revisions), without the site-related data. A XML dump does not create a full backup of the wiki database, the dump does not contain user accounts, images, edit logs, etc.","sidebar":"integrations"},"integrations/document_loaders/merge_doc_loader":{"id":"integrations/document_loaders/merge_doc_loader","title":"MergeDocLoader","description":"Merge the documents returned from a set of specified data loaders.","sidebar":"integrations"},"integrations/document_loaders/mhtml":{"id":"integrations/document_loaders/mhtml","title":"mhtml","description":"MHTML is a is used both for emails but also for archived webpages. MHTML, sometimes referred as MHT, stands for MIME HTML is a single file in which entire webpage is archived. When one saves a webpage as MHTML format, this file extension will contain HTML code, images, audio files, flash animation etc.","sidebar":"integrations"},"integrations/document_loaders/microsoft_onedrive":{"id":"integrations/document_loaders/microsoft_onedrive","title":"Microsoft OneDrive","description":"Microsoft OneDrive (formerly SkyDrive) is a file hosting service operated by Microsoft.","sidebar":"integrations"},"integrations/document_loaders/microsoft_powerpoint":{"id":"integrations/document_loaders/microsoft_powerpoint","title":"Microsoft PowerPoint","description":"Microsoft PowerPoint is a presentation program by Microsoft.","sidebar":"integrations"},"integrations/document_loaders/microsoft_sharepoint":{"id":"integrations/document_loaders/microsoft_sharepoint","title":"Microsoft SharePoint","description":"Microsoft SharePoint is a website-based collaboration system that uses workflow applications, \u201clist\u201d databases, and other web parts and security features to empower business teams to work together developed by Microsoft.","sidebar":"integrations"},"integrations/document_loaders/microsoft_word":{"id":"integrations/document_loaders/microsoft_word","title":"Microsoft Word","description":"Microsoft Word is a word processor developed by Microsoft.","sidebar":"integrations"},"integrations/document_loaders/modern_treasury":{"id":"integrations/document_loaders/modern_treasury","title":"Modern Treasury","description":"Modern Treasury simplifies complex payment operations. It is a unified platform to power products and processes that move money.","sidebar":"integrations"},"integrations/document_loaders/news":{"id":"integrations/document_loaders/news","title":"News URL","description":"This covers how to load HTML news articles from a list of URLs into a document format that we can use downstream.","sidebar":"integrations"},"integrations/document_loaders/notion":{"id":"integrations/document_loaders/notion","title":"Notion DB 1/2","description":"Notion is a collaboration platform with modified Markdown support that integrates kanban boards, tasks, wikis and databases. It is an all-in-one workspace for notetaking, knowledge and data management, and project and task management.","sidebar":"integrations"},"integrations/document_loaders/notiondb":{"id":"integrations/document_loaders/notiondb","title":"Notion DB 2/2","description":"Notion is a collaboration platform with modified Markdown support that integrates kanban boards, tasks, wikis and databases. It is an all-in-one workspace for notetaking, knowledge and data management, and project and task management.","sidebar":"integrations"},"integrations/document_loaders/nuclia":{"id":"integrations/document_loaders/nuclia","title":"Nuclia Understanding API document loader","description":"Nuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.","sidebar":"integrations"},"integrations/document_loaders/obsidian":{"id":"integrations/document_loaders/obsidian","title":"Obsidian","description":"Obsidian is a powerful and extensible knowledge base","sidebar":"integrations"},"integrations/document_loaders/odt":{"id":"integrations/document_loaders/odt","title":"Open Document Format (ODT)","description":"The Open Document Format for Office Applications (ODF), also known as OpenDocument, is an open file format for word processing documents, spreadsheets, presentations and graphics and using ZIP-compressed XML files. It was developed with the aim of providing an open, XML-based file format specification for office applications.","sidebar":"integrations"},"integrations/document_loaders/open_city_data":{"id":"integrations/document_loaders/open_city_data","title":"Open City Data","description":"Socrata provides an API for city open data.","sidebar":"integrations"},"integrations/document_loaders/org_mode":{"id":"integrations/document_loaders/org_mode","title":"Org-mode","description":"A Org Mode document is a document editing, formatting, and organizing mode, designed for notes, planning, and authoring within the free software text editor Emacs.","sidebar":"integrations"},"integrations/document_loaders/pandas_dataframe":{"id":"integrations/document_loaders/pandas_dataframe","title":"Pandas DataFrame","description":"This notebook goes over how to load data from a pandas DataFrame.","sidebar":"integrations"},"integrations/document_loaders/pdf-amazonTextractPDFLoader":{"id":"integrations/document_loaders/pdf-amazonTextractPDFLoader","title":"Amazon Textract","description":"Amazon Textract is a machine learning (ML) service that automatically extracts text, handwriting, and data from scanned documents. It goes beyond simple optical character recognition (OCR) to identify, understand, and extract data from forms and tables. Today, many companies manually extract data from scanned documents such as PDFs, images, tables, and forms, or through simple OCR software that requires manual configuration (which often must be updated when the form changes). To overcome these manual and expensive processes, Textract uses ML to read and process any type of document, accurately extracting text, handwriting, tables, and other data with no manual effort. You can quickly automate document processing and act on the information extracted, whether you\u2019re automating loans processing or extracting information from invoices and receipts. Textract can extract the data in minutes instead of hours or days.","sidebar":"integrations"},"integrations/document_loaders/polars_dataframe":{"id":"integrations/document_loaders/polars_dataframe","title":"Polars DataFrame","description":"This notebook goes over how to load data from a polars DataFrame.","sidebar":"integrations"},"integrations/document_loaders/psychic":{"id":"integrations/document_loaders/psychic","title":"Psychic","description":"This notebook covers how to load documents from Psychic. See here for more details.","sidebar":"integrations"},"integrations/document_loaders/pubmed":{"id":"integrations/document_loaders/pubmed","title":"PubMed","description":"PubMed\xae by The National Center for Biotechnology Information, National Library of Medicine comprises more than 35 million citations for biomedical literature from MEDLINE, life science journals, and online books. Citations may include links to full text content from PubMed Central and publisher web sites.","sidebar":"integrations"},"integrations/document_loaders/pyspark_dataframe":{"id":"integrations/document_loaders/pyspark_dataframe","title":"PySpark DataFrame Loader","description":"This notebook goes over how to load data from a PySpark DataFrame.","sidebar":"integrations"},"integrations/document_loaders/readthedocs_documentation":{"id":"integrations/document_loaders/readthedocs_documentation","title":"ReadTheDocs Documentation","description":"Read the Docs is an open-sourced free software documentation hosting platform. It generates documentation written with the Sphinx documentation generator.","sidebar":"integrations"},"integrations/document_loaders/recursive_url_loader":{"id":"integrations/document_loaders/recursive_url_loader","title":"Recursive URL Loader","description":"We may want to process load all URLs under a root directory.","sidebar":"integrations"},"integrations/document_loaders/reddit":{"id":"integrations/document_loaders/reddit","title":"Reddit","description":"Reddit is an American social news aggregation, content rating, and discussion website.","sidebar":"integrations"},"integrations/document_loaders/roam":{"id":"integrations/document_loaders/roam","title":"Roam","description":"ROAM is a note-taking tool for networked thought, designed to create a personal knowledge base.","sidebar":"integrations"},"integrations/document_loaders/rockset":{"id":"integrations/document_loaders/rockset","title":"Rockset","description":"Rockset is a real-time analytics database which enables queries on massive, semi-structured data without operational burden. With Rockset, ingested data is queryable within one second and analytical queries against that data typically execute in milliseconds. Rockset is compute optimized, making it suitable for serving high concurrency applications in the sub-100TB range (or larger than 100s of TBs with rollups).","sidebar":"integrations"},"integrations/document_loaders/rss":{"id":"integrations/document_loaders/rss","title":"RSS Feeds","description":"This covers how to load HTML news articles from a list of RSS feed URLs into a document format that we can use downstream.","sidebar":"integrations"},"integrations/document_loaders/rst":{"id":"integrations/document_loaders/rst","title":"RST","description":"A reStructured Text (RST) file is a file format for textual data used primarily in the Python programming language community for technical documentation.","sidebar":"integrations"},"integrations/document_loaders/sitemap":{"id":"integrations/document_loaders/sitemap","title":"Sitemap","description":"Extends from the WebBaseLoader, SitemapLoader loads a sitemap from a given URL, and then scrape and load all pages in the sitemap, returning each page as a Document.","sidebar":"integrations"},"integrations/document_loaders/slack":{"id":"integrations/document_loaders/slack","title":"Slack","description":"Slack is an instant messaging program.","sidebar":"integrations"},"integrations/document_loaders/snowflake":{"id":"integrations/document_loaders/snowflake","title":"Snowflake","description":"This notebooks goes over how to load documents from Snowflake","sidebar":"integrations"},"integrations/document_loaders/source_code":{"id":"integrations/document_loaders/source_code","title":"Source Code","description":"This notebook covers how to load source code files using a special approach with language parsing: each top-level function and class in the code is loaded into separate documents. Any remaining code top-level code outside the already loaded functions and classes will be loaded into a seperate document.","sidebar":"integrations"},"integrations/document_loaders/spreedly":{"id":"integrations/document_loaders/spreedly","title":"Spreedly","description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","sidebar":"integrations"},"integrations/document_loaders/stripe":{"id":"integrations/document_loaders/stripe","title":"Stripe","description":"Stripe is an Irish-American financial services and software as a service (SaaS) company. It offers payment-processing software and application programming interfaces for e-commerce websites and mobile applications.","sidebar":"integrations"},"integrations/document_loaders/subtitle":{"id":"integrations/document_loaders/subtitle","title":"Subtitle","description":"The SubRip file format is described on the Matroska multimedia container format website as \\"perhaps the most basic of all subtitle formats.\\" SubRip (SubRip Text) files are named with the extension .srt, and contain formatted lines of plain text in groups separated by a blank line. Subtitles are numbered sequentially, starting at 1. The timecode format used is hoursseconds,milliseconds with time units fixed to two zero-padded digits and fractions fixed to three zero-padded digits (0000,000). The fractional separator used is the comma, since the program was written in France.","sidebar":"integrations"},"integrations/document_loaders/telegram":{"id":"integrations/document_loaders/telegram","title":"Telegram","description":"Telegram Messenger is a globally accessible freemium, cross-platform, encrypted, cloud-based and centralized instant messaging service. The application also provides optional end-to-end encrypted chats and video calling, VoIP, file sharing and several other features.","sidebar":"integrations"},"integrations/document_loaders/tencent_cos_directory":{"id":"integrations/document_loaders/tencent_cos_directory","title":"Tencent COS Directory","description":"This covers how to load document objects from a Tencent COS Directory.","sidebar":"integrations"},"integrations/document_loaders/tencent_cos_file":{"id":"integrations/document_loaders/tencent_cos_file","title":"Tencent COS File","description":"This covers how to load document object from a Tencent COS File.","sidebar":"integrations"},"integrations/document_loaders/tensorflow_datasets":{"id":"integrations/document_loaders/tensorflow_datasets","title":"TensorFlow Datasets","description":"TensorFlow Datasets is a collection of datasets ready to use, with TensorFlow or other Python ML frameworks, such as Jax. All datasets are exposed as tf.data.Datasets, enabling easy-to-use and high-performance input pipelines. To get started see the guide and the list of datasets.","sidebar":"integrations"},"integrations/document_loaders/tomarkdown":{"id":"integrations/document_loaders/tomarkdown","title":"2Markdown","description":"2markdown service transforms website content into structured markdown files.","sidebar":"integrations"},"integrations/document_loaders/toml":{"id":"integrations/document_loaders/toml","title":"TOML","description":"TOML is a file format for configuration files. It is intended to be easy to read and write, and is designed to map unambiguously to a dictionary. Its specification is open-source. TOML is implemented in many programming languages. The name TOML is an acronym for \\"Tom\'s Obvious, Minimal Language\\" referring to its creator, Tom Preston-Werner.","sidebar":"integrations"},"integrations/document_loaders/trello":{"id":"integrations/document_loaders/trello","title":"Trello","description":"Trello is a web-based project management and collaboration tool that allows individuals and teams to organize and track their tasks and projects. It provides a visual interface known as a \\"board\\" where users can create lists and cards to represent their tasks and activities.","sidebar":"integrations"},"integrations/document_loaders/tsv":{"id":"integrations/document_loaders/tsv","title":"TSV","description":"A tab-separated values (TSV) file is a simple, text-based file format for storing tabular data.[3] Records are separated by newlines, and values within a record are separated by tab characters.","sidebar":"integrations"},"integrations/document_loaders/twitter":{"id":"integrations/document_loaders/twitter","title":"Twitter","description":"Twitter is an online social media and social networking service.","sidebar":"integrations"},"integrations/document_loaders/unstructured_file":{"id":"integrations/document_loaders/unstructured_file","title":"Unstructured File","description":"This notebook covers how to use Unstructured package to load files of many types. Unstructured currently supports loading of text files, powerpoints, html, pdfs, images, and more.","sidebar":"integrations"},"integrations/document_loaders/url":{"id":"integrations/document_loaders/url","title":"URL","description":"This covers how to load HTML documents from a list of URLs into a document format that we can use downstream.","sidebar":"integrations"},"integrations/document_loaders/weather":{"id":"integrations/document_loaders/weather","title":"Weather","description":"OpenWeatherMap is an open source weather service provider","sidebar":"integrations"},"integrations/document_loaders/web_base":{"id":"integrations/document_loaders/web_base","title":"WebBaseLoader","description":"This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader","sidebar":"integrations"},"integrations/document_loaders/whatsapp_chat":{"id":"integrations/document_loaders/whatsapp_chat","title":"WhatsApp Chat","description":"WhatsApp (also called WhatsApp Messenger) is a freeware, cross-platform, centralized instant messaging (IM) and voice-over-IP (VoIP) service. It allows users to send text and voice messages, make voice and video calls, and share images, documents, user locations, and other content.","sidebar":"integrations"},"integrations/document_loaders/wikipedia":{"id":"integrations/document_loaders/wikipedia","title":"Wikipedia","description":"Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.","sidebar":"integrations"},"integrations/document_loaders/xml":{"id":"integrations/document_loaders/xml","title":"XML","description":"The UnstructuredXMLLoader is used to load XML files. The loader works with .xml files. The page content will be the text extracted from the XML tags.","sidebar":"integrations"},"integrations/document_loaders/xorbits":{"id":"integrations/document_loaders/xorbits","title":"Xorbits Pandas DataFrame","description":"This notebook goes over how to load data from a xorbits.pandas DataFrame.","sidebar":"integrations"},"integrations/document_loaders/youtube_audio":{"id":"integrations/document_loaders/youtube_audio","title":"Loading documents from a YouTube url","description":"Building chat or QA applications on YouTube videos is a topic of high interest.","sidebar":"integrations"},"integrations/document_loaders/youtube_transcript":{"id":"integrations/document_loaders/youtube_transcript","title":"YouTube transcripts","description":"YouTube is an online video sharing and social media platform created by Google.","sidebar":"integrations"},"integrations/document_transformers/beautiful_soup":{"id":"integrations/document_transformers/beautiful_soup","title":"Beautiful Soup","description":"Beautiful Soup offers fine-grained control over HTML content, enabling specific tag extraction, removal, and content cleaning.","sidebar":"integrations"},"integrations/document_transformers/docai":{"id":"integrations/document_transformers/docai","title":"docai","description":"DocAI is a Google Cloud platform to transform unstructured data from documents into structured data, making it easier to understand, analyze, and consume. You can read more about it//cloud.google.com/document-ai/docs/overview","sidebar":"integrations"},"integrations/document_transformers/doctran_extract_properties":{"id":"integrations/document_transformers/doctran_extract_properties","title":"Doctran Extract Properties","description":"We can extract useful features of documents using the Doctran library, which uses OpenAI\'s function calling feature to extract specific metadata.","sidebar":"integrations"},"integrations/document_transformers/doctran_interrogate_document":{"id":"integrations/document_transformers/doctran_interrogate_document","title":"Doctran Interrogate Documents","description":"Documents used in a vector store knowledge base are typically stored in narrative or conversational format. However, most user queries are in question format. If we convert documents into Q&A format before vectorizing them, we can increase the liklihood of retrieving relevant documents, and decrease the liklihood of retrieving irrelevant documents.","sidebar":"integrations"},"integrations/document_transformers/doctran_translate_document":{"id":"integrations/document_transformers/doctran_translate_document","title":"Doctran Translate Documents","description":"Comparing documents through embeddings has the benefit of working across multiple languages. \\"Harrison says hello\\" and \\"Harrison dice hola\\" will occupy similar positions in the vector space because they have the same meaning semantically.","sidebar":"integrations"},"integrations/document_transformers/html2text":{"id":"integrations/document_transformers/html2text","title":"html2text","description":"html2text is a Python script that converts a page of HTML into clean, easy-to-read plain ASCII text.","sidebar":"integrations"},"integrations/document_transformers/index":{"id":"integrations/document_transformers/index","title":"Document transformers","description":"","sidebar":"integrations"},"integrations/document_transformers/nuclia_transformer":{"id":"integrations/document_transformers/nuclia_transformer","title":"Nuclia Understanding API document transformer","description":"Nuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.","sidebar":"integrations"},"integrations/document_transformers/openai_metadata_tagger":{"id":"integrations/document_transformers/openai_metadata_tagger","title":"OpenAI Functions Metadata Tagger","description":"It can often be useful to tag ingested documents with structured metadata, such as the title, tone, or length of a document, to allow for more targeted similarity search later. However, for large numbers of documents, performing this labelling process manually can be tedious.","sidebar":"integrations"},"integrations/llms/ai21":{"id":"integrations/llms/ai21","title":"AI21","description":"AI21 Studio provides API access to Jurassic-2 large language models.","sidebar":"integrations"},"integrations/llms/aleph_alpha":{"id":"integrations/llms/aleph_alpha","title":"Aleph Alpha","description":"The Luminous series is a family of large language models.","sidebar":"integrations"},"integrations/llms/amazon_api_gateway":{"id":"integrations/llms/amazon_api_gateway","title":"Amazon API Gateway","description":"Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the \\"front door\\" for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications. API Gateway supports containerized and serverless workloads, as well as web applications.","sidebar":"integrations"},"integrations/llms/anyscale":{"id":"integrations/llms/anyscale","title":"Anyscale","description":"Anyscale is a fully-managed Ray platform, on which you can build, deploy, and manage scalable AI and Python applications","sidebar":"integrations"},"integrations/llms/azure_ml":{"id":"integrations/llms/azure_ml","title":"Azure ML","description":"Azure ML is a platform used to build, train, and deploy machine learning models. Users can explore the types of models to deploy in the Model Catalog, which provides Azure Foundation Models and OpenAI Models. Azure Foundation Models include various open-source models and popular Hugging Face models. Users can also import models of their liking into AzureML.","sidebar":"integrations"},"integrations/llms/azure_openai":{"id":"integrations/llms/azure_openai","title":"Azure OpenAI","description":"This notebook goes over how to use Langchain with Azure OpenAI.","sidebar":"integrations"},"integrations/llms/banana":{"id":"integrations/llms/banana","title":"Banana","description":"Banana is focused on building the machine learning infrastructure.","sidebar":"integrations"},"integrations/llms/baseten":{"id":"integrations/llms/baseten","title":"Baseten","description":"Baseten provides all the infrastructure you need to deploy and serve ML models performantly, scalably, and cost-efficiently.","sidebar":"integrations"},"integrations/llms/beam":{"id":"integrations/llms/beam","title":"Beam","description":"Calls the Beam API wrapper to deploy and make subsequent calls to an instance of the gpt2 LLM in a cloud deployment. Requires installation of the Beam library and registration of Beam Client ID and Client Secret. By calling the wrapper an instance of the model is created and run, with returned text relating to the prompt. Additional calls can then be made by directly calling the Beam API.","sidebar":"integrations"},"integrations/llms/bedrock":{"id":"integrations/llms/bedrock","title":"Bedrock","description":"Amazon Bedrock is a fully managed service that makes FMs from leading AI startups and Amazon available via an API, so you can choose from a wide range of FMs to find the model that is best suited for your use case","sidebar":"integrations"},"integrations/llms/bittensor":{"id":"integrations/llms/bittensor","title":"Bittensor","description":"Bittensor is a mining network, similar to Bitcoin, that includes built-in incentives designed to encourage miners to contribute compute + knowledge.","sidebar":"integrations"},"integrations/llms/cerebriumai":{"id":"integrations/llms/cerebriumai","title":"CerebriumAI","description":"Cerebrium is an AWS Sagemaker alternative. It also provides API access to several LLM models.","sidebar":"integrations"},"integrations/llms/chatglm":{"id":"integrations/llms/chatglm","title":"ChatGLM","description":"ChatGLM-6B is an open bilingual language model based on General Language Model (GLM) framework, with 6.2 billion parameters. With the quantization technique, users can deploy locally on consumer-grade graphics cards (only 6GB of GPU memory is required at the INT4 quantization level).","sidebar":"integrations"},"integrations/llms/clarifai":{"id":"integrations/llms/clarifai","title":"Clarifai","description":"Clarifai is an AI Platform that provides the full AI lifecycle ranging from data exploration, data labeling, model training, evaluation, and inference.","sidebar":"integrations"},"integrations/llms/cohere":{"id":"integrations/llms/cohere","title":"Cohere","description":"Cohere is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions.","sidebar":"integrations"},"integrations/llms/ctransformers":{"id":"integrations/llms/ctransformers","title":"C Transformers","description":"The C Transformers library provides Python bindings for GGML models.","sidebar":"integrations"},"integrations/llms/databricks":{"id":"integrations/llms/databricks","title":"Databricks","description":"The Databricks Lakehouse Platform unifies data, analytics, and AI on one platform.","sidebar":"integrations"},"integrations/llms/deepinfra":{"id":"integrations/llms/deepinfra","title":"DeepInfra","description":"DeepInfra provides several LLMs.","sidebar":"integrations"},"integrations/llms/deepsparse":{"id":"integrations/llms/deepsparse","title":"DeepSparse","description":"This page covers how to use the DeepSparse inference runtime within LangChain.","sidebar":"integrations"},"integrations/llms/edenai":{"id":"integrations/llms/edenai","title":"Eden AI","description":"Eden AI is revolutionizing the AI landscape by uniting the best AI providers, empowering users to unlock limitless possibilities and tap into the true potential of artificial intelligence. With an all-in-one comprehensive and hassle-free platform, it allows users to deploy AI features to production lightning fast, enabling effortless access to the full breadth of AI capabilities via a single API. (website//edenai.co/)","sidebar":"integrations"},"integrations/llms/fireworks":{"id":"integrations/llms/fireworks","title":"Fireworks","description":"Fireworks accelerates product development on generative AI by creating an innovative AI experiment and production platform.","sidebar":"integrations"},"integrations/llms/forefrontai":{"id":"integrations/llms/forefrontai","title":"ForefrontAI","description":"The Forefront platform gives you the ability to fine-tune and use open source large language models.","sidebar":"integrations"},"integrations/llms/google_vertex_ai_palm":{"id":"integrations/llms/google_vertex_ai_palm","title":"Google Vertex AI PaLM","description":"Note: This is seperate from the Google PaLM integration, it exposes Vertex AI PaLM API on Google Cloud.","sidebar":"integrations"},"integrations/llms/gooseai":{"id":"integrations/llms/gooseai","title":"GooseAI","description":"GooseAI is a fully managed NLP-as-a-Service, delivered via API. GooseAI provides access to these models.","sidebar":"integrations"},"integrations/llms/gpt4all":{"id":"integrations/llms/gpt4all","title":"GPT4All","description":"GitHub:nomic-ai/gpt4all an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue.","sidebar":"integrations"},"integrations/llms/huggingface_hub":{"id":"integrations/llms/huggingface_hub","title":"Hugging Face Hub","description":"The Hugging Face Hub is a platform with over 120k models, 20k datasets, and 50k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together.","sidebar":"integrations"},"integrations/llms/huggingface_pipelines":{"id":"integrations/llms/huggingface_pipelines","title":"Hugging Face Local Pipelines","description":"Hugging Face models can be run locally through the HuggingFacePipeline class.","sidebar":"integrations"},"integrations/llms/huggingface_textgen_inference":{"id":"integrations/llms/huggingface_textgen_inference","title":"Huggingface TextGen Inference","description":"Text Generation Inference is a Rust, Python and gRPC server for text generation inference. Used in production at HuggingFace to power LLMs api-inference widgets.","sidebar":"integrations"},"integrations/llms/index":{"id":"integrations/llms/index","title":"LLMs","description":"","sidebar":"integrations"},"integrations/llms/jsonformer_experimental":{"id":"integrations/llms/jsonformer_experimental","title":"JSONFormer","description":"JSONFormer is a library that wraps local HuggingFace pipeline models for structured decoding of a subset of the JSON Schema.","sidebar":"integrations"},"integrations/llms/koboldai":{"id":"integrations/llms/koboldai","title":"KoboldAI API","description":"KoboldAI is a \\"a browser-based front-end for AI-assisted writing with multiple local & remote AI models...\\". It has a public and local API that is able to be used in langchain.","sidebar":"integrations"},"integrations/llms/llamacpp":{"id":"integrations/llms/llamacpp","title":"Llama.cpp","description":"llama-cpp-python is a Python binding for llama.cpp.","sidebar":"integrations"},"integrations/llms/llm_caching":{"id":"integrations/llms/llm_caching","title":"LLM Caching integrations","description":"This notebook covers how to cache results of individual LLM calls using different caches.","sidebar":"integrations"},"integrations/llms/manifest":{"id":"integrations/llms/manifest","title":"Manifest","description":"This notebook goes over how to use Manifest and LangChain.","sidebar":"integrations"},"integrations/llms/minimax":{"id":"integrations/llms/minimax","title":"Minimax","description":"Minimax is a Chinese startup that provides natural language processing models for companies and individuals.","sidebar":"integrations"},"integrations/llms/modal":{"id":"integrations/llms/modal","title":"Modal","description":"The Modal cloud platform provides convenient, on-demand access to serverless cloud compute from Python scripts on your local computer.","sidebar":"integrations"},"integrations/llms/mosaicml":{"id":"integrations/llms/mosaicml","title":"MosaicML","description":"MosaicML offers a managed inference service. You can either use a variety of open source models, or deploy your own.","sidebar":"integrations"},"integrations/llms/nlpcloud":{"id":"integrations/llms/nlpcloud","title":"NLP Cloud","description":"The NLP Cloud serves high performance pre-trained or custom models for NER, sentiment-analysis, classification, summarization, paraphrasing, grammar and spelling correction, keywords and keyphrases extraction, chatbot, product description and ad generation, intent classification, text generation, image generation, blog post generation, code generation, question answering, automatic speech recognition, machine translation, language detection, semantic search, semantic similarity, tokenization, POS tagging, embeddings, and dependency parsing. It is ready for production, served through a REST API.","sidebar":"integrations"},"integrations/llms/octoai":{"id":"integrations/llms/octoai","title":"OctoAI","description":"OctoML is a service with efficient compute. It enables users to integrate their choice of AI models into applications. The OctoAI compute service helps you run, tune, and scale AI applications.","sidebar":"integrations"},"integrations/llms/ollama":{"id":"integrations/llms/ollama","title":"Ollama","description":"Ollama allows you to run open-source large language models, such as Llama 2, locally.","sidebar":"integrations"},"integrations/llms/opaqueprompts":{"id":"integrations/llms/opaqueprompts","title":"OpaquePrompts","description":"OpaquePrompts is a service that enables applications to leverage the power of language models without compromising user privacy. Designed for composability and ease of integration into existing applications and services, OpaquePrompts is consumable via a simple Python library as well as through LangChain. Perhaps more importantly, OpaquePrompts leverages the power of confidential computing to ensure that even the OpaquePrompts service itself cannot access the data it is protecting.","sidebar":"integrations"},"integrations/llms/openai":{"id":"integrations/llms/openai","title":"OpenAI","description":"OpenAI offers a spectrum of models with different levels of power suitable for different tasks.","sidebar":"integrations"},"integrations/llms/openllm":{"id":"integrations/llms/openllm","title":"OpenLLM","description":"\ud83e\uddbe OpenLLM is an open platform for operating large language models (LLMs) in production. It enables developers to easily run inference with any open-source LLMs, deploy to the cloud or on-premises, and build powerful AI apps.","sidebar":"integrations"},"integrations/llms/openlm":{"id":"integrations/llms/openlm","title":"OpenLM","description":"OpenLM is a zero-dependency OpenAI-compatible LLM provider that can call different inference endpoints directly via HTTP.","sidebar":"integrations"},"integrations/llms/petals":{"id":"integrations/llms/petals","title":"Petals","description":"Petals runs 100B+ language models at home, BitTorrent-style.","sidebar":"integrations"},"integrations/llms/pipelineai":{"id":"integrations/llms/pipelineai","title":"PipelineAI","description":"PipelineAI allows you to run your ML models at scale in the cloud. It also provides API access to several LLM models.","sidebar":"integrations"},"integrations/llms/predibase":{"id":"integrations/llms/predibase","title":"Predibase","description":"Predibase allows you to train, finetune, and deploy any ML model\u2014from linear regression to large language model.","sidebar":"integrations"},"integrations/llms/predictionguard":{"id":"integrations/llms/predictionguard","title":"Prediction Guard","description":"Basic LLM usage","sidebar":"integrations"},"integrations/llms/promptlayer_openai":{"id":"integrations/llms/promptlayer_openai","title":"PromptLayer OpenAI","description":"PromptLayer is the first platform that allows you to track, manage, and share your GPT prompt engineering. PromptLayer acts a middleware between your code and OpenAI\u2019s python library.","sidebar":"integrations"},"integrations/llms/rellm_experimental":{"id":"integrations/llms/rellm_experimental","title":"RELLM","description":"RELLM is a library that wraps local Hugging Face pipeline models for structured decoding.","sidebar":"integrations"},"integrations/llms/replicate":{"id":"integrations/llms/replicate","title":"Replicate","description":"Replicate runs machine learning models in the cloud. We have a library of open-source models that you can run with a few lines of code. If you\'re building your own machine learning models, Replicate makes it easy to deploy them at scale.","sidebar":"integrations"},"integrations/llms/runhouse":{"id":"integrations/llms/runhouse","title":"Runhouse","description":"The Runhouse allows remote compute and data across environments and users. See the Runhouse docs.","sidebar":"integrations"},"integrations/llms/sagemaker":{"id":"integrations/llms/sagemaker","title":"SageMakerEndpoint","description":"Amazon SageMaker is a system that can build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.","sidebar":"integrations"},"integrations/llms/stochasticai":{"id":"integrations/llms/stochasticai","title":"StochasticAI","description":"Stochastic Acceleration Platform aims to simplify the life cycle of a Deep Learning model. From uploading and versioning the model, through training, compression and acceleration to putting it into production.","sidebar":"integrations"},"integrations/llms/symblai_nebula":{"id":"integrations/llms/symblai_nebula","title":"Nebula (Symbl.ai)","description":"Nebula is a large language model (LLM) built by Symbl.ai. It is trained to perform generative tasks on human conversations. Nebula excels at modeling the nuanced details of a conversation and performing tasks on the conversation.","sidebar":"integrations"},"integrations/llms/textgen":{"id":"integrations/llms/textgen","title":"TextGen","description":"GitHub:oobabooga/text-generation-webui A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.","sidebar":"integrations"},"integrations/llms/titan_takeoff":{"id":"integrations/llms/titan_takeoff","title":"Titan Takeoff","description":"TitanML helps businesses build and deploy better, smaller, cheaper, and faster NLP models through our training, compression, and inference optimization platform.","sidebar":"integrations"},"integrations/llms/tongyi":{"id":"integrations/llms/tongyi","title":"Tongyi Qwen","description":"Tongyi Qwen is a large-scale language model developed by Alibaba\'s Damo Academy. It is capable of understanding user intent through natural language understanding and semantic analysis, based on user input in natural language. It provides services and assistance to users in different domains and tasks. By providing clear and detailed instructions, you can obtain results that better align with your expectations.","sidebar":"integrations"},"integrations/llms/vllm":{"id":"integrations/llms/vllm","title":"vLLM","description":"vLLM is a fast and easy-to-use library for LLM inference and serving, offering:","sidebar":"integrations"},"integrations/llms/writer":{"id":"integrations/llms/writer","title":"Writer","description":"Writer is a platform to generate different language content.","sidebar":"integrations"},"integrations/llms/xinference":{"id":"integrations/llms/xinference","title":"Xorbits Inference (Xinference)","description":"Xinference is a powerful and versatile library designed to serve LLMs,","sidebar":"integrations"},"integrations/memory/cassandra_chat_message_history":{"id":"integrations/memory/cassandra_chat_message_history","title":"Cassandra Chat Message History","description":"Apache Cassandra\xae is a NoSQL, row-oriented, highly scalable and highly available database, well suited for storing large amounts of data.","sidebar":"integrations"},"integrations/memory/dynamodb_chat_message_history":{"id":"integrations/memory/dynamodb_chat_message_history","title":"Dynamodb Chat Message History","description":"This notebook goes over how to use Dynamodb to store chat message history.","sidebar":"integrations"},"integrations/memory/entity_memory_with_sqlite":{"id":"integrations/memory/entity_memory_with_sqlite","title":"Entity Memory with SQLite storage","description":"In this walkthrough we\'ll create a simple conversation chain which uses ConversationEntityMemory backed by a SqliteEntityStore.","sidebar":"integrations"},"integrations/memory/index":{"id":"integrations/memory/index","title":"Memory","description":"","sidebar":"integrations"},"integrations/memory/momento_chat_message_history":{"id":"integrations/memory/momento_chat_message_history","title":"Momento Chat Message History","description":"This notebook goes over how to use Momento Cache to store chat message history using the MomentoChatMessageHistory class. See the Momento docs for more detail on how to get set up with Momento.","sidebar":"integrations"},"integrations/memory/mongodb_chat_message_history":{"id":"integrations/memory/mongodb_chat_message_history","title":"Mongodb Chat Message History","description":"This notebook goes over how to use Mongodb to store chat message history.","sidebar":"integrations"},"integrations/memory/motorhead_memory":{"id":"integrations/memory/motorhead_memory","title":"Mot\xf6rhead Memory","description":"Mot\xf6rhead is a memory server implemented in Rust. It automatically handles incremental summarization in the background and allows for stateless applications.","sidebar":"integrations"},"integrations/memory/motorhead_memory_managed":{"id":"integrations/memory/motorhead_memory_managed","title":"Mot\xf6rhead Memory (Managed)","description":"Mot\xf6rhead is a memory server implemented in Rust. It automatically handles incremental summarization in the background and allows for stateless applications.","sidebar":"integrations"},"integrations/memory/postgres_chat_message_history":{"id":"integrations/memory/postgres_chat_message_history","title":"Postgres Chat Message History","description":"This notebook goes over how to use Postgres to store chat message history.","sidebar":"integrations"},"integrations/memory/redis_chat_message_history":{"id":"integrations/memory/redis_chat_message_history","title":"Redis Chat Message History","description":"This notebook goes over how to use Redis to store chat message history.","sidebar":"integrations"},"integrations/memory/rockset_chat_message_history":{"id":"integrations/memory/rockset_chat_message_history","title":"Rockset Chat Message History","description":"This notebook goes over how to use Rockset to store chat message history.","sidebar":"integrations"},"integrations/memory/sql_chat_message_history":{"id":"integrations/memory/sql_chat_message_history","title":"SQL Chat Message History","description":"This notebook goes over a SQLChatMessageHistory class that allows to store chat history in any database supported by SQLAlchemy.","sidebar":"integrations"},"integrations/memory/streamlit_chat_message_history":{"id":"integrations/memory/streamlit_chat_message_history","title":"Streamlit Chat Message History","description":"This notebook goes over how to store and use chat message history in a Streamlit app. StreamlitChatMessageHistory will store messages in","sidebar":"integrations"},"integrations/memory/xata_chat_message_history":{"id":"integrations/memory/xata_chat_message_history","title":"Xata chat memory","description":"Xata is a serverless data platform, based on PostgreSQL and Elasticsearch. It provides a Python SDK for interacting with your database, and a UI for managing your data. With the XataChatMessageHistory class, you can use Xata databases for longer-term persistence of chat sessions.","sidebar":"integrations"},"integrations/memory/zep_memory":{"id":"integrations/memory/zep_memory","title":"Zep Memory","description":"REACT Agent Chat Message History with Zep - A long-term memory store for LLM applications.","sidebar":"integrations"},"integrations/providers/activeloop_deeplake":{"id":"integrations/providers/activeloop_deeplake","title":"Activeloop Deep Lake","description":"This page covers how to use the Deep Lake ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/ai21":{"id":"integrations/providers/ai21","title":"AI21 Labs","description":"This page covers how to use the AI21 ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/aim_tracking":{"id":"integrations/providers/aim_tracking","title":"Aim","description":"Aim makes it super easy to visualize and debug LangChain executions. Aim tracks inputs and outputs of LLMs and tools, as well as actions of agents.","sidebar":"integrations"},"integrations/providers/ainetwork":{"id":"integrations/providers/ainetwork","title":"AINetwork","description":"AI Network is a layer 1 blockchain designed to accommodate","sidebar":"integrations"},"integrations/providers/airbyte":{"id":"integrations/providers/airbyte","title":"Airbyte","description":"Airbyte is a data integration platform for ELT pipelines from APIs,","sidebar":"integrations"},"integrations/providers/airtable":{"id":"integrations/providers/airtable","title":"Airtable","description":"Airtable is a cloud collaboration service.","sidebar":"integrations"},"integrations/providers/aleph_alpha":{"id":"integrations/providers/aleph_alpha","title":"Aleph Alpha","description":"Aleph Alpha was founded in 2019 with the mission to research and build the foundational technology for an era of strong AI. The team of international scientists, engineers, and innovators researches, develops, and deploys transformative AI like large language and multimodal models and runs the fastest European commercial AI cluster.","sidebar":"integrations"},"integrations/providers/alibabacloud_opensearch":{"id":"integrations/providers/alibabacloud_opensearch","title":"Alibaba Cloud Opensearch","description":"Alibaba Cloud Opensearch OpenSearch is a one-stop platform to develop intelligent search services. OpenSearch was built based on the large-scale distributed search engine developed by Alibaba. OpenSearch serves more than 500 business cases in Alibaba Group and thousands of Alibaba Cloud customers. OpenSearch helps develop search services in different search scenarios, including e-commerce, O2O, multimedia, the content industry, communities and forums, and big data query in enterprises.","sidebar":"integrations"},"integrations/providers/amazon_api_gateway":{"id":"integrations/providers/amazon_api_gateway","title":"Amazon API Gateway","description":"Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the \\"front door\\" for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications. API Gateway supports containerized and serverless workloads, as well as web applications.","sidebar":"integrations"},"integrations/providers/analyticdb":{"id":"integrations/providers/analyticdb","title":"AnalyticDB","description":"This page covers how to use the AnalyticDB ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/annoy":{"id":"integrations/providers/annoy","title":"Annoy","description":"Annoy (Approximate Nearest Neighbors Oh Yeah) is a C++ library with Python bindings to search for points in space that are close to a given query point. It also creates large read-only file-based data structures that are mmapped into memory so that many processes may share the same data.","sidebar":"integrations"},"integrations/providers/anyscale":{"id":"integrations/providers/anyscale","title":"Anyscale","description":"This page covers how to use the Anyscale ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/apify":{"id":"integrations/providers/apify","title":"Apify","description":"This page covers how to use Apify within LangChain.","sidebar":"integrations"},"integrations/providers/arangodb":{"id":"integrations/providers/arangodb","title":"ArangoDB","description":"ArangoDB is a scalable graph database system to drive value from connected data, faster. Native graphs, an integrated search engine, and JSON support, via a single query language. ArangoDB runs on-prem, in the cloud \u2013 anywhere.","sidebar":"integrations"},"integrations/providers/argilla":{"id":"integrations/providers/argilla","title":"Argilla","description":"Argilla - Open-source data platform for LLMs","sidebar":"integrations"},"integrations/providers/arthur_tracking":{"id":"integrations/providers/arthur_tracking","title":"Arthur","description":"Arthur is a model monitoring and observability platform.","sidebar":"integrations"},"integrations/providers/arxiv":{"id":"integrations/providers/arxiv","title":"Arxiv","description":"arXiv is an open-access archive for 2 million scholarly articles in the fields of physics,","sidebar":"integrations"},"integrations/providers/atlas":{"id":"integrations/providers/atlas","title":"Atlas","description":"Nomic Atlas is a platform for interacting with both","sidebar":"integrations"},"integrations/providers/awadb":{"id":"integrations/providers/awadb","title":"AwaDB","description":"AwaDB is an AI Native database for the search and storage of embedding vectors used by LLM Applications.","sidebar":"integrations"},"integrations/providers/aws_s3":{"id":"integrations/providers/aws_s3","title":"AWS S3 Directory","description":"Amazon Simple Storage Service (Amazon S3) is an object storage service.","sidebar":"integrations"},"integrations/providers/azlyrics":{"id":"integrations/providers/azlyrics","title":"AZLyrics","description":"AZLyrics is a large, legal, every day growing collection of lyrics.","sidebar":"integrations"},"integrations/providers/azure_blob_storage":{"id":"integrations/providers/azure_blob_storage","title":"Azure Blob Storage","description":"Azure Blob Storage is Microsoft\'s object storage solution for the cloud. Blob Storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that doesn\'t adhere to a particular data model or definition, such as text or binary data.","sidebar":"integrations"},"integrations/providers/azure_cognitive_search_":{"id":"integrations/providers/azure_cognitive_search_","title":"Azure Cognitive Search","description":"Azure Cognitive Search (formerly known as Azure Search) is a cloud search service that gives developers infrastructure, APIs, and tools for building a rich search experience over private, heterogeneous content in web, mobile, and enterprise applications.","sidebar":"integrations"},"integrations/providers/azure_openai":{"id":"integrations/providers/azure_openai","title":"Azure OpenAI","description":"Microsoft Azure, often referred to as Azure is a cloud computing platform run by Microsoft, which offers access, management, and development of applications and services through global data centers. It provides a range of capabilities, including software as a service (SaaS), platform as a service (PaaS), and infrastructure as a service (IaaS). Microsoft Azure supports many programming languages, tools, and frameworks, including Microsoft-specific and third-party software and systems.","sidebar":"integrations"},"integrations/providers/bageldb":{"id":"integrations/providers/bageldb","title":"BagelDB","description":"BagelDB (Open Vector Database for AI), is like GitHub for AI data.","sidebar":"integrations"},"integrations/providers/bananadev":{"id":"integrations/providers/bananadev","title":"Banana","description":"Banana provided serverless GPU inference for AI models, including a CI/CD build pipeline and a simple Python framework (Potassium) to server your models.","sidebar":"integrations"},"integrations/providers/baseten":{"id":"integrations/providers/baseten","title":"Baseten","description":"Learn how to use LangChain with models deployed on Baseten.","sidebar":"integrations"},"integrations/providers/beam":{"id":"integrations/providers/beam","title":"Beam","description":"This page covers how to use Beam within LangChain.","sidebar":"integrations"},"integrations/providers/bedrock":{"id":"integrations/providers/bedrock","title":"Bedrock","description":"Amazon Bedrock is a fully managed service that makes FMs from leading AI startups and Amazon available via an API, so you can choose from a wide range of FMs to find the model that is best suited for your use case.","sidebar":"integrations"},"integrations/providers/bilibili":{"id":"integrations/providers/bilibili","title":"BiliBili","description":"Bilibili is one of the most beloved long-form video sites in China.","sidebar":"integrations"},"integrations/providers/bittensor":{"id":"integrations/providers/bittensor","title":"NIBittensor","description":"This page covers how to use the BittensorLLM inference runtime within LangChain.","sidebar":"integrations"},"integrations/providers/blackboard":{"id":"integrations/providers/blackboard","title":"Blackboard","description":"Blackboard Learn (previously the Blackboard Learning Management System)","sidebar":"integrations"},"integrations/providers/brave_search":{"id":"integrations/providers/brave_search","title":"Brave Search","description":"Brave Search is a search engine developed by Brave Software.","sidebar":"integrations"},"integrations/providers/cassandra":{"id":"integrations/providers/cassandra","title":"Cassandra","description":"Apache Cassandra\xae is a free and open-source, distributed, wide-column","sidebar":"integrations"},"integrations/providers/cerebriumai":{"id":"integrations/providers/cerebriumai","title":"CerebriumAI","description":"This page covers how to use the CerebriumAI ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/chaindesk":{"id":"integrations/providers/chaindesk","title":"Chaindesk","description":"Chaindesk is an open source document retrieval platform that helps to connect your personal data with Large Language Models.","sidebar":"integrations"},"integrations/providers/chroma":{"id":"integrations/providers/chroma","title":"Chroma","description":"Chroma is a database for building AI applications with embeddings.","sidebar":"integrations"},"integrations/providers/clarifai":{"id":"integrations/providers/clarifai","title":"Clarifai","description":"Clarifai is one of first deep learning platforms having been founded in 2013. Clarifai provides an AI platform with the full AI lifecycle for data exploration, data labeling, model training, evaluation and inference around images, video, text and audio data. In the LangChain ecosystem, as far as we\'re aware, Clarifai is the only provider that supports LLMs, embeddings and a vector store in one production scale platform, making it an excellent choice to operationalize your LangChain implementations.","sidebar":"integrations"},"integrations/providers/clearml_tracking":{"id":"integrations/providers/clearml_tracking","title":"ClearML","description":"ClearML is a ML/DL development and production suite, it contains 5 main modules:","sidebar":"integrations"},"integrations/providers/clickhouse":{"id":"integrations/providers/clickhouse","title":"ClickHouse","description":"ClickHouse is the fast and resource efficient open-source database for real-time","sidebar":"integrations"},"integrations/providers/cnosdb":{"id":"integrations/providers/cnosdb","title":"CnosDB","description":"CnosDB is an open source distributed time series database with high performance, high compression rate and high ease of use.","sidebar":"integrations"},"integrations/providers/cohere":{"id":"integrations/providers/cohere","title":"Cohere","description":"Cohere is a Canadian startup that provides natural language processing models","sidebar":"integrations"},"integrations/providers/college_confidential":{"id":"integrations/providers/college_confidential","title":"College Confidential","description":"College Confidential gives information on 3,800+ colleges and universities.","sidebar":"integrations"},"integrations/providers/comet_tracking":{"id":"integrations/providers/comet_tracking","title":"Comet","description":"In this guide we will demonstrate how to track your Langchain Experiments, Evaluation Metrics, and LLM Sessions with Comet.","sidebar":"integrations"},"integrations/providers/confluence":{"id":"integrations/providers/confluence","title":"Confluence","description":"Confluence is a wiki collaboration platform that saves and organizes all of the project-related material. Confluence is a knowledge base that primarily handles content management activities.","sidebar":"integrations"},"integrations/providers/ctransformers":{"id":"integrations/providers/ctransformers","title":"C Transformers","description":"This page covers how to use the C Transformers library within LangChain.","sidebar":"integrations"},"integrations/providers/dashvector":{"id":"integrations/providers/dashvector","title":"DashVector","description":"DashVector is a fully-managed vectorDB service that supports high-dimension dense and sparse vectors, real-time insertion and filtered search. It is built to scale automatically and can adapt to different application requirements.","sidebar":"integrations"},"integrations/providers/databricks":{"id":"integrations/providers/databricks","title":"Databricks","description":"The Databricks Lakehouse Platform unifies data, analytics, and AI on one platform.","sidebar":"integrations"},"integrations/providers/datadog":{"id":"integrations/providers/datadog","title":"Datadog Tracing","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","sidebar":"integrations"},"integrations/providers/datadog_logs":{"id":"integrations/providers/datadog_logs","title":"Datadog Logs","description":"Datadog is a monitoring and analytics platform for cloud-scale applications.","sidebar":"integrations"},"integrations/providers/dataforseo":{"id":"integrations/providers/dataforseo","title":"DataForSEO","description":"This page provides instructions on how to use the DataForSEO search APIs within LangChain.","sidebar":"integrations"},"integrations/providers/deepinfra":{"id":"integrations/providers/deepinfra","title":"DeepInfra","description":"This page covers how to use the DeepInfra ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/deepsparse":{"id":"integrations/providers/deepsparse","title":"DeepSparse","description":"This page covers how to use the DeepSparse inference runtime within LangChain.","sidebar":"integrations"},"integrations/providers/diffbot":{"id":"integrations/providers/diffbot","title":"Diffbot","description":"Diffbot is a service to read web pages. Unlike traditional web scraping tools,","sidebar":"integrations"},"integrations/providers/dingo":{"id":"integrations/providers/dingo","title":"Dingo","description":"This page covers how to use the Dingo ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/discord":{"id":"integrations/providers/discord","title":"Discord","description":"Discord is a VoIP and instant messaging social platform. Users have the ability to communicate","sidebar":"integrations"},"integrations/providers/docarray":{"id":"integrations/providers/docarray","title":"DocArray","description":"DocArray is a library for nested, unstructured, multimodal data in transit,","sidebar":"integrations"},"integrations/providers/docugami":{"id":"integrations/providers/docugami","title":"Docugami","description":"Docugami converts business documents into a Document XML Knowledge Graph, generating forests","sidebar":"integrations"},"integrations/providers/duckdb":{"id":"integrations/providers/duckdb","title":"DuckDB","description":"DuckDB is an in-process SQL OLAP database management system.","sidebar":"integrations"},"integrations/providers/elasticsearch":{"id":"integrations/providers/elasticsearch","title":"Elasticsearch","description":"Elasticsearch is a distributed, RESTful search and analytics engine.","sidebar":"integrations"},"integrations/providers/epsilla":{"id":"integrations/providers/epsilla","title":"Epsilla","description":"This page covers how to use Epsilla within LangChain.","sidebar":"integrations"},"integrations/providers/evernote":{"id":"integrations/providers/evernote","title":"EverNote","description":"EverNote is intended for archiving and creating notes in which photos, audio and saved web content can be embedded. Notes are stored in virtual \\"notebooks\\" and can be tagged, annotated, edited, searched, and exported.","sidebar":"integrations"},"integrations/providers/facebook_chat":{"id":"integrations/providers/facebook_chat","title":"Facebook Chat","description":"Messenger) is an American proprietary instant messaging app and","sidebar":"integrations"},"integrations/providers/facebook_faiss":{"id":"integrations/providers/facebook_faiss","title":"Facebook Faiss","description":"Facebook AI Similarity Search (Faiss)","sidebar":"integrations"},"integrations/providers/figma":{"id":"integrations/providers/figma","title":"Figma","description":"Figma is a collaborative web application for interface design.","sidebar":"integrations"},"integrations/providers/fireworks":{"id":"integrations/providers/fireworks","title":"Fireworks","description":"This page covers how to use the Fireworks models within Langchain.","sidebar":"integrations"},"integrations/providers/flyte":{"id":"integrations/providers/flyte","title":"Flyte","description":"Flyte is an open-source orchestrator that facilitates building production-grade data and ML pipelines.","sidebar":"integrations"},"integrations/providers/forefrontai":{"id":"integrations/providers/forefrontai","title":"ForefrontAI","description":"This page covers how to use the ForefrontAI ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/git":{"id":"integrations/providers/git","title":"Git","description":"Git is a distributed version control system that tracks changes in any set of computer files, usually used for coordinating work among programmers collaboratively developing source code during software development.","sidebar":"integrations"},"integrations/providers/gitbook":{"id":"integrations/providers/gitbook","title":"GitBook","description":"GitBook is a modern documentation platform where teams can document everything from products to internal knowledge bases and APIs.","sidebar":"integrations"},"integrations/providers/golden":{"id":"integrations/providers/golden","title":"Golden","description":"Golden provides a set of natural language APIs for querying and enrichment using the Golden Knowledge Graph e.g. queries such as: Products from OpenAI, Generative ai companies with series a funding, and rappers who invest can be used to retrieve structured data about relevant entities.","sidebar":"integrations"},"integrations/providers/google_bigquery":{"id":"integrations/providers/google_bigquery","title":"Google BigQuery","description":"Google BigQuery is a serverless and cost-effective enterprise data warehouse that works across clouds and scales with your data.","sidebar":"integrations"},"integrations/providers/google_cloud_storage":{"id":"integrations/providers/google_cloud_storage","title":"Google Cloud Storage","description":"Google Cloud Storage is a managed service for storing unstructured data.","sidebar":"integrations"},"integrations/providers/google_drive":{"id":"integrations/providers/google_drive","title":"Google Drive","description":"Google Drive is a file storage and synchronization service developed by Google.","sidebar":"integrations"},"integrations/providers/google_search":{"id":"integrations/providers/google_search","title":"Google Search","description":"This page covers how to use the Google Search API within LangChain.","sidebar":"integrations"},"integrations/providers/google_serper":{"id":"integrations/providers/google_serper","title":"Google Serper","description":"This page covers how to use the Serper Google Search API within LangChain. Serper is a low-cost Google Search API that can be used to add answer box, knowledge graph, and organic results data from Google Search.","sidebar":"integrations"},"integrations/providers/google_vertex_ai_matchingengine":{"id":"integrations/providers/google_vertex_ai_matchingengine","title":"Google Vertex AI MatchingEngine","description":"Google Vertex AI Matching Engine provides","sidebar":"integrations"},"integrations/providers/gooseai":{"id":"integrations/providers/gooseai","title":"GooseAI","description":"This page covers how to use the GooseAI ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/gpt4all":{"id":"integrations/providers/gpt4all","title":"GPT4All","description":"This page covers how to use the GPT4All wrapper within LangChain. The tutorial is divided into two parts: installation and setup, followed by usage with an example.","sidebar":"integrations"},"integrations/providers/graphsignal":{"id":"integrations/providers/graphsignal","title":"Graphsignal","description":"This page covers how to use Graphsignal to trace and monitor LangChain. Graphsignal enables full visibility into your application. It provides latency breakdowns by chains and tools, exceptions with full context, data monitoring, compute/GPU utilization, OpenAI cost analytics, and more.","sidebar":"integrations"},"integrations/providers/grobid":{"id":"integrations/providers/grobid","title":"Grobid","description":"GROBID is a machine learning library for extracting, parsing, and re-structuring raw documents.","sidebar":"integrations"},"integrations/providers/gutenberg":{"id":"integrations/providers/gutenberg","title":"Gutenberg","description":"Project Gutenberg is an online library of free eBooks.","sidebar":"integrations"},"integrations/providers/hacker_news":{"id":"integrations/providers/hacker_news","title":"Hacker News","description":"Hacker News (sometimes abbreviated as HN) is a social news","sidebar":"integrations"},"integrations/providers/hazy_research":{"id":"integrations/providers/hazy_research","title":"Hazy Research","description":"This page covers how to use the Hazy Research ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/helicone":{"id":"integrations/providers/helicone","title":"Helicone","description":"This page covers how to use the Helicone ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/hologres":{"id":"integrations/providers/hologres","title":"Hologres","description":"Hologres is a unified real-time data warehousing service developed by Alibaba Cloud. You can use Hologres to write, update, process, and analyze large amounts of data in real time.","sidebar":"integrations"},"integrations/providers/huggingface":{"id":"integrations/providers/huggingface","title":"Hugging Face","description":"This page covers how to use the Hugging Face ecosystem (including the Hugging Face Hub) within LangChain.","sidebar":"integrations"},"integrations/providers/ifixit":{"id":"integrations/providers/ifixit","title":"iFixit","description":"iFixit is the largest, open repair community on the web. The site contains nearly 100k","sidebar":"integrations"},"integrations/providers/imsdb":{"id":"integrations/providers/imsdb","title":"IMSDb","description":"IMSDb is the Internet Movie Script Database.","sidebar":"integrations"},"integrations/providers/index":{"id":"integrations/providers/index","title":"Grouped by provider","description":"","sidebar":"integrations"},"integrations/providers/infino":{"id":"integrations/providers/infino","title":"Infino","description":"Infino is an open-source observability platform that stores both metrics and application logs together.","sidebar":"integrations"},"integrations/providers/jina":{"id":"integrations/providers/jina","title":"Jina","description":"This page covers how to use the Jina ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/lancedb":{"id":"integrations/providers/lancedb","title":"LanceDB","description":"This page covers how to use LanceDB within LangChain.","sidebar":"integrations"},"integrations/providers/langchain_decorators":{"id":"integrations/providers/langchain_decorators","title":"LangChain Decorators \u2728","description":"lanchchain decorators is a layer on the top of LangChain that provides syntactic sugar \ud83c\udf6d for writing custom langchain prompts and chains","sidebar":"integrations"},"integrations/providers/llamacpp":{"id":"integrations/providers/llamacpp","title":"Llama.cpp","description":"This page covers how to use llama.cpp within LangChain.","sidebar":"integrations"},"integrations/providers/log10":{"id":"integrations/providers/log10","title":"Log10","description":"This page covers how to use the Log10 within LangChain.","sidebar":"integrations"},"integrations/providers/marqo":{"id":"integrations/providers/marqo","title":"Marqo","description":"This page covers how to use the Marqo ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/mediawikidump":{"id":"integrations/providers/mediawikidump","title":"MediaWikiDump","description":"MediaWiki XML Dumps contain the content of a wiki","sidebar":"integrations"},"integrations/providers/meilisearch":{"id":"integrations/providers/meilisearch","title":"Meilisearch","description":"Meilisearch is an open-source, lightning-fast, and hyper","sidebar":"integrations"},"integrations/providers/metal":{"id":"integrations/providers/metal","title":"Metal","description":"This page covers how to use Metal within LangChain.","sidebar":"integrations"},"integrations/providers/microsoft_onedrive":{"id":"integrations/providers/microsoft_onedrive","title":"Microsoft OneDrive","description":"Microsoft OneDrive (formerly SkyDrive) is a file-hosting service operated by Microsoft.","sidebar":"integrations"},"integrations/providers/microsoft_powerpoint":{"id":"integrations/providers/microsoft_powerpoint","title":"Microsoft PowerPoint","description":"Microsoft PowerPoint is a presentation program by Microsoft.","sidebar":"integrations"},"integrations/providers/microsoft_word":{"id":"integrations/providers/microsoft_word","title":"Microsoft Word","description":"Microsoft Word is a word processor developed by Microsoft.","sidebar":"integrations"},"integrations/providers/milvus":{"id":"integrations/providers/milvus","title":"Milvus","description":"This page covers how to use the Milvus ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/minimax":{"id":"integrations/providers/minimax","title":"Minimax","description":"Minimax is a Chinese startup that provides natural language processing models","sidebar":"integrations"},"integrations/providers/mlflow_ai_gateway":{"id":"integrations/providers/mlflow_ai_gateway","title":"MLflow AI Gateway","description":"The MLflow AI Gateway service is a powerful tool designed to streamline the usage and management of various large","sidebar":"integrations"},"integrations/providers/mlflow_tracking":{"id":"integrations/providers/mlflow_tracking","title":"MLflow","description":"MLflow is a versatile, expandable, open-source platform for managing workflows and artifacts across the machine learning lifecycle. It has built-in integrations with many popular ML libraries, but can be used with any library, algorithm, or deployment tool. It is designed to be extensible, so you can write plugins to support new workflows, libraries, and tools.","sidebar":"integrations"},"integrations/providers/modal":{"id":"integrations/providers/modal","title":"Modal","description":"This page covers how to use the Modal ecosystem to run LangChain custom LLMs.","sidebar":"integrations"},"integrations/providers/modelscope":{"id":"integrations/providers/modelscope","title":"ModelScope","description":"This page covers how to use the modelscope ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/modern_treasury":{"id":"integrations/providers/modern_treasury","title":"Modern Treasury","description":"Modern Treasury simplifies complex payment operations. It is a unified platform to power products and processes that move money.","sidebar":"integrations"},"integrations/providers/momento":{"id":"integrations/providers/momento","title":"Momento","description":"Momento Cache is the world\'s first truly serverless caching service. It provides instant elasticity, scale-to-zero","sidebar":"integrations"},"integrations/providers/mongodb_atlas":{"id":"integrations/providers/mongodb_atlas","title":"MongoDB Atlas","description":"MongoDB Atlas is a fully-managed cloud","sidebar":"integrations"},"integrations/providers/motherduck":{"id":"integrations/providers/motherduck","title":"Motherduck","description":"Motherduck is a managed DuckDB-in-the-cloud service.","sidebar":"integrations"},"integrations/providers/myscale":{"id":"integrations/providers/myscale","title":"MyScale","description":"This page covers how to use MyScale vector database within LangChain.","sidebar":"integrations"},"integrations/providers/neo4j":{"id":"integrations/providers/neo4j","title":"Neo4j","description":"This page covers how to use the Neo4j ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/nlpcloud":{"id":"integrations/providers/nlpcloud","title":"NLPCloud","description":"This page covers how to use the NLPCloud ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/notion":{"id":"integrations/providers/notion","title":"Notion DB","description":"Notion is a collaboration platform with modified Markdown support that integrates kanban","sidebar":"integrations"},"integrations/providers/obsidian":{"id":"integrations/providers/obsidian","title":"Obsidian","description":"Obsidian is a powerful and extensible knowledge base","sidebar":"integrations"},"integrations/providers/openai":{"id":"integrations/providers/openai","title":"OpenAI","description":"OpenAI is American artificial intelligence (AI) research laboratory","sidebar":"integrations"},"integrations/providers/openllm":{"id":"integrations/providers/openllm","title":"OpenLLM","description":"This page demonstrates how to use OpenLLM","sidebar":"integrations"},"integrations/providers/opensearch":{"id":"integrations/providers/opensearch","title":"OpenSearch","description":"This page covers how to use the OpenSearch ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/openweathermap":{"id":"integrations/providers/openweathermap","title":"OpenWeatherMap","description":"OpenWeatherMap provides all essential weather data for a specific location:","sidebar":"integrations"},"integrations/providers/petals":{"id":"integrations/providers/petals","title":"Petals","description":"This page covers how to use the Petals ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/pg_embedding":{"id":"integrations/providers/pg_embedding","title":"Postgres Embedding","description":"pgembedding is an open-source package for","sidebar":"integrations"},"integrations/providers/pgvector":{"id":"integrations/providers/pgvector","title":"PGVector","description":"This page covers how to use the Postgres PGVector ecosystem within LangChain","sidebar":"integrations"},"integrations/providers/pinecone":{"id":"integrations/providers/pinecone","title":"Pinecone","description":"This page covers how to use the Pinecone ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/pipelineai":{"id":"integrations/providers/pipelineai","title":"PipelineAI","description":"This page covers how to use the PipelineAI ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/portkey/index":{"id":"integrations/providers/portkey/index","title":"Portkey","description":"LLMOps for Langchain","sidebar":"integrations"},"integrations/providers/portkey/logging_tracing_portkey":{"id":"integrations/providers/portkey/logging_tracing_portkey","title":"logging_tracing_portkey","description":"When building apps or agents using Langchain, you end up making multiple API calls to fulfill a single user request. However, these requests are not chained when you want to analyse them. With Portkey, all the embeddings, completion, and other requests from a single user request will get logged and traced to a common ID, enabling you to gain full visibility of user interactions.","sidebar":"integrations"},"integrations/providers/predibase":{"id":"integrations/providers/predibase","title":"Predibase","description":"Learn how to use LangChain with models on Predibase.","sidebar":"integrations"},"integrations/providers/predictionguard":{"id":"integrations/providers/predictionguard","title":"Prediction Guard","description":"This page covers how to use the Prediction Guard ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/promptlayer":{"id":"integrations/providers/promptlayer","title":"PromptLayer","description":"This page covers how to use PromptLayer within LangChain.","sidebar":"integrations"},"integrations/providers/psychic":{"id":"integrations/providers/psychic","title":"Psychic","description":"Psychic is a platform for integrating with SaaS tools like Notion, Zendesk,","sidebar":"integrations"},"integrations/providers/pubmed":{"id":"integrations/providers/pubmed","title":"PubMed","description":"PubMed\xae by The National Center for Biotechnology Information, National Library of Medicine","sidebar":"integrations"},"integrations/providers/qdrant":{"id":"integrations/providers/qdrant","title":"Qdrant","description":"This page covers how to use the Qdrant ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/ray_serve":{"id":"integrations/providers/ray_serve","title":"Ray Serve","description":"Ray Serve is a scalable model serving library for building online inference APIs. Serve is particularly well suited for system composition, enabling you to build a complex inference service consisting of multiple chains and business logic all in Python code.","sidebar":"integrations"},"integrations/providers/rebuff":{"id":"integrations/providers/rebuff","title":"Rebuff","description":"Rebuff is a self-hardening prompt injection detector.","sidebar":"integrations"},"integrations/providers/reddit":{"id":"integrations/providers/reddit","title":"Reddit","description":"Reddit is an American social news aggregation, content rating, and discussion website.","sidebar":"integrations"},"integrations/providers/redis":{"id":"integrations/providers/redis","title":"Redis","description":"This page covers how to use the Redis ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/replicate":{"id":"integrations/providers/replicate","title":"Replicate","description":"This page covers how to run models on Replicate within LangChain.","sidebar":"integrations"},"integrations/providers/roam":{"id":"integrations/providers/roam","title":"Roam","description":"ROAM is a note-taking tool for networked thought, designed to create a personal knowledge base.","sidebar":"integrations"},"integrations/providers/rockset":{"id":"integrations/providers/rockset","title":"Rockset","description":"Rockset is a real-time analytics database service for serving low latency, high concurrency analytical queries at scale. It builds a Converged Index\u2122 on structured and semi-structured data with an efficient store for vector embeddings. Its support for running SQL on schemaless data makes it a perfect choice for running vector search with metadata filters.","sidebar":"integrations"},"integrations/providers/runhouse":{"id":"integrations/providers/runhouse","title":"Runhouse","description":"This page covers how to use the Runhouse ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/rwkv":{"id":"integrations/providers/rwkv","title":"RWKV-4","description":"This page covers how to use the RWKV-4 wrapper within LangChain.","sidebar":"integrations"},"integrations/providers/sagemaker_endpoint":{"id":"integrations/providers/sagemaker_endpoint","title":"SageMaker Endpoint","description":"Amazon SageMaker is a system that can build, train, and deploy machine learning (ML) models with fully managed infrastructure, tools, and workflows.","sidebar":"integrations"},"integrations/providers/sagemaker_tracking":{"id":"integrations/providers/sagemaker_tracking","title":"SageMaker Tracking","description":"This notebook shows how LangChain Callback can be used to log and track prompts and other LLM hyperparameters into SageMaker Experiments. Here, we use different scenarios to showcase the capability:","sidebar":"integrations"},"integrations/providers/scann":{"id":"integrations/providers/scann","title":"ScaNN","description":"Google ScaNN","sidebar":"integrations"},"integrations/providers/searx":{"id":"integrations/providers/searx","title":"SearxNG Search API","description":"This page covers how to use the SearxNG search API within LangChain.","sidebar":"integrations"},"integrations/providers/serpapi":{"id":"integrations/providers/serpapi","title":"SerpAPI","description":"This page covers how to use the SerpAPI search APIs within LangChain.","sidebar":"integrations"},"integrations/providers/shaleprotocol":{"id":"integrations/providers/shaleprotocol","title":"Shale Protocol","description":"Shale Protocol provides production-ready inference APIs for open LLMs. It\'s a Plug & Play API as it\'s hosted on a highly scalable GPU cloud infrastructure.","sidebar":"integrations"},"integrations/providers/singlestoredb":{"id":"integrations/providers/singlestoredb","title":"SingleStoreDB","description":"SingleStoreDB is a high-performance distributed SQL database that supports deployment both in the cloud and on-premises. It provides vector storage, and vector functions including dotproduct and euclideandistance, thereby supporting AI applications that require text similarity matching.","sidebar":"integrations"},"integrations/providers/sklearn":{"id":"integrations/providers/sklearn","title":"scikit-learn","description":"scikit-learn is an open source collection of machine learning algorithms,","sidebar":"integrations"},"integrations/providers/slack":{"id":"integrations/providers/slack","title":"Slack","description":"Slack is an instant messaging program.","sidebar":"integrations"},"integrations/providers/spacy":{"id":"integrations/providers/spacy","title":"spaCy","description":"spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython.","sidebar":"integrations"},"integrations/providers/spreedly":{"id":"integrations/providers/spreedly","title":"Spreedly","description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","sidebar":"integrations"},"integrations/providers/starrocks":{"id":"integrations/providers/starrocks","title":"StarRocks","description":"StarRocks is a High-Performance Analytical Database.","sidebar":"integrations"},"integrations/providers/stochasticai":{"id":"integrations/providers/stochasticai","title":"StochasticAI","description":"This page covers how to use the StochasticAI ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/stripe":{"id":"integrations/providers/stripe","title":"Stripe","description":"Stripe is an Irish-American financial services and software as a service (SaaS) company. It offers payment-processing software and application programming interfaces for e-commerce websites and mobile applications.","sidebar":"integrations"},"integrations/providers/supabase":{"id":"integrations/providers/supabase","title":"Supabase (Postgres)","description":"Supabase is an open source Firebase alternative.","sidebar":"integrations"},"integrations/providers/symblai_nebula":{"id":"integrations/providers/symblai_nebula","title":"Nebula","description":"This page covers how to use Nebula, Symbl.ai\'s LLM, ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/tair":{"id":"integrations/providers/tair","title":"Tair","description":"This page covers how to use the Tair ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/telegram":{"id":"integrations/providers/telegram","title":"Telegram","description":"Telegram Messenger is a globally accessible freemium, cross-platform, encrypted, cloud-based and centralized instant messaging service. The application also provides optional end-to-end encrypted chats and video calling, VoIP, file sharing and several other features.","sidebar":"integrations"},"integrations/providers/tencentvectordb":{"id":"integrations/providers/tencentvectordb","title":"TencentVectorDB","description":"This page covers how to use the TencentVectorDB ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/tensorflow_datasets":{"id":"integrations/providers/tensorflow_datasets","title":"TensorFlow Datasets","description":"TensorFlow Datasets is a collection of datasets ready to use,","sidebar":"integrations"},"integrations/providers/tigris":{"id":"integrations/providers/tigris","title":"Tigris","description":"Tigris is an open source Serverless NoSQL Database and Search Platform designed to simplify building high-performance vector search applications.","sidebar":"integrations"},"integrations/providers/tomarkdown":{"id":"integrations/providers/tomarkdown","title":"2Markdown","description":"2markdown service transforms website content into structured markdown files.","sidebar":"integrations"},"integrations/providers/trello":{"id":"integrations/providers/trello","title":"Trello","description":"Trello is a web-based project management and collaboration tool that allows individuals and teams to organize and track their tasks and projects. It provides a visual interface known as a \\"board\\" where users can create lists and cards to represent their tasks and activities.","sidebar":"integrations"},"integrations/providers/trulens":{"id":"integrations/providers/trulens","title":"TruLens","description":"This page covers how to use TruLens to evaluate and track LLM apps built on langchain.","sidebar":"integrations"},"integrations/providers/twitter":{"id":"integrations/providers/twitter","title":"Twitter","description":"Twitter is an online social media and social networking service.","sidebar":"integrations"},"integrations/providers/typesense":{"id":"integrations/providers/typesense","title":"Typesense","description":"Typesense is an open source, in-memory search engine, that you can either","sidebar":"integrations"},"integrations/providers/unstructured":{"id":"integrations/providers/unstructured","title":"Unstructured","description":"The unstructured package from","sidebar":"integrations"},"integrations/providers/usearch":{"id":"integrations/providers/usearch","title":"USearch","description":"USearch is a Smaller & Faster Single-File Vector Search Engine.","sidebar":"integrations"},"integrations/providers/vectara/index":{"id":"integrations/providers/vectara/index","title":"Vectara","description":"What is Vectara?","sidebar":"integrations"},"integrations/providers/vectara/vectara_chat":{"id":"integrations/providers/vectara/vectara_chat","title":"Chat Over Documents with Vectara","description":"This notebook is based on the chatvectordb notebook, but using Vectara as the vector database.","sidebar":"integrations"},"integrations/providers/vectara/vectara_text_generation":{"id":"integrations/providers/vectara/vectara_text_generation","title":"Vectara Text Generation","description":"This notebook is based on text generation notebook and adapted to Vectara.","sidebar":"integrations"},"integrations/providers/vespa":{"id":"integrations/providers/vespa","title":"Vespa","description":"Vespa is a fully featured search engine and vector database.","sidebar":"integrations"},"integrations/providers/wandb_tracing":{"id":"integrations/providers/wandb_tracing","title":"WandB Tracing","description":"There are two recommended ways to trace your LangChains:","sidebar":"integrations"},"integrations/providers/wandb_tracking":{"id":"integrations/providers/wandb_tracking","title":"Weights & Biases","description":"This notebook goes over how to track your LangChain experiments into one centralized Weights and Biases dashboard. To learn more about prompt engineering and the callback please refer to this Report which explains both alongside the resultant dashboards you can expect to see.","sidebar":"integrations"},"integrations/providers/weather":{"id":"integrations/providers/weather","title":"Weather","description":"OpenWeatherMap is an open source weather service provider.","sidebar":"integrations"},"integrations/providers/weaviate":{"id":"integrations/providers/weaviate","title":"Weaviate","description":"This page covers how to use the Weaviate ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/whatsapp":{"id":"integrations/providers/whatsapp","title":"WhatsApp","description":"WhatsApp (also called WhatsApp Messenger) is a freeware, cross-platform, centralized instant messaging (IM) and voice-over-IP (VoIP) service. It allows users to send text and voice messages, make voice and video calls, and share images, documents, user locations, and other content.","sidebar":"integrations"},"integrations/providers/whylabs_profiling":{"id":"integrations/providers/whylabs_profiling","title":"WhyLabs","description":"WhyLabs is an observability platform designed to monitor data pipelines and ML applications for data quality regressions, data drift, and model performance degradation. Built on top of an open-source package called whylogs, the platform enables Data Scientists and Engineers to:","sidebar":"integrations"},"integrations/providers/wikipedia":{"id":"integrations/providers/wikipedia","title":"Wikipedia","description":"Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.","sidebar":"integrations"},"integrations/providers/wolfram_alpha":{"id":"integrations/providers/wolfram_alpha","title":"Wolfram Alpha","description":"WolframAlpha is an answer engine developed by Wolfram Research.","sidebar":"integrations"},"integrations/providers/writer":{"id":"integrations/providers/writer","title":"Writer","description":"This page covers how to use the Writer ecosystem within LangChain.","sidebar":"integrations"},"integrations/providers/xata":{"id":"integrations/providers/xata","title":"Xata","description":"Xata is a serverless data platform, based on PostgreSQL.","sidebar":"integrations"},"integrations/providers/xinference":{"id":"integrations/providers/xinference","title":"Xorbits Inference (Xinference)","description":"This page demonstrates how to use Xinference","sidebar":"integrations"},"integrations/providers/yeagerai":{"id":"integrations/providers/yeagerai","title":"Yeager.ai","description":"This page covers how to use Yeager.ai to generate LangChain tools and agents.","sidebar":"integrations"},"integrations/providers/youtube":{"id":"integrations/providers/youtube","title":"YouTube","description":"YouTube is an online video sharing and social media platform by Google.","sidebar":"integrations"},"integrations/providers/zep":{"id":"integrations/providers/zep","title":"Zep","description":"Zep - A long-term memory store for LLM applications.","sidebar":"integrations"},"integrations/providers/zilliz":{"id":"integrations/providers/zilliz","title":"Zilliz","description":"Zilliz Cloud is a fully managed service on cloud for LF AI Milvus\xae,","sidebar":"integrations"},"integrations/retrievers/amazon_kendra_retriever":{"id":"integrations/retrievers/amazon_kendra_retriever","title":"Amazon Kendra","description":"Amazon Kendra is an intelligent search service provided by Amazon Web Services (AWS). It utilizes advanced natural language processing (NLP) and machine learning algorithms to enable powerful search capabilities across various data sources within an organization. Kendra is designed to help users find the information they need quickly and accurately, improving productivity and decision-making.","sidebar":"integrations"},"integrations/retrievers/arxiv":{"id":"integrations/retrievers/arxiv","title":"Arxiv","description":"arXiv is an open-access archive for 2 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics.","sidebar":"integrations"},"integrations/retrievers/azure_cognitive_search":{"id":"integrations/retrievers/azure_cognitive_search","title":"Azure Cognitive Search","description":"Azure Cognitive Search (formerly known as Azure Search) is a cloud search service that gives developers infrastructure, APIs, and tools for building a rich search experience over private, heterogeneous content in web, mobile, and enterprise applications.","sidebar":"integrations"},"integrations/retrievers/bm25":{"id":"integrations/retrievers/bm25","title":"BM25","description":"BM25 also known as the Okapi BM25, is a ranking function used in information retrieval systems to estimate the relevance of documents to a given search query.","sidebar":"integrations"},"integrations/retrievers/chaindesk":{"id":"integrations/retrievers/chaindesk","title":"Chaindesk","description":"Chaindesk platform brings data from anywhere (Datsources: Text, PDF, Word, PowerPpoint, Excel, Notion, Airtable, Google Sheets, etc..) into Datastores (container of multiple Datasources).","sidebar":"integrations"},"integrations/retrievers/chatgpt-plugin":{"id":"integrations/retrievers/chatgpt-plugin","title":"ChatGPT Plugin","description":"OpenAI plugins connect ChatGPT to third-party applications. These plugins enable ChatGPT to interact with APIs defined by developers, enhancing ChatGPT\'s capabilities and allowing it to perform a wide range of actions.","sidebar":"integrations"},"integrations/retrievers/cohere-reranker":{"id":"integrations/retrievers/cohere-reranker","title":"Cohere Reranker","description":"Cohere is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions.","sidebar":"integrations"},"integrations/retrievers/docarray_retriever":{"id":"integrations/retrievers/docarray_retriever","title":"DocArray Retriever","description":"DocArray is a versatile, open-source tool for managing your multi-modal data. It lets you shape your data however you want, and offers the flexibility to store and search it using various document index backends. Plus, it gets even better - you can utilize your DocArray document index to create a DocArrayRetriever, and build awesome Langchain apps!","sidebar":"integrations"},"integrations/retrievers/elastic_search_bm25":{"id":"integrations/retrievers/elastic_search_bm25","title":"ElasticSearch BM25","description":"Elasticsearch is a distributed, RESTful search and analytics engine. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents.","sidebar":"integrations"},"integrations/retrievers/google_cloud_enterprise_search":{"id":"integrations/retrievers/google_cloud_enterprise_search","title":"Google Cloud Enterprise Search","description":"Enterprise Search is a part of the Generative AI App Builder suite of tools offered by Google Cloud.","sidebar":"integrations"},"integrations/retrievers/google_drive":{"id":"integrations/retrievers/google_drive","title":"Google Drive Retriever","description":"This notebook covers how to retrieve documents from Google Drive.","sidebar":"integrations"},"integrations/retrievers/index":{"id":"integrations/retrievers/index","title":"Retrievers","description":"","sidebar":"integrations"},"integrations/retrievers/knn":{"id":"integrations/retrievers/knn","title":"kNN","description":"In statistics, the k-nearest neighbors algorithm (k-NN) is a non-parametric supervised learning method first developed by Evelyn Fix and Joseph Hodges in 1951, and later expanded by Thomas Cover. It is used for classification and regression.","sidebar":"integrations"},"integrations/retrievers/merger_retriever":{"id":"integrations/retrievers/merger_retriever","title":"LOTR (Merger Retriever)","description":"Lord of the Retrievers, also known as MergerRetriever, takes a list of retrievers as input and merges the results of their getrelevantdocuments() methods into a single list. The merged results will be a list of documents that are relevant to the query and that have been ranked by the different retrievers.","sidebar":"integrations"},"integrations/retrievers/metal":{"id":"integrations/retrievers/metal","title":"Metal","description":"Metal is a managed service for ML Embeddings.","sidebar":"integrations"},"integrations/retrievers/pinecone_hybrid_search":{"id":"integrations/retrievers/pinecone_hybrid_search","title":"Pinecone Hybrid Search","description":"Pinecone is a vector database with broad functionality.","sidebar":"integrations"},"integrations/retrievers/pubmed":{"id":"integrations/retrievers/pubmed","title":"PubMed","description":"PubMed\xae by The National Center for Biotechnology Information, National Library of Medicine comprises more than 35 million citations for biomedical literature from MEDLINE, life science journals, and online books. Citations may include links to full text content from PubMed Central and publisher web sites.","sidebar":"integrations"},"integrations/retrievers/re_phrase":{"id":"integrations/retrievers/re_phrase","title":"RePhraseQueryRetriever","description":"Simple retriever that applies an LLM between the user input and the query pass the to retriever.","sidebar":"integrations"},"integrations/retrievers/svm":{"id":"integrations/retrievers/svm","title":"SVM","description":"Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.","sidebar":"integrations"},"integrations/retrievers/tf_idf":{"id":"integrations/retrievers/tf_idf","title":"TF-IDF","description":"TF-IDF means term-frequency times inverse document-frequency.","sidebar":"integrations"},"integrations/retrievers/vespa":{"id":"integrations/retrievers/vespa","title":"Vespa","description":"Vespa is a fully featured search engine and vector database. It supports vector search (ANN), lexical search, and search in structured data, all in the same query.","sidebar":"integrations"},"integrations/retrievers/weaviate-hybrid":{"id":"integrations/retrievers/weaviate-hybrid","title":"Weaviate Hybrid Search","description":"Weaviate is an open source vector database.","sidebar":"integrations"},"integrations/retrievers/wikipedia":{"id":"integrations/retrievers/wikipedia","title":"Wikipedia","description":"Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.","sidebar":"integrations"},"integrations/retrievers/zep_memorystore":{"id":"integrations/retrievers/zep_memorystore","title":"Zep","description":"Retriever Example for Zep - A long-term memory store for LLM applications.","sidebar":"integrations"},"integrations/text_embedding/aleph_alpha":{"id":"integrations/text_embedding/aleph_alpha","title":"Aleph Alpha","description":"There are two possible ways to use Aleph Alpha\'s semantic embeddings. If you have texts with a dissimilar structure (e.g. a Document and a Query) you would want to use asymmetric embeddings. Conversely, for texts with comparable structures, symmetric embeddings are the suggested approach.","sidebar":"integrations"},"integrations/text_embedding/Awa":{"id":"integrations/text_embedding/Awa","title":"AwaEmbedding","description":"This notebook explains how to use AwaEmbedding, which is included in awadb, to embedding texts in langchain.","sidebar":"integrations"},"integrations/text_embedding/azureopenai":{"id":"integrations/text_embedding/azureopenai","title":"AzureOpenAI","description":"Let\'s load the OpenAI Embedding class with environment variables set to indicate to use Azure endpoints.","sidebar":"integrations"},"integrations/text_embedding/bedrock":{"id":"integrations/text_embedding/bedrock","title":"Bedrock Embeddings","description":"","sidebar":"integrations"},"integrations/text_embedding/bge_huggingface":{"id":"integrations/text_embedding/bge_huggingface","title":"BGE Hugging Face Embeddings","description":"This notebook shows how to use BGE Embeddings through Hugging Face","sidebar":"integrations"},"integrations/text_embedding/clarifai":{"id":"integrations/text_embedding/clarifai","title":"Clarifai","description":"Clarifai is an AI Platform that provides the full AI lifecycle ranging from data exploration, data labeling, model training, evaluation, and inference.","sidebar":"integrations"},"integrations/text_embedding/cohere":{"id":"integrations/text_embedding/cohere","title":"Cohere","description":"Let\'s load the Cohere Embedding class.","sidebar":"integrations"},"integrations/text_embedding/dashscope":{"id":"integrations/text_embedding/dashscope","title":"DashScope","description":"Let\'s load the DashScope Embedding class.","sidebar":"integrations"},"integrations/text_embedding/deepinfra":{"id":"integrations/text_embedding/deepinfra","title":"DeepInfra","description":"DeepInfra is a serverless inference as a service that provides access to a variety of LLMs and embeddings models. This notebook goes over how to use LangChain with DeepInfra for text embeddings.","sidebar":"integrations"},"integrations/text_embedding/edenai":{"id":"integrations/text_embedding/edenai","title":"EDEN AI","description":"Eden AI is revolutionizing the AI landscape by uniting the best AI providers, empowering users to unlock limitless possibilities and tap into the true potential of artificial intelligence. With an all-in-one comprehensive and hassle-free platform, it allows users to deploy AI features to production lightning fast, enabling effortless access to the full breadth of AI capabilities via a single API. (website//edenai.co/)","sidebar":"integrations"},"integrations/text_embedding/elasticsearch":{"id":"integrations/text_embedding/elasticsearch","title":"Elasticsearch","description":"Walkthrough of how to generate embeddings using a hosted embedding model in Elasticsearch","sidebar":"integrations"},"integrations/text_embedding/embaas":{"id":"integrations/text_embedding/embaas","title":"Embaas","description":"embaas is a fully managed NLP API service that offers features like embedding generation, document text extraction, document to embeddings and more. You can choose a variety of pre-trained models.","sidebar":"integrations"},"integrations/text_embedding/ernie":{"id":"integrations/text_embedding/ernie","title":"ERNIE Embedding-V1","description":"ERNIE Embedding-V1 is a text representation model based on Baidu Wenxin\'s large-scale model technology,","sidebar":"integrations"},"integrations/text_embedding/fake":{"id":"integrations/text_embedding/fake","title":"Fake Embeddings","description":"LangChain also provides a fake embedding class. You can use this to test your pipelines.","sidebar":"integrations"},"integrations/text_embedding/google_vertex_ai_palm":{"id":"integrations/text_embedding/google_vertex_ai_palm","title":"Google Cloud Platform Vertex AI PaLM","description":"Note: This is seperate from the Google PaLM integration, it exposes Vertex AI PaLM API on Google Cloud.","sidebar":"integrations"},"integrations/text_embedding/gpt4all":{"id":"integrations/text_embedding/gpt4all","title":"GPT4All","description":"GPT4All is a free-to-use, locally running, privacy-aware chatbot. There is no GPU or internet required. It features popular models and its own models such as GPT4All Falcon, Wizard, etc.","sidebar":"integrations"},"integrations/text_embedding/huggingfacehub":{"id":"integrations/text_embedding/huggingfacehub","title":"Hugging Face","description":"Let\'s load the Hugging Face Embedding class.","sidebar":"integrations"},"integrations/text_embedding/index":{"id":"integrations/text_embedding/index","title":"Text embedding models","description":"","sidebar":"integrations"},"integrations/text_embedding/instruct_embeddings":{"id":"integrations/text_embedding/instruct_embeddings","title":"InstructEmbeddings","description":"Let\'s load the HuggingFace instruct Embeddings class.","sidebar":"integrations"},"integrations/text_embedding/jina":{"id":"integrations/text_embedding/jina","title":"Jina","description":"Let\'s load the Jina Embedding class.","sidebar":"integrations"},"integrations/text_embedding/llamacpp":{"id":"integrations/text_embedding/llamacpp","title":"Llama-cpp","description":"This notebook goes over how to use Llama-cpp embeddings within LangChain","sidebar":"integrations"},"integrations/text_embedding/localai":{"id":"integrations/text_embedding/localai","title":"LocalAI","description":"Let\'s load the LocalAI Embedding class. In order to use the LocalAI Embedding class, you need to have the LocalAI service hosted somewhere and configure the embedding models. See the documentation at https//localai.io/features/embeddings/index.html.","sidebar":"integrations"},"integrations/text_embedding/minimax":{"id":"integrations/text_embedding/minimax","title":"MiniMax","description":"MiniMax offers an embeddings service.","sidebar":"integrations"},"integrations/text_embedding/modelscope_hub":{"id":"integrations/text_embedding/modelscope_hub","title":"ModelScope","description":"Let\'s load the ModelScope Embedding class.","sidebar":"integrations"},"integrations/text_embedding/mosaicml":{"id":"integrations/text_embedding/mosaicml","title":"MosaicML embeddings","description":"MosaicML offers a managed inference service. You can either use a variety of open source models, or deploy your own.","sidebar":"integrations"},"integrations/text_embedding/nlp_cloud":{"id":"integrations/text_embedding/nlp_cloud","title":"NLP Cloud","description":"NLP Cloud is an artificial intelligence platform that allows you to use the most advanced AI engines, and even train your own engines with your own data.","sidebar":"integrations"},"integrations/text_embedding/openai":{"id":"integrations/text_embedding/openai","title":"OpenAI","description":"Let\'s load the OpenAI Embedding class.","sidebar":"integrations"},"integrations/text_embedding/sagemaker-endpoint":{"id":"integrations/text_embedding/sagemaker-endpoint","title":"SageMaker Endpoint Embeddings","description":"Let\'s load the SageMaker Endpoints Embeddings class. The class can be used if you host, e.g. your own Hugging Face model on SageMaker.","sidebar":"integrations"},"integrations/text_embedding/self-hosted":{"id":"integrations/text_embedding/self-hosted","title":"Self Hosted Embeddings","description":"Let\'s load the SelfHostedEmbeddings, SelfHostedHuggingFaceEmbeddings, and SelfHostedHuggingFaceInstructEmbeddings classes.","sidebar":"integrations"},"integrations/text_embedding/sentence_transformers":{"id":"integrations/text_embedding/sentence_transformers","title":"Sentence Transformers Embeddings","description":"SentenceTransformers embeddings are called using the HuggingFaceEmbeddings integration. We have also added an alias for SentenceTransformerEmbeddings for users who are more familiar with directly using that package.","sidebar":"integrations"},"integrations/text_embedding/spacy_embedding":{"id":"integrations/text_embedding/spacy_embedding","title":"Spacy Embedding","description":"Loading the Spacy embedding class to generate and query embeddings","sidebar":"integrations"},"integrations/text_embedding/tensorflowhub":{"id":"integrations/text_embedding/tensorflowhub","title":"TensorflowHub","description":"Let\'s load the TensorflowHub Embedding class.","sidebar":"integrations"},"integrations/text_embedding/xinference":{"id":"integrations/text_embedding/xinference","title":"Xorbits inference (Xinference)","description":"This notebook goes over how to use Xinference embeddings within LangChain","sidebar":"integrations"},"integrations/toolkits/ainetwork":{"id":"integrations/toolkits/ainetwork","title":"AINetwork","description":"AI Network is a layer 1 blockchain designed to accommodate large-scale AI models, utilizing a decentralized GPU network powered by the $AIN token, enriching AI-driven NFTs (AINFTs).","sidebar":"integrations"},"integrations/toolkits/airbyte_structured_qa":{"id":"integrations/toolkits/airbyte_structured_qa","title":"Airbyte Question Answering","description":"This notebook shows how to do question answering over structured data, in this case using the AirbyteStripeLoader.","sidebar":"integrations"},"integrations/toolkits/amadeus":{"id":"integrations/toolkits/amadeus","title":"Amadeus","description":"This notebook walks you through connecting LangChain to the Amadeus travel information API","sidebar":"integrations"},"integrations/toolkits/azure_cognitive_services":{"id":"integrations/toolkits/azure_cognitive_services","title":"Azure Cognitive Services","description":"This toolkit is used to interact with the Azure Cognitive Services API to achieve some multimodal capabilities.","sidebar":"integrations"},"integrations/toolkits/csv":{"id":"integrations/toolkits/csv","title":"CSV","description":"This notebook shows how to use agents to interact with data in CSV format. It is mostly optimized for question answering.","sidebar":"integrations"},"integrations/toolkits/document_comparison_toolkit":{"id":"integrations/toolkits/document_comparison_toolkit","title":"Document Comparison","description":"This notebook shows how to use an agent to compare two documents.","sidebar":"integrations"},"integrations/toolkits/github":{"id":"integrations/toolkits/github","title":"Github","description":"The Github toolkit contains tools that enable an LLM agent to interact with a github repository.","sidebar":"integrations"},"integrations/toolkits/gmail":{"id":"integrations/toolkits/gmail","title":"Gmail","description":"This notebook walks through connecting a LangChain email to the Gmail API.","sidebar":"integrations"},"integrations/toolkits/google_drive":{"id":"integrations/toolkits/google_drive","title":"Google Drive tool","description":"This notebook walks through connecting a LangChain to the Google Drive API.","sidebar":"integrations"},"integrations/toolkits/index":{"id":"integrations/toolkits/index","title":"Agents & Toolkits","description":"Agents and Toolkits are placed in the same directory because they are always used together.","sidebar":"integrations"},"integrations/toolkits/jira":{"id":"integrations/toolkits/jira","title":"Jira","description":"This notebook goes over how to use the Jira toolkit.","sidebar":"integrations"},"integrations/toolkits/json":{"id":"integrations/toolkits/json","title":"JSON","description":"This notebook showcases an agent interacting with large JSON/dict objects.","sidebar":"integrations"},"integrations/toolkits/multion":{"id":"integrations/toolkits/multion","title":"MultiOn","description":"This notebook walks you through connecting LangChain to the MultiOn Client in your browser","sidebar":"integrations"},"integrations/toolkits/office365":{"id":"integrations/toolkits/office365","title":"Office365","description":"This notebook walks through connecting LangChain to Office365 email and calendar.","sidebar":"integrations"},"integrations/toolkits/openapi":{"id":"integrations/toolkits/openapi","title":"OpenAPI","description":"We can construct agents to consume arbitrary APIs, here APIs conformant to the OpenAPI/Swagger specification.","sidebar":"integrations"},"integrations/toolkits/openapi_nla":{"id":"integrations/toolkits/openapi_nla","title":"Natural Language APIs","description":"Natural Language API Toolkits (NLAToolkits) permit LangChain Agents to efficiently plan and combine calls across endpoints.","sidebar":"integrations"},"integrations/toolkits/pandas":{"id":"integrations/toolkits/pandas","title":"Pandas Dataframe","description":"This notebook shows how to use agents to interact with a Pandas DataFrame. It is mostly optimized for question answering.","sidebar":"integrations"},"integrations/toolkits/playwright":{"id":"integrations/toolkits/playwright","title":"PlayWright Browser","description":"This toolkit is used to interact with the browser. While other tools (like the Requests tools) are fine for static sites, PlayWright Browser toolkits let your agent navigate the web and interact with dynamically rendered sites.","sidebar":"integrations"},"integrations/toolkits/powerbi":{"id":"integrations/toolkits/powerbi","title":"PowerBI Dataset","description":"This notebook showcases an agent interacting with a Power BI Dataset. The agent is answering more general questions about a dataset, as well as recover from errors.","sidebar":"integrations"},"integrations/toolkits/python":{"id":"integrations/toolkits/python","title":"Python","description":"This notebook showcases an agent designed to write and execute Python code to answer a question.","sidebar":"integrations"},"integrations/toolkits/spark":{"id":"integrations/toolkits/spark","title":"Spark Dataframe","description":"This notebook shows how to use agents to interact with a Spark DataFrame and Spark Connect. It is mostly optimized for question answering.","sidebar":"integrations"},"integrations/toolkits/spark_sql":{"id":"integrations/toolkits/spark_sql","title":"Spark SQL","description":"This notebook shows how to use agents to interact with Spark SQL. Similar to SQL Database Agent, it is designed to address general inquiries about Spark SQL and facilitate error recovery.","sidebar":"integrations"},"integrations/toolkits/sql_database":{"id":"integrations/toolkits/sql_database","title":"SQL Database","description":"This notebook showcases an agent designed to interact with a SQL databases.","sidebar":"integrations"},"integrations/toolkits/vectorstore":{"id":"integrations/toolkits/vectorstore","title":"Vectorstore","description":"This notebook showcases an agent designed to retrieve information from one or more vectorstores, either with or without sources.","sidebar":"integrations"},"integrations/toolkits/xorbits":{"id":"integrations/toolkits/xorbits","title":"Xorbits","description":"This notebook shows how to use agents to interact with Xorbits Pandas dataframe and Xorbits Numpy ndarray. It is mostly optimized for question answering.","sidebar":"integrations"},"integrations/tools/alpha_vantage":{"id":"integrations/tools/alpha_vantage","title":"Alpha Vantage","description":"Alpha Vantage Alpha Vantage provides realtime and historical financial market data through a set of powerful and developer-friendly data APIs and spreadsheets.","sidebar":"integrations"},"integrations/tools/apify":{"id":"integrations/tools/apify","title":"Apify","description":"This notebook shows how to use the Apify integration for LangChain.","sidebar":"integrations"},"integrations/tools/arxiv":{"id":"integrations/tools/arxiv","title":"ArXiv","description":"This notebook goes over how to use the arxiv tool with an agent.","sidebar":"integrations"},"integrations/tools/awslambda":{"id":"integrations/tools/awslambda","title":"AWS Lambda","description":"Amazon AWS Lambda is a serverless computing service provided by Amazon Web Services (AWS). It helps developers to build and run applications and services without provisioning or managing servers. This serverless architecture enables you to focus on writing and deploying code, while AWS automatically takes care of scaling, patching, and managing the infrastructure required to run your applications.","sidebar":"integrations"},"integrations/tools/bash":{"id":"integrations/tools/bash","title":"Shell (bash)","description":"Giving agents access to the shell is powerful (though risky outside a sandboxed environment).","sidebar":"integrations"},"integrations/tools/bing_search":{"id":"integrations/tools/bing_search","title":"Bing Search","description":"This notebook goes over how to use the bing search component.","sidebar":"integrations"},"integrations/tools/brave_search":{"id":"integrations/tools/brave_search","title":"Brave Search","description":"This notebook goes over how to use the Brave Search tool.","sidebar":"integrations"},"integrations/tools/chatgpt_plugins":{"id":"integrations/tools/chatgpt_plugins","title":"ChatGPT Plugins","description":"This example shows how to use ChatGPT Plugins within LangChain abstractions.","sidebar":"integrations"},"integrations/tools/dalle_image_generator":{"id":"integrations/tools/dalle_image_generator","title":"Dall-E Image Generator","description":"This notebook shows how you can generate images from a prompt synthesized using an OpenAI LLM. The images are generated using Dall-E, which uses the same OpenAI API key as the LLM.","sidebar":"integrations"},"integrations/tools/dataforseo":{"id":"integrations/tools/dataforseo","title":"DataForSeo","description":"This notebook demonstrates how to use the DataForSeo API to obtain search engine results. The DataForSeo API retrieves SERP from most popular search engines like Google, Bing, Yahoo. It also allows to get SERPs from different search engine types like Maps, News, Events, etc.","sidebar":"integrations"},"integrations/tools/ddg":{"id":"integrations/tools/ddg","title":"DuckDuckGo Search","description":"This notebook goes over how to use the duck-duck-go search component.","sidebar":"integrations"},"integrations/tools/edenai_tools":{"id":"integrations/tools/edenai_tools","title":"Eden AI","description":"This Jupyter Notebook demonstrates how to use Eden AI tools with an Agent.","sidebar":"integrations"},"integrations/tools/filesystem":{"id":"integrations/tools/filesystem","title":"File System","description":"LangChain provides tools for interacting with a local file system out of the box. This notebook walks through some of them.","sidebar":"integrations"},"integrations/tools/golden_query":{"id":"integrations/tools/golden_query","title":"Golden Query","description":"Golden provides a set of natural language APIs for querying and enrichment using the Golden Knowledge Graph e.g. queries such as: Products from OpenAI, Generative ai companies with series a funding, and rappers who invest can be used to retrieve structured data about relevant entities.","sidebar":"integrations"},"integrations/tools/google_drive":{"id":"integrations/tools/google_drive","title":"Google Drive","description":"This notebook walks through connecting a LangChain to the Google Drive API.","sidebar":"integrations"},"integrations/tools/google_places":{"id":"integrations/tools/google_places","title":"Google Places","description":"This notebook goes through how to use Google Places API","sidebar":"integrations"},"integrations/tools/google_search":{"id":"integrations/tools/google_search","title":"Google Search","description":"This notebook goes over how to use the google search component.","sidebar":"integrations"},"integrations/tools/google_serper":{"id":"integrations/tools/google_serper","title":"Google Serper","description":"This notebook goes over how to use the Google Serper component to search the web. First you need to sign up for a free account at serper.dev and get your api key.","sidebar":"integrations"},"integrations/tools/gradio_tools":{"id":"integrations/tools/gradio_tools","title":"Gradio","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM\'s fingers \ud83e\uddbe","sidebar":"integrations"},"integrations/tools/graphql":{"id":"integrations/tools/graphql","title":"GraphQL","description":"GraphQL is a query language for APIs and a runtime for executing those queries against your data. GraphQL provides a complete and understandable description of the data in your API, gives clients the power to ask for exactly what they need and nothing more, makes it easier to evolve APIs over time, and enables powerful developer tools.","sidebar":"integrations"},"integrations/tools/huggingface_tools":{"id":"integrations/tools/huggingface_tools","title":"HuggingFace Hub Tools","description":"Huggingface Tools that supporting text I/O can be","sidebar":"integrations"},"integrations/tools/human_tools":{"id":"integrations/tools/human_tools","title":"Human as a tool","description":"Human are AGI so they can certainly be used as a tool to help out AI agent","sidebar":"integrations"},"integrations/tools/ifttt":{"id":"integrations/tools/ifttt","title":"IFTTT WebHooks","description":"This notebook shows how to use IFTTT Webhooks.","sidebar":"integrations"},"integrations/tools/index":{"id":"integrations/tools/index","title":"Tools","description":"","sidebar":"integrations"},"integrations/tools/lemonai":{"id":"integrations/tools/lemonai","title":"Lemon Agent","description":"Lemon Agent helps you build powerful AI assistants in minutes and automate workflows by allowing for accurate and reliable read and write operations in tools like Airtable, Hubspot, Discord, Notion, Slack and Github.","sidebar":"integrations"},"integrations/tools/metaphor_search":{"id":"integrations/tools/metaphor_search","title":"Metaphor Search","description":"Metaphor is a search engine fully designed to be used by LLMs. You can search and then get the contents for any page.","sidebar":"integrations"},"integrations/tools/nuclia":{"id":"integrations/tools/nuclia","title":"Nuclia Understanding","description":"Nuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.","sidebar":"integrations"},"integrations/tools/openweathermap":{"id":"integrations/tools/openweathermap","title":"OpenWeatherMap","description":"This notebook goes over how to use the OpenWeatherMap component to fetch weather information.","sidebar":"integrations"},"integrations/tools/pubmed":{"id":"integrations/tools/pubmed","title":"PubMed","description":"PubMed\xae comprises more than 35 million citations for biomedical literature from MEDLINE, life science journals, and online books. Citations may include links to full text content from PubMed Central and publisher web sites.","sidebar":"integrations"},"integrations/tools/requests":{"id":"integrations/tools/requests","title":"Requests","description":"The web contains a lot of information that LLMs do not have access to. In order to easily let LLMs interact with that information, we provide a wrapper around the Python Requests module that takes in a URL and fetches data from that URL.","sidebar":"integrations"},"integrations/tools/sceneXplain":{"id":"integrations/tools/sceneXplain","title":"SceneXplain","description":"SceneXplain is an ImageCaptioning service accessible through the SceneXplain Tool.","sidebar":"integrations"},"integrations/tools/search_tools":{"id":"integrations/tools/search_tools","title":"Search Tools","description":"This notebook shows off usage of various search tools.","sidebar":"integrations"},"integrations/tools/searx_search":{"id":"integrations/tools/searx_search","title":"SearxNG Search","description":"This notebook goes over how to use a self hosted SearxNG search API to search the web.","sidebar":"integrations"},"integrations/tools/serpapi":{"id":"integrations/tools/serpapi","title":"SerpAPI","description":"This notebook goes over how to use the SerpAPI component to search the web.","sidebar":"integrations"},"integrations/tools/sqlite":{"id":"integrations/tools/sqlite","title":"SQL Database Chain","description":"This example demonstrates the use of the SQLDatabaseChain for answering questions over a SQL database.","sidebar":"integrations"},"integrations/tools/twilio":{"id":"integrations/tools/twilio","title":"Twilio","description":"This notebook goes over how to use the Twilio API wrapper to send a message through SMS or Twilio Messaging Channels.","sidebar":"integrations"},"integrations/tools/wikipedia":{"id":"integrations/tools/wikipedia","title":"Wikipedia","description":"Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. Wikipedia is the largest and most-read reference work in history.","sidebar":"integrations"},"integrations/tools/wolfram_alpha":{"id":"integrations/tools/wolfram_alpha","title":"Wolfram Alpha","description":"This notebook goes over how to use the wolfram alpha component.","sidebar":"integrations"},"integrations/tools/yahoo_finance_news":{"id":"integrations/tools/yahoo_finance_news","title":"Yahoo Finance News","description":"This notebook goes over how to use the yahoofinancenews tool with an agent.","sidebar":"integrations"},"integrations/tools/youtube":{"id":"integrations/tools/youtube","title":"YouTube","description":"YouTube Search package searches YouTube videos avoiding using their heavily rate-limited API.","sidebar":"integrations"},"integrations/tools/zapier":{"id":"integrations/tools/zapier","title":"Zapier Natural Language Actions","description":"Zapier Natural Language Actions gives you access to the 5k+ apps, 20k+ actions on Zapier\'s platform through a natural language API interface.","sidebar":"integrations"},"integrations/vectorstores/activeloop_deeplake":{"id":"integrations/vectorstores/activeloop_deeplake","title":"Activeloop Deep Lake","description":"Activeloop Deep Lake as a Multi-Modal Vector Store that stores embeddings and their metadata including text, Jsons, images, audio, video, and more. It saves the data locally, in your cloud, or on Activeloop storage. It performs hybrid search including embeddings and their attributes.","sidebar":"integrations"},"integrations/vectorstores/alibabacloud_opensearch":{"id":"integrations/vectorstores/alibabacloud_opensearch","title":"Alibaba Cloud OpenSearch","description":"Alibaba Cloud Opensearch is a one-stop platform to develop intelligent search services. OpenSearch was built on the large-scale distributed search engine developed by Alibaba. OpenSearch serves more than 500 business cases in Alibaba Group and thousands of Alibaba Cloud customers. OpenSearch helps develop search services in different search scenarios, including e-commerce, O2O, multimedia, the content industry, communities and forums, and big data query in enterprises.","sidebar":"integrations"},"integrations/vectorstores/analyticdb":{"id":"integrations/vectorstores/analyticdb","title":"AnalyticDB","description":"AnalyticDB for PostgreSQL is a massively parallel processing (MPP) data warehousing service that is designed to analyze large volumes of data online.","sidebar":"integrations"},"integrations/vectorstores/annoy":{"id":"integrations/vectorstores/annoy","title":"Annoy","description":"Annoy (Approximate Nearest Neighbors Oh Yeah) is a C++ library with Python bindings to search for points in space that are close to a given query point. It also creates large read-only file-based data structures that are mmapped into memory so that many processes may share the same data.","sidebar":"integrations"},"integrations/vectorstores/atlas":{"id":"integrations/vectorstores/atlas","title":"Atlas","description":"Atlas is a platform by Nomic made for interacting with both small and internet scale unstructured datasets. It enables anyone to visualize, search, and share massive datasets in their browser.","sidebar":"integrations"},"integrations/vectorstores/awadb":{"id":"integrations/vectorstores/awadb","title":"AwaDB","description":"AwaDB is an AI Native database for the search and storage of embedding vectors used by LLM Applications.","sidebar":"integrations"},"integrations/vectorstores/azuresearch":{"id":"integrations/vectorstores/azuresearch","title":"Azure Cognitive Search","description":"Azure Cognitive Search (formerly known as Azure Search) is a cloud search service that gives developers infrastructure, APIs, and tools for building a rich search experience over private, heterogeneous content in web, mobile, and enterprise applications.","sidebar":"integrations"},"integrations/vectorstores/bageldb":{"id":"integrations/vectorstores/bageldb","title":"BagelDB","description":"BagelDB (Open Vector Database for AI), is like GitHub for AI data.","sidebar":"integrations"},"integrations/vectorstores/cassandra":{"id":"integrations/vectorstores/cassandra","title":"Cassandra","description":"Apache Cassandra\xae is a NoSQL, row-oriented, highly scalable and highly available database.","sidebar":"integrations"},"integrations/vectorstores/chroma":{"id":"integrations/vectorstores/chroma","title":"Chroma","description":"Chroma is a AI-native open-source vector database focused on developer productivity and happiness. Chroma is licensed under Apache 2.0.","sidebar":"integrations"},"integrations/vectorstores/clickhouse":{"id":"integrations/vectorstores/clickhouse","title":"ClickHouse","description":"ClickHouse is the fastest and most resource efficient open-source database for real-time apps and analytics with full SQL support and a wide range of functions to assist users in writing analytical queries. Lately added data structures and distance search functions (like L2Distance) as well as approximate nearest neighbor search indexes enable ClickHouse to be used as a high performance and scalable vector database to store and search vectors with SQL.","sidebar":"integrations"},"integrations/vectorstores/dashvector":{"id":"integrations/vectorstores/dashvector","title":"DashVector","description":"DashVector is a fully-managed vectorDB service that supports high-dimension dense and sparse vectors, real-time insertion and filtered search. It is built to scale automatically and can adapt to different application requirements.","sidebar":"integrations"},"integrations/vectorstores/dingo":{"id":"integrations/vectorstores/dingo","title":"Dingo","description":"Dingo is a distributed multi-mode vector database, which combines the characteristics of data lakes and vector databases, and can store data of any type and size (Key-Value, PDF, audio, video, etc.). It has real-time low-latency processing capabilities to achieve rapid insight and response, and can efficiently conduct instant analysis and process multi-modal data.","sidebar":"integrations"},"integrations/vectorstores/docarray_hnsw":{"id":"integrations/vectorstores/docarray_hnsw","title":"DocArray HnswSearch","description":"DocArrayHnswSearch is a lightweight Document Index implementation provided by Docarray that runs fully locally and is best suited for small- to medium-sized datasets. It stores vectors on disk in hnswlib, and stores all other data in SQLite.","sidebar":"integrations"},"integrations/vectorstores/docarray_in_memory":{"id":"integrations/vectorstores/docarray_in_memory","title":"DocArray InMemorySearch","description":"DocArrayInMemorySearch is a document index provided by Docarray that stores documents in memory. It is a great starting point for small datasets, where you may not want to launch a database server.","sidebar":"integrations"},"integrations/vectorstores/elasticsearch":{"id":"integrations/vectorstores/elasticsearch","title":"Elasticsearch","description":"Elasticsearch is a distributed, RESTful search and analytics engine, capable of performing both vector and lexical search. It is built on top of the Apache Lucene library.","sidebar":"integrations"},"integrations/vectorstores/epsilla":{"id":"integrations/vectorstores/epsilla","title":"Epsilla","description":"Epsilla is an open-source vector database that leverages the advanced parallel graph traversal techniques for vector indexing. Epsilla is licensed under GPL-3.0.","sidebar":"integrations"},"integrations/vectorstores/faiss":{"id":"integrations/vectorstores/faiss","title":"Faiss","description":"Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning.","sidebar":"integrations"},"integrations/vectorstores/hologres":{"id":"integrations/vectorstores/hologres","title":"Hologres","description":"Hologres is a unified real-time data warehousing service developed by Alibaba Cloud. You can use Hologres to write, update, process, and analyze large amounts of data in real time.","sidebar":"integrations"},"integrations/vectorstores/index":{"id":"integrations/vectorstores/index","title":"Vector stores","description":"","sidebar":"integrations"},"integrations/vectorstores/lancedb":{"id":"integrations/vectorstores/lancedb","title":"LanceDB","description":"LanceDB is an open-source database for vector-search built with persistent storage, which greatly simplifies retrevial, filtering and management of embeddings. Fully open source.","sidebar":"integrations"},"integrations/vectorstores/marqo":{"id":"integrations/vectorstores/marqo","title":"Marqo","description":"This notebook shows how to use functionality related to the Marqo vectorstore.","sidebar":"integrations"},"integrations/vectorstores/matchingengine":{"id":"integrations/vectorstores/matchingengine","title":"Google Vertex AI MatchingEngine","description":"This notebook shows how to use functionality related to the GCP Vertex AI MatchingEngine vector database.","sidebar":"integrations"},"integrations/vectorstores/meilisearch":{"id":"integrations/vectorstores/meilisearch","title":"Meilisearch","description":"Meilisearch is an open-source, lightning-fast, and hyper relevant search engine. It comes with great defaults to help developers build snappy search experiences.","sidebar":"integrations"},"integrations/vectorstores/milvus":{"id":"integrations/vectorstores/milvus","title":"Milvus","description":"Milvus is a database that stores, indexes, and manages massive embedding vectors generated by deep neural networks and other machine learning (ML) models.","sidebar":"integrations"},"integrations/vectorstores/mongodb_atlas":{"id":"integrations/vectorstores/mongodb_atlas","title":"MongoDB Atlas","description":"MongoDB Atlas is a fully-managed cloud database available in AWS, Azure, and GCP.  It now has support for native Vector Search on your MongoDB document data.","sidebar":"integrations"},"integrations/vectorstores/myscale":{"id":"integrations/vectorstores/myscale","title":"MyScale","description":"MyScale is a cloud-based database optimized for AI applications and solutions, built on the open-source ClickHouse.","sidebar":"integrations"},"integrations/vectorstores/neo4jvector":{"id":"integrations/vectorstores/neo4jvector","title":"Neo4j Vector Index","description":"Neo4j is an open-source graph database with integrated support for vector similarity search","sidebar":"integrations"},"integrations/vectorstores/nucliadb_vectorstore":{"id":"integrations/vectorstores/nucliadb_vectorstore","title":"nucliadb_vectorstore","description":"You can use a local NucliaDB instance or use Nuclia Cloud.","sidebar":"integrations"},"integrations/vectorstores/opensearch":{"id":"integrations/vectorstores/opensearch","title":"OpenSearch","description":"OpenSearch is a scalable, flexible, and extensible open-source software suite for search, analytics, and observability applications licensed under Apache 2.0. OpenSearch is a distributed search and analytics engine based on Apache Lucene.","sidebar":"integrations"},"integrations/vectorstores/pgembedding":{"id":"integrations/vectorstores/pgembedding","title":"Postgres Embedding","description":"Postgres Embedding is an open-source vector similarity search for Postgres that uses  Hierarchical Navigable Small Worlds (HNSW) for approximate nearest neighbor search.","sidebar":"integrations"},"integrations/vectorstores/pgvector":{"id":"integrations/vectorstores/pgvector","title":"PGVector","description":"PGVector is an open-source vector similarity search for Postgres","sidebar":"integrations"},"integrations/vectorstores/pinecone":{"id":"integrations/vectorstores/pinecone","title":"Pinecone","description":"Pinecone is a vector database with broad functionality.","sidebar":"integrations"},"integrations/vectorstores/qdrant":{"id":"integrations/vectorstores/qdrant","title":"Qdrant","description":"Qdrant (read: quadrant ) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support. It makes it useful for all sorts of neural network or semantic-based matching, faceted search, and other applications.","sidebar":"integrations"},"integrations/vectorstores/redis":{"id":"integrations/vectorstores/redis","title":"Redis","description":"Redis vector database introduction and langchain integration guide.","sidebar":"integrations"},"integrations/vectorstores/rockset":{"id":"integrations/vectorstores/rockset","title":"Rockset","description":"Rockset is a real-time search and analytics database built for the cloud. Rockset uses a Converged Index\u2122 with an efficient store for vector embeddings to serve low latency, high concurrency search queries at scale. Rockset has full support for metadata filtering and  handles real-time ingestion for constantly updating, streaming data.","sidebar":"integrations"},"integrations/vectorstores/scann":{"id":"integrations/vectorstores/scann","title":"ScaNN","description":"ScaNN (Scalable Nearest Neighbors) is a method for efficient vector similarity search at scale.","sidebar":"integrations"},"integrations/vectorstores/singlestoredb":{"id":"integrations/vectorstores/singlestoredb","title":"SingleStoreDB","description":"SingleStoreDB is a high-performance distributed SQL database that supports deployment both in the cloud and on-premises. It provides vector storage, and vector functions including dotproduct and euclideandistance, thereby supporting AI applications that require text similarity matching.","sidebar":"integrations"},"integrations/vectorstores/sklearn":{"id":"integrations/vectorstores/sklearn","title":"scikit-learn","description":"scikit-learn is an open source collection of machine learning algorithms, including some implementations of the k nearest neighbors. SKLearnVectorStore wraps this implementation and adds the possibility to persist the vector store in json, bson (binary json) or Apache Parquet format.","sidebar":"integrations"},"integrations/vectorstores/sqlitevss":{"id":"integrations/vectorstores/sqlitevss","title":"sqlite-vss","description":"sqlite-vss is an SQLite extension designed for vector search, emphasizing local-first operations and easy integration into applications without external servers. Leveraging the Faiss library, it offers efficient similarity search and clustering capabilities.","sidebar":"integrations"},"integrations/vectorstores/starrocks":{"id":"integrations/vectorstores/starrocks","title":"StarRocks","description":"StarRocks is a High-Performance Analytical Database.","sidebar":"integrations"},"integrations/vectorstores/supabase":{"id":"integrations/vectorstores/supabase","title":"Supabase (Postgres)","description":"Supabase is an open source Firebase alternative. Supabase is built on top of PostgreSQL, which offers strong SQL querying capabilities and enables a simple interface with already-existing tools and frameworks.","sidebar":"integrations"},"integrations/vectorstores/tair":{"id":"integrations/vectorstores/tair","title":"Tair","description":"Tair is a cloud native in-memory database service developed by Alibaba Cloud.","sidebar":"integrations"},"integrations/vectorstores/tencentvectordb":{"id":"integrations/vectorstores/tencentvectordb","title":"Tencent Cloud VectorDB","description":"Tencent Cloud VectorDB is a fully managed, self-developed, enterprise-level distributed database service designed for storing, retrieving, and analyzing multi-dimensional vector data. The database supports multiple index types and similarity calculation methods. A single index can support a vector scale of up to 1 billion and can support millions of QPS and millisecond-level query latency. Tencent Cloud Vector Database can not only provide an external knowledge base for large models to improve the accuracy of large model responses but can also be widely used in AI fields such as recommendation systems, NLP services, computer vision, and intelligent customer service.","sidebar":"integrations"},"integrations/vectorstores/tigris":{"id":"integrations/vectorstores/tigris","title":"Tigris","description":"Tigris is an open source Serverless NoSQL Database and Search Platform designed to simplify building high-performance vector search applications.","sidebar":"integrations"},"integrations/vectorstores/typesense":{"id":"integrations/vectorstores/typesense","title":"Typesense","description":"Typesense is an open source, in-memory search engine, that you can either self-host or run on Typesense Cloud.","sidebar":"integrations"},"integrations/vectorstores/usearch":{"id":"integrations/vectorstores/usearch","title":"USearch","description":"USearch is a Smaller & Faster Single-File Vector Search Engine","sidebar":"integrations"},"integrations/vectorstores/vectara":{"id":"integrations/vectorstores/vectara","title":"Vectara","description":"Vectara is a API platform for building GenAI applications. It provides an easy-to-use API for document indexing and querying that is managed by Vectara and is optimized for performance and accuracy.","sidebar":"integrations"},"integrations/vectorstores/weaviate":{"id":"integrations/vectorstores/weaviate","title":"Weaviate","description":"Weaviate is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML-models, and scale seamlessly into billions of data objects.","sidebar":"integrations"},"integrations/vectorstores/xata":{"id":"integrations/vectorstores/xata","title":"Xata","description":"Xata is a serverless data platform, based on PostgreSQL. It provides a Python SDK for interacting with your database, and a UI for managing your data.","sidebar":"integrations"},"integrations/vectorstores/zep":{"id":"integrations/vectorstores/zep","title":"Zep","description":"Zep is an open source long-term memory store for LLM applications. Zep makes it easy to add relevant documents,","sidebar":"integrations"},"integrations/vectorstores/zilliz":{"id":"integrations/vectorstores/zilliz","title":"Zilliz","description":"Zilliz Cloud is a fully managed service on cloud for LF AI Milvus\xae,","sidebar":"integrations"},"modules/agents/agent_types/chat_conversation_agent":{"id":"modules/agents/agent_types/chat_conversation_agent","title":"Conversational","description":"This walkthrough demonstrates how to use an agent optimized for conversation. Other agents are often optimized for using tools to figure out the best response, which is not ideal in a conversational setting where you may want the agent to be able to chat with the user as well.","sidebar":"docs"},"modules/agents/agent_types/index":{"id":"modules/agents/agent_types/index","title":"Agent types","description":"Action agents","sidebar":"docs"},"modules/agents/agent_types/openai_functions_agent":{"id":"modules/agents/agent_types/openai_functions_agent","title":"OpenAI functions","description":"Certain OpenAI models (like gpt-3.5-turbo-0613 and gpt-4-0613) have been fine-tuned to detect when a function should be called and respond with the inputs that should be passed to the function.","sidebar":"docs"},"modules/agents/agent_types/openai_multi_functions_agent":{"id":"modules/agents/agent_types/openai_multi_functions_agent","title":"OpenAI Multi Functions Agent","description":"This notebook showcases using an agent that uses the OpenAI functions ability to respond to the prompts of the user using a Large Language Model.","sidebar":"docs"},"modules/agents/agent_types/plan_and_execute":{"id":"modules/agents/agent_types/plan_and_execute","title":"Plan-and-execute","description":"Plan-and-execute agents accomplish an objective by first planning what to do, then executing the sub tasks. This idea is largely inspired by BabyAGI and then the \\"Plan-and-Solve\\" paper.","sidebar":"docs"},"modules/agents/agent_types/react":{"id":"modules/agents/agent_types/react","title":"ReAct","description":"This walkthrough showcases using an agent to implement the ReAct logic.","sidebar":"docs"},"modules/agents/agent_types/react_docstore":{"id":"modules/agents/agent_types/react_docstore","title":"ReAct document store","description":"This walkthrough showcases using an agent to implement the ReAct logic for working with document store specifically.","sidebar":"docs"},"modules/agents/agent_types/self_ask_with_search":{"id":"modules/agents/agent_types/self_ask_with_search","title":"Self-ask with search","description":"This walkthrough showcases the self-ask with search chain.","sidebar":"docs"},"modules/agents/agent_types/structured_chat":{"id":"modules/agents/agent_types/structured_chat","title":"Structured tool chat","description":"The structured tool chat agent is capable of using multi-input tools.","sidebar":"docs"},"modules/agents/agent_types/xml_agent":{"id":"modules/agents/agent_types/xml_agent","title":"XML Agent","description":"Some language models (like Anthropic\'s Claude) are particularly good at reasoning/writing XML. This goes over how to use an agent that uses XML when prompting.","sidebar":"docs"},"modules/agents/how_to/add_memory_openai_functions":{"id":"modules/agents/how_to/add_memory_openai_functions","title":"Add Memory to OpenAI Functions Agent","description":"This notebook goes over how to add memory to an OpenAI Functions agent.","sidebar":"docs"},"modules/agents/how_to/agent_iter":{"id":"modules/agents/how_to/agent_iter","title":"Running Agent as an Iterator","description":"To demonstrate the AgentExecutorIterator functionality, we will set up a problem where an Agent must:","sidebar":"docs"},"modules/agents/how_to/agent_vectorstore":{"id":"modules/agents/how_to/agent_vectorstore","title":"Combine agents and vector stores","description":"This notebook covers how to combine agents and vector stores. The use case for this is that you\'ve ingested your data into a vector store and want to interact with it in an agentic manner.","sidebar":"docs"},"modules/agents/how_to/async_agent":{"id":"modules/agents/how_to/async_agent","title":"Async API","description":"LangChain provides async support for Agents by leveraging the asyncio library.","sidebar":"docs"},"modules/agents/how_to/chatgpt_clone":{"id":"modules/agents/how_to/chatgpt_clone","title":"Create ChatGPT clone","description":"This chain replicates ChatGPT by combining (1) a specific prompt, and (2) the concept of memory.","sidebar":"docs"},"modules/agents/how_to/custom_agent":{"id":"modules/agents/how_to/custom_agent","title":"Custom agent","description":"This notebook goes through how to create your own custom agent.","sidebar":"docs"},"modules/agents/how_to/custom_agent_with_tool_retrieval":{"id":"modules/agents/how_to/custom_agent_with_tool_retrieval","title":"Custom agent with tool retrieval","description":"This notebook builds off of this notebook and assumes familiarity with how agents work.","sidebar":"docs"},"modules/agents/how_to/custom_llm_agent":{"id":"modules/agents/how_to/custom_llm_agent","title":"Custom LLM agent","description":"This notebook goes through how to create your own custom LLM agent.","sidebar":"docs"},"modules/agents/how_to/custom_llm_chat_agent":{"id":"modules/agents/how_to/custom_llm_chat_agent","title":"Custom LLM Agent (with a ChatModel)","description":"This notebook goes through how to create your own custom agent based on a chat model.","sidebar":"docs"},"modules/agents/how_to/custom_mrkl_agent":{"id":"modules/agents/how_to/custom_mrkl_agent","title":"Custom MRKL agent","description":"This notebook goes through how to create your own custom MRKL agent.","sidebar":"docs"},"modules/agents/how_to/custom_multi_action_agent":{"id":"modules/agents/how_to/custom_multi_action_agent","title":"Custom multi-action agent","description":"This notebook goes through how to create your own custom agent.","sidebar":"docs"},"modules/agents/how_to/custom-functions-with-openai-functions-agent":{"id":"modules/agents/how_to/custom-functions-with-openai-functions-agent","title":"Custom functions with OpenAI Functions Agent","description":"This notebook goes through how to integrate custom functions with OpenAI Functions agent.","sidebar":"docs"},"modules/agents/how_to/handle_parsing_errors":{"id":"modules/agents/how_to/handle_parsing_errors","title":"Handle parsing errors","description":"Occasionally the LLM cannot determine what step to take because its outputs are not correctly formatted to be handled by the output parser. In this case, by default the agent errors. But you can easily control this functionality with handleparsingerrors! Let\'s explore how.","sidebar":"docs"},"modules/agents/how_to/intermediate_steps":{"id":"modules/agents/how_to/intermediate_steps","title":"Access intermediate steps","description":"In order to get more visibility into what an agent is doing, we can also return intermediate steps. This comes in the form of an extra key in the return value, which is a list of (action, observation) tuples.","sidebar":"docs"},"modules/agents/how_to/max_iterations":{"id":"modules/agents/how_to/max_iterations","title":"Cap the max number of iterations","description":"This notebook walks through how to cap an agent at taking a certain number of steps. This can be useful to ensure that they do not go haywire and take too many steps.","sidebar":"docs"},"modules/agents/how_to/max_time_limit":{"id":"modules/agents/how_to/max_time_limit","title":"Timeouts for agents","description":"This notebook walks through how to cap an agent executor after a certain amount of time. This can be useful for safeguarding against long running agent runs.","sidebar":"docs"},"modules/agents/how_to/mrkl":{"id":"modules/agents/how_to/mrkl","title":"Replicating MRKL","description":"This walkthrough demonstrates how to replicate the MRKL system using agents.","sidebar":"docs"},"modules/agents/how_to/sharedmemory_for_tools":{"id":"modules/agents/how_to/sharedmemory_for_tools","title":"Shared memory across agents and tools","description":"This notebook goes over adding memory to both an Agent and its tools. Before going through this notebook, please walk through the following notebooks, as this will build on top of both of them:","sidebar":"docs"},"modules/agents/how_to/streaming_stdout_final_only":{"id":"modules/agents/how_to/streaming_stdout_final_only","title":"Streaming final agent output","description":"If you only want the final output of an agent to be streamed, you can use the callback `FinalStreamingStdOutCallbackHandler`.","sidebar":"docs"},"modules/agents/how_to/use_toolkits_with_openai_functions":{"id":"modules/agents/how_to/use_toolkits_with_openai_functions","title":"Use ToolKits with OpenAI Functions","description":"This notebook shows how to use the OpenAI functions agent with arbitrary toolkits.","sidebar":"docs"},"modules/agents/index":{"id":"modules/agents/index","title":"Agents","description":"The core idea of agents is to use an LLM to choose a sequence of actions to take.","sidebar":"docs"},"modules/agents/toolkits/index":{"id":"modules/agents/toolkits/index","title":"Toolkits","description":"Head to Integrations for documentation on built-in toolkit integrations.","sidebar":"docs"},"modules/agents/tools/custom_tools":{"id":"modules/agents/tools/custom_tools","title":"Defining Custom Tools","description":"When constructing your own agent, you will need to provide it with a list of Tools that it can use. Besides the actual function that is called, the Tool consists of several components:","sidebar":"docs"},"modules/agents/tools/human_approval":{"id":"modules/agents/tools/human_approval","title":"Human-in-the-loop Tool Validation","description":"This walkthrough demonstrates how to add human validation to any Tool. We\'ll do this using the HumanApprovalCallbackhandler.","sidebar":"docs"},"modules/agents/tools/index":{"id":"modules/agents/tools/index","title":"Tools","description":"Head to Integrations for documentation on built-in tool integrations.","sidebar":"docs"},"modules/agents/tools/multi_input_tool":{"id":"modules/agents/tools/multi_input_tool","title":"Multi-Input Tools","description":"This notebook shows how to use a tool that requires multiple inputs with an agent. The recommended way to do so is with the StructuredTool class.","sidebar":"docs"},"modules/agents/tools/tool_input_validation":{"id":"modules/agents/tools/tool_input_validation","title":"Tool Input Schema","description":"By default, tools infer the argument schema by inspecting the function signature. For more strict requirements, custom input schema can be specified, along with custom validation logic.","sidebar":"docs"},"modules/agents/tools/tools_as_openai_functions":{"id":"modules/agents/tools/tools_as_openai_functions","title":"Tools as OpenAI Functions","description":"This notebook goes over how to use LangChain tools as OpenAI functions.","sidebar":"docs"},"modules/callbacks/async_callbacks":{"id":"modules/callbacks/async_callbacks","title":"Async callbacks","description":"If you are planning to use the async API, it is recommended to use AsyncCallbackHandler to avoid blocking the runloop.","sidebar":"docs"},"modules/callbacks/custom_callbacks":{"id":"modules/callbacks/custom_callbacks","title":"Custom callback handlers","description":"You can create a custom handler to set on the object as well. In the example below, we\'ll implement streaming with a custom handler.","sidebar":"docs"},"modules/callbacks/custom_chain":{"id":"modules/callbacks/custom_chain","title":"Callbacks for custom chains","description":"When you create a custom chain you can easily set it up to use the same callback system as all the built-in chains.","sidebar":"docs"},"modules/callbacks/filecallbackhandler":{"id":"modules/callbacks/filecallbackhandler","title":"Logging to file","description":"This example shows how to print logs to file. It shows how to use the FileCallbackHandler, which does the same thing as StdOutCallbackHandler, but instead writes the output to file. It also uses the loguru library to log other outputs that are not captured by the handler.","sidebar":"docs"},"modules/callbacks/index":{"id":"modules/callbacks/index","title":"Callbacks","description":"Head to Integrations for documentation on built-in callbacks integrations with 3rd-party tools.","sidebar":"docs"},"modules/callbacks/multiple_callbacks":{"id":"modules/callbacks/multiple_callbacks","title":"Multiple callback handlers","description":"In the previous examples, we passed in callback handlers upon creation of an object by using callbacks=. In this case, the callbacks will be scoped to that particular object.","sidebar":"docs"},"modules/callbacks/tags":{"id":"modules/callbacks/tags","title":"Tags","description":"You can add tags to your callbacks by passing a tags argument to the call()/run()/apply() methods. This is useful for filtering your logs, e.g. if you want to log all requests made to a specific LLMChain, you can add a tag, and then filter your logs by that tag. You can pass tags to both constructor and request callbacks, see the examples above for details. These tags are then passed to the tags argument of the \\"start\\" callback methods, ie. onllmstart, onchatmodelstart, onchainstart, ontool_start.","sidebar":"docs"},"modules/callbacks/token_counting":{"id":"modules/callbacks/token_counting","title":"Token counting","description":"LangChain offers a context manager that allows you to count tokens.","sidebar":"docs"},"modules/chains/document/index":{"id":"modules/chains/document/index","title":"Documents","description":"These are the core chains for working with documents. They are useful for summarizing documents, answering questions over documents, extracting information from documents, and more.","sidebar":"docs"},"modules/chains/document/map_reduce":{"id":"modules/chains/document/map_reduce","title":"Map reduce","description":"The map reduce documents chain first applies an LLM chain to each document individually (the Map step), treating the chain output as a new document. It then passes all the new documents to a separate combine documents chain to get a single output (the Reduce step). It can optionally first compress, or collapse, the mapped documents to make sure that they fit in the combine documents chain (which will often pass them to an LLM). This compression step is performed recursively if necessary.","sidebar":"docs"},"modules/chains/document/map_rerank":{"id":"modules/chains/document/map_rerank","title":"Map re-rank","description":"The map re-rank documents chain runs an initial prompt on each document, that not only tries to complete a task but also gives a score for how certain it is in its answer. The highest scoring response is returned.","sidebar":"docs"},"modules/chains/document/refine":{"id":"modules/chains/document/refine","title":"Refine","description":"The Refine documents chain constructs a response by looping over the input documents and iteratively updating its answer. For each document, it passes all non-document inputs, the current document, and the latest intermediate answer to an LLM chain to get a new answer.","sidebar":"docs"},"modules/chains/document/stuff":{"id":"modules/chains/document/stuff","title":"Stuff","description":"The stuff documents chain (\\"stuff\\" as in \\"to stuff\\" or \\"to fill\\") is the most straightforward of the document chains. It takes a list of documents, inserts them all into a prompt and passes that prompt to an LLM.","sidebar":"docs"},"modules/chains/foundational/index":{"id":"modules/chains/foundational/index","title":"Foundational","description":"","sidebar":"docs"},"modules/chains/foundational/llm_chain":{"id":"modules/chains/foundational/llm_chain","title":"LLM","description":"An LLMChain is a simple chain that adds some functionality around language models. It is used widely throughout LangChain, including in other chains and agents.","sidebar":"docs"},"modules/chains/foundational/router":{"id":"modules/chains/foundational/router","title":"Router","description":"This notebook demonstrates how to use the RouterChain paradigm to create a chain that dynamically selects the next chain to use for a given input.","sidebar":"docs"},"modules/chains/foundational/sequential_chains":{"id":"modules/chains/foundational/sequential_chains","title":"Sequential","description":"The next step after calling a language model is make a series of calls to a language model. This is particularly useful when you want to take the output from one call and use it as the input to another.","sidebar":"docs"},"modules/chains/foundational/transformation":{"id":"modules/chains/foundational/transformation","title":"Transformation","description":"This notebook showcases using a generic transformation chain.","sidebar":"docs"},"modules/chains/how_to/async_chain":{"id":"modules/chains/how_to/async_chain","title":"Async API","description":"LangChain provides async support for Chains by leveraging the asyncio library.","sidebar":"docs"},"modules/chains/how_to/call_methods":{"id":"modules/chains/how_to/call_methods","title":"Different call methods","description":"All classes inherited from Chain offer a few ways of running chain logic. The most direct one is by using call:","sidebar":"docs"},"modules/chains/how_to/custom_chain":{"id":"modules/chains/how_to/custom_chain","title":"Custom chain","description":"To implement your own custom chain you can subclass Chain and implement the following methods:","sidebar":"docs"},"modules/chains/how_to/debugging":{"id":"modules/chains/how_to/debugging","title":"Debugging chains","description":"It can be hard to debug a Chain object solely from its output as most Chain objects involve a fair amount of input prompt preprocessing and LLM output post-processing.","sidebar":"docs"},"modules/chains/how_to/from_hub":{"id":"modules/chains/how_to/from_hub","title":"Loading from LangChainHub","description":"This notebook covers how to load chains from LangChainHub.","sidebar":"docs"},"modules/chains/how_to/index":{"id":"modules/chains/how_to/index","title":"How to","description":"","sidebar":"docs"},"modules/chains/how_to/memory":{"id":"modules/chains/how_to/memory","title":"Adding memory (state)","description":"Chains can be initialized with a Memory object, which will persist data across calls to the chain. This makes a Chain stateful.","sidebar":"docs"},"modules/chains/how_to/openai_functions":{"id":"modules/chains/how_to/openai_functions","title":"Using OpenAI functions","description":"This walkthrough demonstrates how to incorporate OpenAI function-calling API\'s in a chain. We\'ll go over:","sidebar":"docs"},"modules/chains/how_to/serialization":{"id":"modules/chains/how_to/serialization","title":"Serialization","description":"This notebook covers how to serialize chains to and from disk. The serialization format we use is JSON or YAML. Currently, only some chains support this type of serialization. We will grow the number of supported chains over time.","sidebar":"docs"},"modules/chains/index":{"id":"modules/chains/index","title":"Chains","description":"Using an LLM in isolation is fine for simple applications,","sidebar":"docs"},"modules/data_connection/document_loaders/csv":{"id":"modules/data_connection/document_loaders/csv","title":"CSV","description":"A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas.","sidebar":"docs"},"modules/data_connection/document_loaders/file_directory":{"id":"modules/data_connection/document_loaders/file_directory","title":"File Directory","description":"This covers how to load all documents in a directory.","sidebar":"docs"},"modules/data_connection/document_loaders/html":{"id":"modules/data_connection/document_loaders/html","title":"HTML","description":"The HyperText Markup Language or HTML is the standard markup language for documents designed to be displayed in a web browser.","sidebar":"docs"},"modules/data_connection/document_loaders/index":{"id":"modules/data_connection/document_loaders/index","title":"Document loaders","description":"Head to Integrations for documentation on built-in document loader integrations with 3rd-party tools.","sidebar":"docs"},"modules/data_connection/document_loaders/json":{"id":"modules/data_connection/document_loaders/json","title":"JSON","description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute\u2013value pairs and arrays (or other serializable values).","sidebar":"docs"},"modules/data_connection/document_loaders/markdown":{"id":"modules/data_connection/document_loaders/markdown","title":"Markdown","description":"Markdown is a lightweight markup language for creating formatted text using a plain-text editor.","sidebar":"docs"},"modules/data_connection/document_loaders/pdf":{"id":"modules/data_connection/document_loaders/pdf","title":"PDF","description":"Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.","sidebar":"docs"},"modules/data_connection/document_transformers/index":{"id":"modules/data_connection/document_transformers/index","title":"Document transformers","description":"Head to Integrations for documentation on built-in document transformer integrations with 3rd-party tools.","sidebar":"docs"},"modules/data_connection/document_transformers/post_retrieval/long_context_reorder":{"id":"modules/data_connection/document_transformers/post_retrieval/long_context_reorder","title":"Lost in the middle: The problem with long contexts","description":"No matter the architecture of your model, there is a substantial performance degradation when you include 10+ retrieved documents.","sidebar":"docs"},"modules/data_connection/document_transformers/text_splitters/character_text_splitter":{"id":"modules/data_connection/document_transformers/text_splitters/character_text_splitter","title":"Split by character","description":"This is the simplest method. This splits based on characters (by default \\"\\\\n\\\\n\\") and measure chunk length by number of characters.","sidebar":"docs"},"modules/data_connection/document_transformers/text_splitters/code_splitter":{"id":"modules/data_connection/document_transformers/text_splitters/code_splitter","title":"Split code","description":"CodeTextSplitter allows you to split your code with multiple languages supported. Import enum Language and specify the language.","sidebar":"docs"},"modules/data_connection/document_transformers/text_splitters/markdown_header_metadata":{"id":"modules/data_connection/document_transformers/text_splitters/markdown_header_metadata","title":"MarkdownHeaderTextSplitter","description":"Motivation","sidebar":"docs"},"modules/data_connection/document_transformers/text_splitters/recursive_text_splitter":{"id":"modules/data_connection/document_transformers/text_splitters/recursive_text_splitter","title":"Recursively split by character","description":"This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\\"\\\\n\\\\n\\", \\"\\\\n\\", \\" \\", \\"\\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.","sidebar":"docs"},"modules/data_connection/document_transformers/text_splitters/split_by_token":{"id":"modules/data_connection/document_transformers/text_splitters/split_by_token","title":"Split by tokens","description":"Language models have a token limit. You should not exceed the token limit. When you split your text into chunks it is therefore a good idea to count the number of tokens. There are many tokenizers. When you count tokens in your text you should use the same tokenizer as used in the language model.","sidebar":"docs"},"modules/data_connection/index":{"id":"modules/data_connection/index","title":"Retrieval","description":"Many LLM applications require user-specific data that is not part of the model\'s training set.","sidebar":"docs"},"modules/data_connection/indexing":{"id":"modules/data_connection/indexing","title":"Indexing","description":"Here, we will look at a basic indexing workflow using the LangChain indexing API.","sidebar":"docs"},"modules/data_connection/retrievers/contextual_compression/index":{"id":"modules/data_connection/retrievers/contextual_compression/index","title":"Contextual compression","description":"One challenge with retrieval is that usually you don\'t know the specific queries your document storage system will face when you ingest data into the system. This means that the information most relevant to a query may be buried in a document with a lot of irrelevant text. Passing that full document through your application can lead to more expensive LLM calls and poorer responses.","sidebar":"docs"},"modules/data_connection/retrievers/ensemble":{"id":"modules/data_connection/retrievers/ensemble","title":"Ensemble Retriever","description":"The EnsembleRetriever takes a list of retrievers as input and ensemble the results of their getrelevantdocuments() methods and rerank the results based on the Reciprocal Rank Fusion algorithm.","sidebar":"docs"},"modules/data_connection/retrievers/index":{"id":"modules/data_connection/retrievers/index","title":"Retrievers","description":"Head to Integrations for documentation on built-in retriever integrations with 3rd-party tools.","sidebar":"docs"},"modules/data_connection/retrievers/multi_vector":{"id":"modules/data_connection/retrievers/multi_vector","title":"MultiVector Retriever","description":"It can often be beneficial to store multiple vectors per document. There are multiple use cases where this is beneficial. LangChain has a base MultiVectorRetriever which makes querying this type of setup easy. A lot of the complexity lies in how to create the multiple vectors per document. This notebook covers some of the common ways to create those vectors and use the MultiVectorRetriever.","sidebar":"docs"},"modules/data_connection/retrievers/MultiQueryRetriever":{"id":"modules/data_connection/retrievers/MultiQueryRetriever","title":"MultiQueryRetriever","description":"Distance-based vector database retrieval embeds (represents) queries in high-dimensional space and finds similar embedded documents based on \\"distance\\". But, retrieval may produce different results with subtle changes in query wording or if the embeddings do not capture the semantics of the data well. Prompt engineering / tuning is sometimes done to manually address these problems, but can be tedious.","sidebar":"docs"},"modules/data_connection/retrievers/parent_document_retriever":{"id":"modules/data_connection/retrievers/parent_document_retriever","title":"Parent Document Retriever","description":"When splitting documents for retrieval, there are often conflicting desires:","sidebar":"docs"},"modules/data_connection/retrievers/self_query/activeloop_deeplake_self_query":{"id":"modules/data_connection/retrievers/self_query/activeloop_deeplake_self_query","title":"Deep Lake self-querying","description":"Deep Lake is a multimodal database for building AI applications.","sidebar":"docs"},"modules/data_connection/retrievers/self_query/chroma_self_query":{"id":"modules/data_connection/retrievers/self_query/chroma_self_query","title":"Chroma self-querying","description":"Chroma is a database for building AI applications with embeddings.","sidebar":"docs"},"modules/data_connection/retrievers/self_query/dashvector":{"id":"modules/data_connection/retrievers/self_query/dashvector","title":"DashVector self-querying","description":"DashVector is a fully-managed vectorDB service that supports high-dimension dense and sparse vectors, real-time insertion and filtered search. It is built to scale automatically and can adapt to different application requirements.","sidebar":"docs"},"modules/data_connection/retrievers/self_query/elasticsearch_self_query":{"id":"modules/data_connection/retrievers/self_query/elasticsearch_self_query","title":"Elasticsearch self-querying","description":"Creating a Elasticsearch vector store","sidebar":"docs"},"modules/data_connection/retrievers/self_query/index":{"id":"modules/data_connection/retrievers/self_query/index","title":"Self-querying","description":"A self-querying retriever is one that, as the name suggests, has the ability to query itself. Specifically, given any natural language query, the retriever uses a query-constructing LLM chain to write a structured query and then applies that structured query to its underlying VectorStore. This allows the retriever to not only use the user-input query for semantic similarity comparison with the contents of stored documents but to also extract filters from the user query on the metadata of stored documents and to execute those filters.","sidebar":"docs"},"modules/data_connection/retrievers/self_query/milvus_self_query":{"id":"modules/data_connection/retrievers/self_query/milvus_self_query","title":"Self-querying with Milvus","description":"In the walkthrough we\'ll demo the SelfQueryRetriever with a Milvus vector store.","sidebar":"docs"},"modules/data_connection/retrievers/self_query/myscale_self_query":{"id":"modules/data_connection/retrievers/self_query/myscale_self_query","title":"Self-querying with MyScale","description":"MyScale is an integrated vector database. You can access your database in SQL and also from here, LangChain. MyScale can make a use of various data types and functions for filters. It will boost up your LLM app no matter if you are scaling up your data or expand your system to broader application.","sidebar":"docs"},"modules/data_connection/retrievers/self_query/pinecone":{"id":"modules/data_connection/retrievers/self_query/pinecone","title":"Self-querying with Pinecone","description":"In the walkthrough we\'ll demo the SelfQueryRetriever with a Pinecone vector store.","sidebar":"docs"},"modules/data_connection/retrievers/self_query/qdrant_self_query":{"id":"modules/data_connection/retrievers/self_query/qdrant_self_query","title":"Qdrant self-querying","description":"Qdrant (read: quadrant) is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload. Qdrant is tailored to extended filtering support.","sidebar":"docs"},"modules/data_connection/retrievers/self_query/weaviate_self_query":{"id":"modules/data_connection/retrievers/self_query/weaviate_self_query","title":"Weaviate self-querying","description":"Creating a Weaviate vector store","sidebar":"docs"},"modules/data_connection/retrievers/time_weighted_vectorstore":{"id":"modules/data_connection/retrievers/time_weighted_vectorstore","title":"Time-weighted vector store retriever","description":"This retriever uses a combination of semantic similarity and a time decay.","sidebar":"docs"},"modules/data_connection/retrievers/vectorstore":{"id":"modules/data_connection/retrievers/vectorstore","title":"Vector store-backed retriever","description":"A vector store retriever is a retriever that uses a vector store to retrieve documents. It is a lightweight wrapper around the vector store class to make it conform to the retriever interface.","sidebar":"docs"},"modules/data_connection/retrievers/web_research":{"id":"modules/data_connection/retrievers/web_research","title":"WebResearchRetriever","description":"Given a query, this retriever will:","sidebar":"docs"},"modules/data_connection/text_embedding/caching_embeddings":{"id":"modules/data_connection/text_embedding/caching_embeddings","title":"Caching","description":"Embeddings can be stored or temporarily cached to avoid needing to recompute them.","sidebar":"docs"},"modules/data_connection/text_embedding/index":{"id":"modules/data_connection/text_embedding/index","title":"Text embedding models","description":"Head to Integrations for documentation on built-in integrations with text embedding model providers.","sidebar":"docs"},"modules/data_connection/vectorstores/index":{"id":"modules/data_connection/vectorstores/index","title":"Vector stores","description":"Head to Integrations for documentation on built-in integrations with 3rd-party vector stores.","sidebar":"docs"},"modules/index":{"id":"modules/index","title":"Modules","description":"LangChain provides standard, extendable interfaces and external integrations for the following modules, listed from least to most complex:","sidebar":"docs"},"modules/memory/adding_memory":{"id":"modules/memory/adding_memory","title":"Memory in LLMChain","description":"This notebook goes over how to use the Memory class with an LLMChain.","sidebar":"docs"},"modules/memory/adding_memory_chain_multiple_inputs":{"id":"modules/memory/adding_memory_chain_multiple_inputs","title":"Memory in the Multi-Input Chain","description":"Most memory objects assume a single input. In this notebook, we go over how to add memory to a chain that has multiple inputs. We will add memory to a question/answering chain. This chain takes as inputs both related documents and a user question.","sidebar":"docs"},"modules/memory/agent_with_memory":{"id":"modules/memory/agent_with_memory","title":"Memory in Agent","description":"This notebook goes over adding memory to an Agent. Before going through this notebook, please walkthrough the following notebooks, as this will build on top of both of them:","sidebar":"docs"},"modules/memory/agent_with_memory_in_db":{"id":"modules/memory/agent_with_memory_in_db","title":"Message Memory in Agent backed by a database","description":"This notebook goes over adding memory to an Agent where the memory uses an external message store. Before going through this notebook, please walkthrough the following notebooks, as this will build on top of both of them:","sidebar":"docs"},"modules/memory/chat_messages/index":{"id":"modules/memory/chat_messages/index","title":"Chat Messages","description":"Head to Integrations for documentation on built-in memory integrations with 3rd-party databases and tools.","sidebar":"docs"},"modules/memory/conversational_customization":{"id":"modules/memory/conversational_customization","title":"Customizing Conversational Memory","description":"This notebook walks through a few ways to customize conversational memory.","sidebar":"docs"},"modules/memory/custom_memory":{"id":"modules/memory/custom_memory","title":"Custom Memory","description":"Although there are a few predefined types of memory in LangChain, it is highly possible you will want to add your own type of memory that is optimal for your application. This notebook covers how to do that.","sidebar":"docs"},"modules/memory/index":{"id":"modules/memory/index","title":"Memory","description":"Most LLM applications have a conversational interface. An essential component of a conversation is being able to refer to information introduced earlier in the conversation.","sidebar":"docs"},"modules/memory/multiple_memory":{"id":"modules/memory/multiple_memory","title":"Multiple Memory classes","description":"We can use multiple memory classes in the same chain. To combine multiple memory classes, we initialize and use the CombinedMemory class.","sidebar":"docs"},"modules/memory/types/buffer":{"id":"modules/memory/types/buffer","title":"Conversation Buffer","description":"This notebook shows how to use ConversationBufferMemory. This memory allows for storing messages and then extracts the messages in a variable.","sidebar":"docs"},"modules/memory/types/buffer_window":{"id":"modules/memory/types/buffer_window","title":"Conversation Buffer Window","description":"ConversationBufferWindowMemory keeps a list of the interactions of the conversation over time. It only uses the last K interactions. This can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large.","sidebar":"docs"},"modules/memory/types/entity_summary_memory":{"id":"modules/memory/types/entity_summary_memory","title":"Entity","description":"Entity memory remembers given facts about specific entities in a conversation. It extracts information on entities (using an LLM) and builds up its knowledge about that entity over time (also using an LLM).","sidebar":"docs"},"modules/memory/types/index":{"id":"modules/memory/types/index","title":"Memory types","description":"There are many different types of memory.","sidebar":"docs"},"modules/memory/types/kg":{"id":"modules/memory/types/kg","title":"Conversation Knowledge Graph","description":"This type of memory uses a knowledge graph to recreate memory.","sidebar":"docs"},"modules/memory/types/summary":{"id":"modules/memory/types/summary","title":"Conversation Summary","description":"Now let\'s take a look at using a slightly more complex type of memory - ConversationSummaryMemory. This type of memory creates a summary of the conversation over time. This can be useful for condensing information from the conversation over time.","sidebar":"docs"},"modules/memory/types/summary_buffer":{"id":"modules/memory/types/summary_buffer","title":"Conversation Summary Buffer","description":"ConversationSummaryBufferMemory combines the two ideas. It keeps a buffer of recent interactions in memory, but rather than just completely flushing old interactions it compiles them into a summary and uses both.","sidebar":"docs"},"modules/memory/types/token_buffer":{"id":"modules/memory/types/token_buffer","title":"Conversation Token Buffer","description":"ConversationTokenBufferMemory keeps a buffer of recent interactions in memory, and uses token length rather than number of interactions to determine when to flush interactions.","sidebar":"docs"},"modules/memory/types/vectorstore_retriever_memory":{"id":"modules/memory/types/vectorstore_retriever_memory","title":"Backed by a Vector Store","description":"VectorStoreRetrieverMemory stores memories in a vector store and queries the top-K most \\"salient\\" docs every time it is called.","sidebar":"docs"},"modules/model_io/index":{"id":"modules/model_io/index","title":"Model I/O","description":"The core element of any language model application is...the model. LangChain gives you the building blocks to interface with any language model.","sidebar":"docs"},"modules/model_io/models/chat/chat_model_caching":{"id":"modules/model_io/models/chat/chat_model_caching","title":"Caching","description":"LangChain provides an optional caching layer for chat models. This is useful for two reasons:","sidebar":"docs"},"modules/model_io/models/chat/human_input_chat_model":{"id":"modules/model_io/models/chat/human_input_chat_model","title":"Human input chat model","description":"Along with HumanInputLLM, LangChain also provides a pseudo chat model class that can be used for testing, debugging, or educational purposes. This allows you to mock out calls to the chat model and simulate how a human would respond if they received the messages.","sidebar":"docs"},"modules/model_io/models/chat/index":{"id":"modules/model_io/models/chat/index","title":"Chat models","description":"Head to Integrations for documentation on built-in integrations with chat model providers.","sidebar":"docs"},"modules/model_io/models/chat/llm_chain":{"id":"modules/model_io/models/chat/llm_chain","title":"LLMChain","description":"You can use the existing LLMChain in a very similar way to before - provide a prompt and a model.","sidebar":"docs"},"modules/model_io/models/chat/prompts":{"id":"modules/model_io/models/chat/prompts","title":"Prompts","description":"Prompts for chat models are built around messages, instead of just plain text.","sidebar":"docs"},"modules/model_io/models/chat/streaming":{"id":"modules/model_io/models/chat/streaming","title":"Streaming","description":"Some chat models provide a streaming response. This means that instead of waiting for the entire response to be returned, you can start processing it as soon as it\'s available. This is useful if you want to display the response to the user as it\'s being generated, or if you want to process the response as it\'s being generated.","sidebar":"docs"},"modules/model_io/models/index":{"id":"modules/model_io/models/index","title":"Language models","description":"LangChain provides interfaces and integrations for two types of models:","sidebar":"docs"},"modules/model_io/models/llms/async_llm":{"id":"modules/model_io/models/llms/async_llm","title":"Async API","description":"LangChain provides async support for LLMs by leveraging the asyncio library.","sidebar":"docs"},"modules/model_io/models/llms/custom_llm":{"id":"modules/model_io/models/llms/custom_llm","title":"Custom LLM","description":"This notebook goes over how to create a custom LLM wrapper, in case you want to use your own LLM or a different wrapper than one that is supported in LangChain.","sidebar":"docs"},"modules/model_io/models/llms/fake_llm":{"id":"modules/model_io/models/llms/fake_llm","title":"Fake LLM","description":"LangChain provides a fake LLM class that can be used for testing. This allows you to mock out calls to the LLM and simulate what would happen if the LLM responded in a certain way.","sidebar":"docs"},"modules/model_io/models/llms/human_input_llm":{"id":"modules/model_io/models/llms/human_input_llm","title":"Human input LLM","description":"Similar to the fake LLM, LangChain provides a pseudo LLM class that can be used for testing, debugging, or educational purposes. This allows you to mock out calls to the LLM and simulate how a human would respond if they received the prompts.","sidebar":"docs"},"modules/model_io/models/llms/index":{"id":"modules/model_io/models/llms/index","title":"LLMs","description":"Head to Integrations for documentation on built-in integrations with LLM providers.","sidebar":"docs"},"modules/model_io/models/llms/llm_caching":{"id":"modules/model_io/models/llms/llm_caching","title":"Caching","description":"LangChain provides an optional caching layer for LLMs. This is useful for two reasons:","sidebar":"docs"},"modules/model_io/models/llms/llm_serialization":{"id":"modules/model_io/models/llms/llm_serialization","title":"Serialization","description":"This notebook walks through how to write and read an LLM Configuration to and from disk. This is useful if you want to save the configuration for a given LLM (e.g., the provider, the temperature, etc).","sidebar":"docs"},"modules/model_io/models/llms/streaming_llm":{"id":"modules/model_io/models/llms/streaming_llm","title":"Streaming","description":"Some LLMs provide a streaming response. This means that instead of waiting for the entire response to be returned, you can start processing it as soon as it\'s available. This is useful if you want to display the response to the user as it\'s being generated, or if you want to process the response as it\'s being generated.","sidebar":"docs"},"modules/model_io/models/llms/token_usage_tracking":{"id":"modules/model_io/models/llms/token_usage_tracking","title":"Tracking token usage","description":"This notebook goes over how to track your token usage for specific calls. It is currently only implemented for the OpenAI API.","sidebar":"docs"},"modules/model_io/output_parsers/comma_separated":{"id":"modules/model_io/output_parsers/comma_separated","title":"List parser","description":"This output parser can be used when you want to return a list of comma-separated items.","sidebar":"docs"},"modules/model_io/output_parsers/datetime":{"id":"modules/model_io/output_parsers/datetime","title":"Datetime parser","description":"This OutputParser can be used to parse LLM output into datetime format.","sidebar":"docs"},"modules/model_io/output_parsers/enum":{"id":"modules/model_io/output_parsers/enum","title":"Enum parser","description":"This notebook shows how to use an Enum output parser.","sidebar":"docs"},"modules/model_io/output_parsers/index":{"id":"modules/model_io/output_parsers/index","title":"Output parsers","description":"Language models output text. But many times you may want to get more structured information than just text back. This is where output parsers come in.","sidebar":"docs"},"modules/model_io/output_parsers/output_fixing_parser":{"id":"modules/model_io/output_parsers/output_fixing_parser","title":"Auto-fixing parser","description":"This output parser wraps another output parser, and in the event that the first one fails it calls out to another LLM to fix any errors.","sidebar":"docs"},"modules/model_io/output_parsers/pydantic":{"id":"modules/model_io/output_parsers/pydantic","title":"Pydantic (JSON) parser","description":"This output parser allows users to specify an arbitrary JSON schema and query LLMs for JSON outputs that conform to that schema.","sidebar":"docs"},"modules/model_io/output_parsers/retry":{"id":"modules/model_io/output_parsers/retry","title":"Retry parser","description":"While in some cases it is possible to fix any parsing mistakes by only looking at the output, in other cases it isn\'t. An example of this is when the output is not just in the incorrect format, but is partially complete. Consider the below example.","sidebar":"docs"},"modules/model_io/output_parsers/structured":{"id":"modules/model_io/output_parsers/structured","title":"Structured output parser","description":"This output parser can be used when you want to return multiple fields. While the Pydantic/JSON parser is more powerful, we initially experimented with data structures having text fields only.","sidebar":"docs"},"modules/model_io/prompts/example_selectors/custom_example_selector":{"id":"modules/model_io/prompts/example_selectors/custom_example_selector","title":"Custom example selector","description":"In this tutorial, we\'ll create a custom example selector that selects examples randomly from a given list of examples.","sidebar":"docs"},"modules/model_io/prompts/example_selectors/index":{"id":"modules/model_io/prompts/example_selectors/index","title":"Example selectors","description":"If you have a large number of examples, you may need to select which ones to include in the prompt. The Example Selector is the class responsible for doing so.","sidebar":"docs"},"modules/model_io/prompts/example_selectors/length_based":{"id":"modules/model_io/prompts/example_selectors/length_based","title":"Select by length","description":"This example selector selects which examples to use based on length. This is useful when you are worried about constructing a prompt that will go over the length of the context window. For longer inputs, it will select fewer examples to include, while for shorter inputs it will select more.","sidebar":"docs"},"modules/model_io/prompts/example_selectors/mmr":{"id":"modules/model_io/prompts/example_selectors/mmr","title":"Select by maximal marginal relevance (MMR)","description":"The MaxMarginalRelevanceExampleSelector selects examples based on a combination of which examples are most similar to the inputs, while also optimizing for diversity. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs, and then iteratively adding them while penalizing them for closeness to already selected examples.","sidebar":"docs"},"modules/model_io/prompts/example_selectors/ngram_overlap":{"id":"modules/model_io/prompts/example_selectors/ngram_overlap","title":"Select by n-gram overlap","description":"The NGramOverlapExampleSelector selects and orders examples based on which examples are most similar to the input, according to an ngram overlap score. The ngram overlap score is a float between 0.0 and 1.0, inclusive.","sidebar":"docs"},"modules/model_io/prompts/example_selectors/similarity":{"id":"modules/model_io/prompts/example_selectors/similarity","title":"Select by similarity","description":"This object selects examples based on similarity to the inputs. It does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs.","sidebar":"docs"},"modules/model_io/prompts/index":{"id":"modules/model_io/prompts/index","title":"Prompts","description":"A prompt for a language model is a set of instructions or input provided by a user to","sidebar":"docs"},"modules/model_io/prompts/prompt_templates/connecting_to_a_feature_store":{"id":"modules/model_io/prompts/prompt_templates/connecting_to_a_feature_store","title":"Connecting to a Feature Store","description":"Feature stores are a concept from traditional machine learning that make sure data fed into models is up-to-date and relevant. For more on this, see here.","sidebar":"docs"},"modules/model_io/prompts/prompt_templates/custom_prompt_template":{"id":"modules/model_io/prompts/prompt_templates/custom_prompt_template","title":"Custom prompt template","description":"Let\'s suppose we want the LLM to generate English language explanations of a function given its name. To achieve this task, we will create a custom prompt template that takes in the function name as input, and formats the prompt template to provide the source code of the function.","sidebar":"docs"},"modules/model_io/prompts/prompt_templates/few_shot_examples":{"id":"modules/model_io/prompts/prompt_templates/few_shot_examples","title":"Few-shot prompt templates","description":"In this tutorial, we\'ll learn how to create a prompt template that uses few-shot examples. A few-shot prompt template can be constructed from either a set of examples, or from an Example Selector object.","sidebar":"docs"},"modules/model_io/prompts/prompt_templates/few_shot_examples_chat":{"id":"modules/model_io/prompts/prompt_templates/few_shot_examples_chat","title":"Few-shot examples for chat models","description":"This notebook covers how to use few-shot examples in chat models. There does not appear to be solid consensus on how best to do few-shot prompting, and the optimal prompt compilation will likely vary by model. Because of this, we provide few-shot prompt templates like the FewShotChatMessagePromptTemplate as a flexible starting point, and you can modify or replace them as you see fit.","sidebar":"docs"},"modules/model_io/prompts/prompt_templates/format_output":{"id":"modules/model_io/prompts/prompt_templates/format_output","title":"Format template output","description":"The output of the format method is available as a string, list of messages and ChatPromptValue","sidebar":"docs"},"modules/model_io/prompts/prompt_templates/formats":{"id":"modules/model_io/prompts/prompt_templates/formats","title":"Template formats","description":"PromptTemplate by default uses Python f-string as its template format. However, it can also use other formats like jinja2, specified through the template_format argument.","sidebar":"docs"},"modules/model_io/prompts/prompt_templates/index":{"id":"modules/model_io/prompts/prompt_templates/index","title":"Prompt templates","description":"Prompt templates are pre-defined recipes for generating prompts for language models.","sidebar":"docs"},"modules/model_io/prompts/prompt_templates/msg_prompt_templates":{"id":"modules/model_io/prompts/prompt_templates/msg_prompt_templates","title":"Types of MessagePromptTemplate","description":"LangChain provides different types of MessagePromptTemplate. The most commonly used are AIMessagePromptTemplate, SystemMessagePromptTemplate and HumanMessagePromptTemplate, which create an AI message, system message and human message respectively.","sidebar":"docs"},"modules/model_io/prompts/prompt_templates/partial":{"id":"modules/model_io/prompts/prompt_templates/partial","title":"Partial prompt templates","description":"Like other methods, it can make sense to \\"partial\\" a prompt template - e.g. pass in a subset of the required values, as to create a new prompt template which expects only the remaining subset of values.","sidebar":"docs"},"modules/model_io/prompts/prompt_templates/prompt_composition":{"id":"modules/model_io/prompts/prompt_templates/prompt_composition","title":"Composition","description":"This notebook goes over how to compose multiple prompts together. This can be useful when you want to reuse parts of prompts. This can be done with a PipelinePrompt. A PipelinePrompt consists of two main parts:","sidebar":"docs"},"modules/model_io/prompts/prompt_templates/prompt_serialization":{"id":"modules/model_io/prompts/prompt_templates/prompt_serialization","title":"Serialization","description":"It is often preferrable to store prompts not as python code but as files. This can make it easy to share, store, and version prompts. This notebook covers how to do that in LangChain, walking through all the different types of prompts and the different serialization options.","sidebar":"docs"},"modules/model_io/prompts/prompt_templates/prompts_pipelining":{"id":"modules/model_io/prompts/prompt_templates/prompts_pipelining","title":"Prompt pipelining","description":"The idea behind prompt pipelining is to provide a user friendly interface for composing different parts of prompts together. You can do this with either string prompts or chat prompts. Constructing prompts this way allows for easy reuse of components.","sidebar":"docs"},"modules/model_io/prompts/prompt_templates/validate":{"id":"modules/model_io/prompts/prompt_templates/validate","title":"Validate template","description":"By default, PromptTemplate will validate the template string by checking whether the inputvariables match the variables defined in template. You can disable this behavior by setting validatetemplate to False.","sidebar":"docs"},"solidworks-api/installation":{"id":"solidworks-api/installation","title":"Installation","description":""},"solidworks-api/introduction":{"id":"solidworks-api/introduction","title":"Introduction","description":"LangChain is a framework for developing applications powered by language models. It enables applications that are:"},"solidworks-api/quickstart":{"id":"solidworks-api/quickstart","title":"Quickstart","description":"Installation"},"use_cases/apis":{"id":"use_cases/apis","title":"Interacting with APIs","description":"Open In Collab","sidebar":"use_cases"},"use_cases/chatbots":{"id":"use_cases/chatbots","title":"Chatbots","description":"Open In Collab","sidebar":"use_cases"},"use_cases/code_understanding":{"id":"use_cases/code_understanding","title":"Code understanding","description":"Open In Collab","sidebar":"use_cases"},"use_cases/extraction":{"id":"use_cases/extraction","title":"Extraction","description":"Open In Collab","sidebar":"use_cases"},"use_cases/more/agents/agent_simulations/camel_role_playing":{"id":"use_cases/more/agents/agent_simulations/camel_role_playing","title":"CAMEL Role-Playing Autonomous Cooperative Agents","description":"This is a langchain implementation of paper Communicative Agents for \u201cMind\u201d Exploration of Large Scale Language Model Society\\".","sidebar":"use_cases"},"use_cases/more/agents/agent_simulations/characters":{"id":"use_cases/more/agents/agent_simulations/characters","title":"Generative Agents in LangChain","description":"This notebook implements a generative agent based on the paper Generative Agents: Interactive Simulacra of Human Behavior by Park, et. al.","sidebar":"use_cases"},"use_cases/more/agents/agent_simulations/gymnasium":{"id":"use_cases/more/agents/agent_simulations/gymnasium","title":"Simulated Environment: Gymnasium","description":"For many applications of LLM agents, the environment is real (internet, database, REPL, etc). However, we can also define agents to interact in simulated environments like text-based games. This is an example of how to create a simple agent-environment interaction loop with Gymnasium (formerly OpenAI Gym).","sidebar":"use_cases"},"use_cases/more/agents/agent_simulations/index":{"id":"use_cases/more/agents/agent_simulations/index","title":"Agent simulations","description":"Agent simulations involve interacting one or more agents with each other.","sidebar":"use_cases"},"use_cases/more/agents/agent_simulations/multi_player_dnd":{"id":"use_cases/more/agents/agent_simulations/multi_player_dnd","title":"Multi-Player Dungeons & Dragons","description":"This notebook shows how the DialogueAgent and DialogueSimulator class make it easy to extend the Two-Player Dungeons & Dragons example to multiple players.","sidebar":"use_cases"},"use_cases/more/agents/agent_simulations/multiagent_authoritarian":{"id":"use_cases/more/agents/agent_simulations/multiagent_authoritarian","title":"Multi-agent authoritarian speaker selection","description":"This notebook showcases how to implement a multi-agent simulation where a privileged agent decides who to speak.","sidebar":"use_cases"},"use_cases/more/agents/agent_simulations/multiagent_bidding":{"id":"use_cases/more/agents/agent_simulations/multiagent_bidding","title":"Multi-agent decentralized speaker selection","description":"This notebook showcases how to implement a multi-agent simulation without a fixed schedule for who speaks when. Instead the agents decide for themselves who speaks. We can implement this by having each agent bid to speak. Whichever agent\'s bid is the highest gets to speak.","sidebar":"use_cases"},"use_cases/more/agents/agent_simulations/petting_zoo":{"id":"use_cases/more/agents/agent_simulations/petting_zoo","title":"Multi-Agent Simulated Environment: Petting Zoo","description":"In this example, we show how to define multi-agent simulations with simulated environments. Like ours single-agent example with Gymnasium, we create an agent-environment loop with an externally defined environment. The main difference is that we now implement this kind of interaction loop with multiple agents instead. We will use the Petting Zoo library, which is the multi-agent counterpart to Gymnasium.","sidebar":"use_cases"},"use_cases/more/agents/agent_simulations/two_agent_debate_tools":{"id":"use_cases/more/agents/agent_simulations/two_agent_debate_tools","title":"Agent Debates with Tools","description":"This example shows how to simulate multi-agent dialogues where agents have access to tools.","sidebar":"use_cases"},"use_cases/more/agents/agent_simulations/two_player_dnd":{"id":"use_cases/more/agents/agent_simulations/two_player_dnd","title":"Two-Player Dungeons & Dragons","description":"In this notebook, we show how we can use concepts from CAMEL to simulate a role-playing game with a protagonist and a dungeon master. To simulate this game, we create an DialogueSimulator class that coordinates the dialogue between the two agents.","sidebar":"use_cases"},"use_cases/more/agents/agents":{"id":"use_cases/more/agents/agents","title":"Agents","description":"Open In Collab","sidebar":"use_cases"},"use_cases/more/agents/agents/camel_role_playing":{"id":"use_cases/more/agents/agents/camel_role_playing","title":"CAMEL Role-Playing Autonomous Cooperative Agents","description":"This is a langchain implementation of paper Communicative Agents for \u201cMind\u201d Exploration of Large Scale Language Model Society\\".","sidebar":"use_cases"},"use_cases/more/agents/agents/custom_agent_with_plugin_retrieval":{"id":"use_cases/more/agents/agents/custom_agent_with_plugin_retrieval","title":"Custom Agent with PlugIn Retrieval","description":"This notebook combines two concepts in order to build a custom agent that can interact with AI Plugins:","sidebar":"use_cases"},"use_cases/more/agents/agents/custom_agent_with_plugin_retrieval_using_plugnplai":{"id":"use_cases/more/agents/agents/custom_agent_with_plugin_retrieval_using_plugnplai","title":"Plug-and-Plai","description":"This notebook builds upon the idea of plugin retrieval, but pulls all tools from plugnplai - a directory of AI Plugins.","sidebar":"use_cases"},"use_cases/more/agents/agents/index":{"id":"use_cases/more/agents/agents/index","title":"Agents","description":"Agents can be used for a variety of tasks.","sidebar":"use_cases"},"use_cases/more/agents/agents/sales_agent_with_context":{"id":"use_cases/more/agents/agents/sales_agent_with_context","title":"SalesGPT - Your Context-Aware AI Sales Assistant With Knowledge Base","description":"This notebook demonstrates an implementation of a Context-Aware AI Sales agent with a Product Knowledge Base.","sidebar":"use_cases"},"use_cases/more/agents/agents/wikibase_agent":{"id":"use_cases/more/agents/agents/wikibase_agent","title":"Wikibase Agent","description":"This notebook demonstrates a very simple wikibase agent that uses sparql generation. Although this code is intended to work against any","sidebar":"use_cases"},"use_cases/more/agents/autonomous_agents/autogpt":{"id":"use_cases/more/agents/autonomous_agents/autogpt","title":"AutoGPT","description":"Implementation of https://github.com/Significant-Gravitas/Auto-GPT but with LangChain primitives (LLMs, PromptTemplates, VectorStores, Embeddings, Tools)","sidebar":"use_cases"},"use_cases/more/agents/autonomous_agents/baby_agi":{"id":"use_cases/more/agents/autonomous_agents/baby_agi","title":"BabyAGI User Guide","description":"This notebook demonstrates how to implement BabyAGI by Yohei Nakajima. BabyAGI is an AI agent that can generate and pretend to execute tasks based on a given objective.","sidebar":"use_cases"},"use_cases/more/agents/autonomous_agents/baby_agi_with_agent":{"id":"use_cases/more/agents/autonomous_agents/baby_agi_with_agent","title":"BabyAGI with Tools","description":"This notebook builds on top of baby agi, but shows how you can swap out the execution chain. The previous execution chain was just an LLM which made stuff up. By swapping it out with an agent that has access to tools, we can hopefully get real reliable information","sidebar":"use_cases"},"use_cases/more/agents/autonomous_agents/hugginggpt":{"id":"use_cases/more/agents/autonomous_agents/hugginggpt","title":"HuggingGPT","description":"Implementation of HuggingGPT. HuggingGPT is a system to connect LLMs (ChatGPT) with ML community (Hugging Face).","sidebar":"use_cases"},"use_cases/more/agents/autonomous_agents/index":{"id":"use_cases/more/agents/autonomous_agents/index","title":"Autonomous (long-running) agents","description":"Autonomous Agents are agents that designed to be more long running.","sidebar":"use_cases"},"use_cases/more/agents/autonomous_agents/marathon_times":{"id":"use_cases/more/agents/autonomous_agents/marathon_times","title":"marathon_times","description":"AutoGPT example finding Winning Marathon Times","sidebar":"use_cases"},"use_cases/more/agents/autonomous_agents/meta_prompt":{"id":"use_cases/more/agents/autonomous_agents/meta_prompt","title":"Meta-Prompt","description":"This is a LangChain implementation of Meta-Prompt, by Noah Goodman, for building self-improving agents.","sidebar":"use_cases"},"use_cases/more/agents/multi_modal/multi_modal_output_agent":{"id":"use_cases/more/agents/multi_modal/multi_modal_output_agent","title":"Multi-modal outputs: Image & Text","description":"This notebook shows how non-text producing tools can be used to create multi-modal agents.","sidebar":"use_cases"},"use_cases/more/code_writing/cpal":{"id":"use_cases/more/code_writing/cpal","title":"Causal program-aided language (CPAL) chain","description":"The CPAL chain builds on the recent PAL to stop LLM hallucination. The problem with the PAL approach is that it hallucinates on a math problem with a nested chain of dependence. The innovation here is that this new CPAL approach includes causal structure to fix hallucination.","sidebar":"use_cases"},"use_cases/more/code_writing/index":{"id":"use_cases/more/code_writing/index","title":"Code writing","description":"All program-writing chains should be treated as VERY experimental and should not be used in any environment where sensitive/important data is stored, as there is arbitrary code execution involved in using these.","sidebar":"use_cases"},"use_cases/more/code_writing/llm_bash":{"id":"use_cases/more/code_writing/llm_bash","title":"Bash chain","description":"This notebook showcases using LLMs and a bash process to perform simple filesystem commands.","sidebar":"use_cases"},"use_cases/more/code_writing/llm_math":{"id":"use_cases/more/code_writing/llm_math","title":"Math chain","description":"This notebook showcases using LLMs and Python REPLs to do complex word math problems.","sidebar":"use_cases"},"use_cases/more/code_writing/llm_symbolic_math":{"id":"use_cases/more/code_writing/llm_symbolic_math","title":"LLM Symbolic Math","description":"This notebook showcases using LLMs and Python to Solve Algebraic Equations. Under the hood is makes use of SymPy.","sidebar":"use_cases"},"use_cases/more/code_writing/pal":{"id":"use_cases/more/code_writing/pal","title":"Program-aided language model (PAL) chain","description":"Implements Program-Aided Language Models, as in https://arxiv.org/pdf/2211.10435.pdf.","sidebar":"use_cases"},"use_cases/more/graph/diffbot_graphtransformer":{"id":"use_cases/more/graph/diffbot_graphtransformer","title":"Diffbot Graph Transformer","description":"Open In Collab","sidebar":"use_cases"},"use_cases/more/graph/graph_arangodb_qa":{"id":"use_cases/more/graph/graph_arangodb_qa","title":"ArangoDB QA chain","description":"Open In Collab","sidebar":"use_cases"},"use_cases/more/graph/graph_cypher_qa":{"id":"use_cases/more/graph/graph_cypher_qa","title":"Neo4j DB QA chain","description":"This notebook shows how to use LLMs to provide a natural language interface to a graph database you can query with the Cypher query language.","sidebar":"use_cases"},"use_cases/more/graph/graph_falkordb_qa":{"id":"use_cases/more/graph/graph_falkordb_qa","title":"FalkorDBQAChain","description":"This notebook shows how to use LLMs to provide a natural language interface to FalkorDB database.","sidebar":"use_cases"},"use_cases/more/graph/graph_hugegraph_qa":{"id":"use_cases/more/graph/graph_hugegraph_qa","title":"HugeGraph QA Chain","description":"This notebook shows how to use LLMs to provide a natural language interface to HugeGraph database.","sidebar":"use_cases"},"use_cases/more/graph/graph_kuzu_qa":{"id":"use_cases/more/graph/graph_kuzu_qa","title":"KuzuQAChain","description":"This notebook shows how to use LLMs to provide a natural language interface to K\xf9zu database.","sidebar":"use_cases"},"use_cases/more/graph/graph_memgraph_qa":{"id":"use_cases/more/graph/graph_memgraph_qa","title":"Memgraph QA chain","description":"This notebook shows how to use LLMs to provide a natural language interface to a Memgraph database. To complete this tutorial, you will need Docker and Python 3.x installed.","sidebar":"use_cases"},"use_cases/more/graph/graph_nebula_qa":{"id":"use_cases/more/graph/graph_nebula_qa","title":"NebulaGraphQAChain","description":"This notebook shows how to use LLMs to provide a natural language interface to NebulaGraph database.","sidebar":"use_cases"},"use_cases/more/graph/graph_qa":{"id":"use_cases/more/graph/graph_qa","title":"Graph QA","description":"This notebook goes over how to do question answering over a graph data structure.","sidebar":"use_cases"},"use_cases/more/graph/graph_sparql_qa":{"id":"use_cases/more/graph/graph_sparql_qa","title":"GraphSparqlQAChain","description":"Graph databases are an excellent choice for applications based on network-like models. To standardize the syntax and semantics of such graphs, the W3C recommends Semantic Web Technologies, cp. Semantic Web. SPARQL serves as a query language analogously to SQL or Cypher for these graphs. This notebook demonstrates the application of LLMs as a natural language interface to a graph database by generating SPARQL.\\\\","sidebar":"use_cases"},"use_cases/more/graph/index":{"id":"use_cases/more/graph/index","title":"Analyzing graph data","description":"Graph databases give us a powerful way to represent and query real-world relationships. There are a number of chains that make it easy to use LLMs to interact with various graph DBs.","sidebar":"use_cases"},"use_cases/more/graph/neptune_cypher_qa":{"id":"use_cases/more/graph/neptune_cypher_qa","title":"Neptune Open Cypher QA Chain","description":"This QA chain queries Neptune graph database using openCypher and returns human readable response","sidebar":"use_cases"},"use_cases/more/graph/tot":{"id":"use_cases/more/graph/tot","title":"Tree of Thought (ToT) example","description":"The Tree of Thought (ToT) is a chain that allows you to query a Large Language Model (LLM) using the Tree of Thought technique. This is based on the paper \\"Large Language Model Guided Tree-of-Thought\\"","sidebar":"use_cases"},"use_cases/more/self_check/index":{"id":"use_cases/more/self_check/index","title":"Self-checking","description":"One of the main issues with using LLMs is that they can often hallucinate and make false claims. One of the surprisingly effective ways to remediate this is to use the LLM itself to check its own answers.","sidebar":"use_cases"},"use_cases/more/self_check/llm_checker":{"id":"use_cases/more/self_check/llm_checker","title":"Self-checking chain","description":"This notebook showcases how to use LLMCheckerChain.","sidebar":"use_cases"},"use_cases/more/self_check/llm_summarization_checker":{"id":"use_cases/more/self_check/llm_summarization_checker","title":"Summarization checker chain","description":"This notebook shows some examples of LLMSummarizationCheckerChain in use with different types of texts.  It has a few distinct differences from the LLMCheckerChain, in that it doesn\'t have any assumptions to the format of the input text (or summary).","sidebar":"use_cases"},"use_cases/more/self_check/smart_llm":{"id":"use_cases/more/self_check/smart_llm","title":"How to use a SmartLLMChain","description":"A SmartLLMChain is a form of self-critique chain that can help you if have particularly complex questions to answer. Instead of doing a single LLM pass, it instead performs these 3 steps:","sidebar":"use_cases"},"use_cases/qa_structured/integrations/elasticsearch":{"id":"use_cases/qa_structured/integrations/elasticsearch","title":"Elasticsearch","description":"Open In Collab","sidebar":"use_cases"},"use_cases/qa_structured/integrations/myscale_vector_sql":{"id":"use_cases/qa_structured/integrations/myscale_vector_sql","title":"Vector SQL Retriever with MyScale","description":"MyScale is an integrated vector database. You can access your database in SQL and also from here, LangChain. MyScale can make a use of various data types and functions for filters. It will boost up your LLM app no matter if you are scaling up your data or expand your system to broader application.","sidebar":"use_cases"},"use_cases/qa_structured/sql":{"id":"use_cases/qa_structured/sql","title":"SQL","description":"Open In Collab","sidebar":"use_cases"},"use_cases/question_answering/how_to/analyze_document":{"id":"use_cases/question_answering/how_to/analyze_document","title":"Analyze Document","description":"The AnalyzeDocumentChain can be used as an end-to-end to chain. This chain takes in a single document, splits it up, and then runs it through a CombineDocumentsChain.","sidebar":"use_cases"},"use_cases/question_answering/how_to/chat_vector_db":{"id":"use_cases/question_answering/how_to/chat_vector_db","title":"Store and reference chat history","description":"The ConversationalRetrievalQA chain builds on RetrievalQAChain to provide a chat history component.","sidebar":"use_cases"},"use_cases/question_answering/how_to/code/code-analysis-deeplake":{"id":"use_cases/question_answering/how_to/code/code-analysis-deeplake","title":"Use LangChain, GPT and Activeloop\'s Deep Lake to work with code base","description":"In this tutorial, we are going to use Langchain + Activeloop\'s Deep Lake with GPT to analyze the code base of the LangChain itself.","sidebar":"use_cases"},"use_cases/question_answering/how_to/code/index":{"id":"use_cases/question_answering/how_to/code/index","title":"Code understanding","description":"Overview","sidebar":"use_cases"},"use_cases/question_answering/how_to/code/twitter-the-algorithm-analysis-deeplake":{"id":"use_cases/question_answering/how_to/code/twitter-the-algorithm-analysis-deeplake","title":"Analysis of Twitter the-algorithm source code with LangChain, GPT4 and Activeloop\'s Deep Lake","description":"In this tutorial, we are going to use Langchain + Activeloop\'s Deep Lake with GPT4 to analyze the code base of the twitter algorithm.","sidebar":"use_cases"},"use_cases/question_answering/how_to/conversational_retrieval_agents":{"id":"use_cases/question_answering/how_to/conversational_retrieval_agents","title":"Conversational Retrieval Agent","description":"This is an agent specifically optimized for doing retrieval when necessary and also holding a conversation.","sidebar":"use_cases"},"use_cases/question_answering/how_to/document-context-aware-QA":{"id":"use_cases/question_answering/how_to/document-context-aware-QA","title":"Perform context-aware text splitting","description":"Text splitting for vector storage often uses sentences or other delimiters to keep related text together.","sidebar":"use_cases"},"use_cases/question_answering/how_to/flare":{"id":"use_cases/question_answering/how_to/flare","title":"Retrieve as you generate with FLARE","description":"This notebook is an implementation of Forward-Looking Active REtrieval augmented generation (FLARE).","sidebar":"use_cases"},"use_cases/question_answering/how_to/hyde":{"id":"use_cases/question_answering/how_to/hyde","title":"Improve document indexing with HyDE","description":"This notebook goes over how to use Hypothetical Document Embeddings (HyDE), as described in this paper.","sidebar":"use_cases"},"use_cases/question_answering/how_to/local_retrieval_qa":{"id":"use_cases/question_answering/how_to/local_retrieval_qa","title":"Use local LLMs","description":"The popularity of projects like PrivateGPT, llama.cpp, and GPT4All underscore the importance of running LLMs locally.","sidebar":"use_cases"},"use_cases/question_answering/how_to/multi_retrieval_qa_router":{"id":"use_cases/question_answering/how_to/multi_retrieval_qa_router","title":"Dynamically select from multiple retrievers","description":"This notebook demonstrates how to use the RouterChain paradigm to create a chain that dynamically selects which Retrieval system to use. Specifically we show how to use the MultiRetrievalQAChain to create a question-answering chain that selects the retrieval QA chain which is most relevant for a given question, and then answers the question using it.","sidebar":"use_cases"},"use_cases/question_answering/how_to/multiple_retrieval":{"id":"use_cases/question_answering/how_to/multiple_retrieval","title":"Multiple Retrieval Sources","description":"Often times you may want to do retrieval over multiple sources. These can be different vectorstores (where one contains information about topic X and the other contains info about topic Y). They could also be completely different databases altogether!","sidebar":"use_cases"},"use_cases/question_answering/how_to/qa_citations":{"id":"use_cases/question_answering/how_to/qa_citations","title":"Cite sources","description":"This notebook shows how to use OpenAI functions ability to extract citations from text.","sidebar":"use_cases"},"use_cases/question_answering/how_to/question_answering":{"id":"use_cases/question_answering/how_to/question_answering","title":"QA over in-memory documents","description":"Here we walk through how to use LangChain for question answering over a list of documents. Under the hood we\'ll be using our Document chains.","sidebar":"use_cases"},"use_cases/question_answering/how_to/vector_db_qa":{"id":"use_cases/question_answering/how_to/vector_db_qa","title":"QA using a Retriever","description":"This example showcases question answering over an index.","sidebar":"use_cases"},"use_cases/question_answering/how_to/vector_db_text_generation":{"id":"use_cases/question_answering/how_to/vector_db_text_generation","title":"Retrieve from vector stores directly","description":"This notebook walks through how to use LangChain for text generation over a vector index. This is useful if we want to generate text that is able to draw from a large body of custom text, for example, generating blog posts that have an understanding of previous blog posts written, or product tutorials that can refer to product documentation.","sidebar":"use_cases"},"use_cases/question_answering/integrations/openai_functions_retrieval_qa":{"id":"use_cases/question_answering/integrations/openai_functions_retrieval_qa","title":"Structure answers with OpenAI functions","description":"OpenAI functions allows for structuring of response output. This is often useful in question answering when you want to not only get the final answer but also supporting evidence, citations, etc.","sidebar":"use_cases"},"use_cases/question_answering/integrations/semantic-search-over-chat":{"id":"use_cases/question_answering/integrations/semantic-search-over-chat","title":"QA using Activeloop\'s DeepLake","description":"In this tutorial, we are going to use Langchain + Activeloop\'s Deep Lake with GPT4 to semantically search and ask questions over a group chat.","sidebar":"use_cases"},"use_cases/question_answering/question_answering":{"id":"use_cases/question_answering/question_answering","title":"Question Answering","description":"Open In Collab","sidebar":"use_cases"},"use_cases/summarization":{"id":"use_cases/summarization","title":"Summarization","description":"Open In Collab","sidebar":"use_cases"},"use_cases/tagging":{"id":"use_cases/tagging","title":"Tagging","description":"Open In Collab","sidebar":"use_cases"},"use_cases/web_scraping":{"id":"use_cases/web_scraping","title":"Web scraping","description":"Open In Collab","sidebar":"use_cases"}}}')}}]);