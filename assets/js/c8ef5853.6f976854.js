"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[61042],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>h});var r=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var i=r.createContext({}),l=function(e){var t=r.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},d=function(e){var t=l(e.components);return r.createElement(i.Provider,{value:t},e.children)},p="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,i=e.parentName,d=c(e,["components","mdxType","originalType","parentName"]),p=l(n),m=a,h=p["".concat(i,".").concat(m)]||p[m]||u[m]||o;return n?r.createElement(h,s(s({ref:t},d),{},{components:n})):r.createElement(h,s({ref:t},d))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,s=new Array(o);s[0]=m;var c={};for(var i in t)hasOwnProperty.call(t,i)&&(c[i]=t[i]);c.originalType=e,c[p]="string"==typeof e?e:a,s[1]=c;for(var l=2;l<o;l++)s[l]=n[l];return r.createElement.apply(null,s)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},22743:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>i,contentTitle:()=>s,default:()=>h,frontMatter:()=>o,metadata:()=>c,toc:()=>l});var r=n(87462),a=(n(67294),n(3905));const o={},s="StarRocks",c={unversionedId:"integrations/vectorstores/starrocks",id:"integrations/vectorstores/starrocks",title:"StarRocks",description:"StarRocks is a High-Performance Analytical Database.",source:"@site/docs/integrations/vectorstores/starrocks.md",sourceDirName:"integrations/vectorstores",slug:"/integrations/vectorstores/starrocks",permalink:"/langchain/docs/integrations/vectorstores/starrocks",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"sqlite-vss",permalink:"/langchain/docs/integrations/vectorstores/sqlitevss"},next:{title:"Supabase (Postgres)",permalink:"/langchain/docs/integrations/vectorstores/supabase"}},i={},l=[{value:"Setup",id:"setup",level:2},{value:"Load docs and split them into tokens",id:"load-docs-and-split-them-into-tokens",level:2},{value:"Create vectordb instance",id:"create-vectordb-instance",level:2},{value:"Use StarRocks as vectordb",id:"use-starrocks-as-vectordb",level:3},{value:"Convert tokens into embeddings and put them into vectordb",id:"convert-tokens-into-embeddings-and-put-them-into-vectordb",level:2},{value:"Build QA and ask question to it",id:"build-qa-and-ask-question-to-it",level:2}],d=(p="CodeOutputBlock",function(e){return console.warn("Component "+p+" was not imported, exported, or provided by MDXProvider as global scope"),(0,a.kt)("div",e)});var p;const u={toc:l},m="wrapper";function h(e){let{components:t,...n}=e;return(0,a.kt)(m,(0,r.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"starrocks"},"StarRocks"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},(0,a.kt)("a",{parentName:"p",href:"https://www.starrocks.io/"},"StarRocks")," is a High-Performance Analytical Database.\n",(0,a.kt)("inlineCode",{parentName:"p"},"StarRocks")," is a next-gen sub-second MPP database for full analytics scenarios, including multi-dimensional analytics, real-time analytics and ad-hoc query.")),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Usually ",(0,a.kt)("inlineCode",{parentName:"p"},"StarRocks")," is categorized into OLAP, and it has showed excellent performance in ",(0,a.kt)("a",{parentName:"p",href:"https://benchmark.clickhouse.com/"},"ClickBench \u2014 a Benchmark For Analytical DBMS"),". Since it has a super-fast vectorized execution engine, it could also be used as a fast vectordb.")),(0,a.kt)("p",null,"Here we'll show how to use the StarRocks Vector Store."),(0,a.kt)("h2",{id:"setup"},"Setup"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"#!pip install pymysql\n")),(0,a.kt)("p",null,"Set ",(0,a.kt)("inlineCode",{parentName:"p"},"update_vectordb = False")," at the beginning. If there is no docs updated, then we don't need to rebuild the embeddings of docs"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\x3c!--IMPORTS:[{"imported": "OpenAIEmbeddings", "source": "langchain.embeddings.openai", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html", "title": "StarRocks"}, {"imported": "StarRocks", "source": "langchain.vectorstores", "docs": "https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.starrocks.StarRocks.html", "title": "StarRocks"}, {"imported": "StarRocksSettings", "source": "langchain.vectorstores.starrocks", "docs": "https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.starrocks.StarRocksSettings.html", "title": "StarRocks"}, {"imported": "Chroma", "source": "langchain.vectorstores", "docs": "https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.chroma.Chroma.html", "title": "StarRocks"}, {"imported": "CharacterTextSplitter", "source": "langchain.text_splitter", "docs": "https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.CharacterTextSplitter.html", "title": "StarRocks"}, {"imported": "TokenTextSplitter", "source": "langchain.text_splitter", "docs": "https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.TokenTextSplitter.html", "title": "StarRocks"}, {"imported": "DirectoryLoader", "source": "langchain.document_loaders", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.directory.DirectoryLoader.html", "title": "StarRocks"}, {"imported": "RetrievalQA", "source": "langchain.chains", "docs": "https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html", "title": "StarRocks"}, {"imported": "TextLoader", "source": "langchain.document_loaders", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.text.TextLoader.html", "title": "StarRocks"}, {"imported": "UnstructuredMarkdownLoader", "source": "langchain.document_loaders", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain.document_loaders.markdown.UnstructuredMarkdownLoader.html", "title": "StarRocks"}]--\x3e\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.vectorstores import StarRocks\nfrom langchain.vectorstores.starrocks import StarRocksSettings\nfrom langchain.vectorstores import Chroma\nfrom langchain.text_splitter import CharacterTextSplitter, TokenTextSplitter\nfrom langchain import OpenAI, VectorDBQA\nfrom langchain.document_loaders import DirectoryLoader\nfrom langchain.chains import RetrievalQA\nfrom langchain.document_loaders import TextLoader, UnstructuredMarkdownLoader\n\nupdate_vectordb = False\n')),(0,a.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    /Users/dirlt/utils/py3env/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.1.0)/charset_normalizer (2.0.9) doesn't match a supported version!\n      warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"))),(0,a.kt)("h2",{id:"load-docs-and-split-them-into-tokens"},"Load docs and split them into tokens"),(0,a.kt)("p",null,"Load all markdown files under the ",(0,a.kt)("inlineCode",{parentName:"p"},"docs")," directory"),(0,a.kt)("p",null,"for starrocks documents, you can clone repo from ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/StarRocks/starrocks"},"https://github.com/StarRocks/starrocks"),", and there is ",(0,a.kt)("inlineCode",{parentName:"p"},"docs")," directory in it."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'loader = DirectoryLoader(\n    "./docs", glob="**/*.md", loader_cls=UnstructuredMarkdownLoader\n)\ndocuments = loader.load()\n')),(0,a.kt)("p",null,"Split docs into tokens, and set ",(0,a.kt)("inlineCode",{parentName:"p"},"update_vectordb = True")," because there are new docs/tokens."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"# load text splitter and split docs into snippets of text\ntext_splitter = TokenTextSplitter(chunk_size=400, chunk_overlap=50)\nsplit_docs = text_splitter.split_documents(documents)\n\n# tell vectordb to update text embeddings\nupdate_vectordb = True\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"split_docs[-20]\n")),(0,a.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    Document(page_content='Compile StarRocks with Docker\\n\\nThis topic describes how to compile StarRocks using Docker.\\n\\nOverview\\n\\nStarRocks provides development environment images for both Ubuntu 22.04 and CentOS 7.9. With the image, you can launch a Docker container and compile StarRocks in the container.\\n\\nStarRocks version and DEV ENV image\\n\\nDifferent branches of StarRocks correspond to different development environment images provided on StarRocks Docker Hub.\\n\\nFor Ubuntu 22.04:\\n\\n| Branch name | Image name              |\\n  | --------------- | ----------------------------------- |\\n  | main            | starrocks/dev-env-ubuntu:latest     |\\n  | branch-3.0      | starrocks/dev-env-ubuntu:3.0-latest |\\n  | branch-2.5      | starrocks/dev-env-ubuntu:2.5-latest |\\n\\nFor CentOS 7.9:\\n\\n| Branch name | Image name                       |\\n  | --------------- | ------------------------------------ |\\n  | main            | starrocks/dev-env-centos7:latest     |\\n  | branch-3.0      | starrocks/dev-env-centos7:3.0-latest |\\n  | branch-2.5      | starrocks/dev-env-centos7:2.5-latest |\\n\\nPrerequisites\\n\\nBefore compiling StarRocks, make sure the following requirements are satisfied:\\n\\nHardware\\n\\n', metadata={'source': 'docs/developers/build-starrocks/Build_in_docker.md'})\n"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'print("# docs  = %d, # splits = %d" % (len(documents), len(split_docs)))\n')),(0,a.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    # docs  = 657, # splits = 2802\n"))),(0,a.kt)("h2",{id:"create-vectordb-instance"},"Create vectordb instance"),(0,a.kt)("h3",{id:"use-starrocks-as-vectordb"},"Use StarRocks as vectordb"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"def gen_starrocks(update_vectordb, embeddings, settings):\n    if update_vectordb:\n        docsearch = StarRocks.from_documents(split_docs, embeddings, config=settings)\n    else:\n        docsearch = StarRocks(embeddings, settings)\n    return docsearch\n")),(0,a.kt)("h2",{id:"convert-tokens-into-embeddings-and-put-them-into-vectordb"},"Convert tokens into embeddings and put them into vectordb"),(0,a.kt)("p",null,"Here we use StarRocks as vectordb, you can configure StarRocks instance via ",(0,a.kt)("inlineCode",{parentName:"p"},"StarRocksSettings"),"."),(0,a.kt)("p",null,"Configuring StarRocks instance is pretty much like configuring mysql instance. You need to specify:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"host/port"),(0,a.kt)("li",{parentName:"ol"},"username(default: 'root')"),(0,a.kt)("li",{parentName:"ol"},"password(default: '')"),(0,a.kt)("li",{parentName:"ol"},"database(default: 'default')"),(0,a.kt)("li",{parentName:"ol"},"table(default: 'langchain')")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'embeddings = OpenAIEmbeddings()\n\n# configure starrocks settings(host/port/user/pw/db)\nsettings = StarRocksSettings()\nsettings.port = 41003\nsettings.host = "127.0.0.1"\nsettings.username = "root"\nsettings.password = ""\nsettings.database = "zya"\ndocsearch = gen_starrocks(update_vectordb, embeddings, settings)\n\nprint(docsearch)\n\nupdate_vectordb = False\n')),(0,a.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"    Inserting data...: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2802/2802 [02:26<00:00, 19.11it/s]\n\n\n    zya.langchain @ 127.0.0.1:41003\n    \n    username: root\n    \n    Table Schema:\n    ----------------------------------------------------------------------------\n    |name                    |type                    |key                     |\n    ----------------------------------------------------------------------------\n    |id                      |varchar(65533)          |true                    |\n    |document                |varchar(65533)          |false                   |\n    |embedding               |array<float>            |false                   |\n    |metadata                |varchar(65533)          |false                   |\n    ----------------------------------------------------------------------------\n    \n"))),(0,a.kt)("h2",{id:"build-qa-and-ask-question-to-it"},"Build QA and ask question to it"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'llm = OpenAI()\nqa = RetrievalQA.from_chain_type(\n    llm=llm, chain_type="stuff", retriever=docsearch.as_retriever()\n)\nquery = "is profile enabled by default? if not, how to enable profile?"\nresp = qa.run(query)\nprint(resp)\n')),(0,a.kt)(d,{lang:"python",mdxType:"CodeOutputBlock"},(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"     No, profile is not enabled by default. To enable profile, set the variable `enable_profile` to `true` using the command `set enable_profile = true;`\n"))))}h.isMDXComponent=!0}}]);