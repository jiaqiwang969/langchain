<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-integrations/tools/searx_search">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.0">
<title data-rh="true">SearxNG Search | ü¶úÔ∏èüîó Langchain</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jiaqiwang969.github.io/langchain/img/parrot-chainlink-icon.png"><meta data-rh="true" name="twitter:image" content="https://jiaqiwang969.github.io/langchain/img/parrot-chainlink-icon.png"><meta data-rh="true" property="og:url" content="https://jiaqiwang969.github.io/langchain/docs/integrations/tools/searx_search"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="SearxNG Search | ü¶úÔ∏èüîó Langchain"><meta data-rh="true" name="description" content="This notebook goes over how to use a self hosted SearxNG search API to search the web."><meta data-rh="true" property="og:description" content="This notebook goes over how to use a self hosted SearxNG search API to search the web."><link data-rh="true" rel="icon" href="/langchain/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://jiaqiwang969.github.io/langchain/docs/integrations/tools/searx_search"><link data-rh="true" rel="alternate" href="https://jiaqiwang969.github.io/langchain/docs/integrations/tools/searx_search" hreflang="en"><link data-rh="true" rel="alternate" href="https://jiaqiwang969.github.io/langchain/docs/integrations/tools/searx_search" hreflang="x-default"><link rel="stylesheet" href="/langchain/assets/css/styles.b9396054.css">
<link rel="preload" href="/langchain/assets/js/runtime~main.a20b23d6.js" as="script">
<link rel="preload" href="/langchain/assets/js/main.af9852a9.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/langchain/"><b class="navbar__title text--truncate">ü¶úÔ∏èüîó LangChain</b></a><a class="navbar__item navbar__link" href="/langchain/docs/get_started/introduction">Docs</a><a class="navbar__item navbar__link" href="/langchain/docs/use_cases">Use cases</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/langchain/docs/integrations">Integrations</a><a href="https://api.python.langchain.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://smith.langchain.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">LangSmith</a><a href="https://js.langchain.com/docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">JS/TS Docs</a><a href="https://github.com/hwchase17/langchain" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="mendable-search"><button class="ms-global search-btn__input ms-m-0 ms-flex ms-h-10 ms-w-full ms-flex-row ms-items-center ms-justify-between ms-gap-2 ms-rounded-xl ms-bg-gray-50 ms-p-1 ms-pl-2 ms-pr-1 ms-shadow ms-outline-none ms-ring-0 ms-transition-all hover:ms-cursor-pointer hover:ms-shadow-md sm:ms-p-2 sm:ms-pl-4 sm:ms-pr-2"><div class="ms-global search-btn__input-container ms-flex ms-w-full ms-min-w-0 ms-items-center ms-gap-1"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="search-btn__icon hover:fill-white ms-h-5 ms-w-5 ms-fill-gray-400 ms-text-gray-400 hover:ms-text-white focus:ms-fill-white focus:ms-text-white sm:ms-h-6 sm:ms-w-6" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0z"></path><path d="M15.5 14h-.79l-.28-.27A6.471 6.471 0 0016 9.5 6.5 6.5 0 109.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"></path></svg><input readonly="" id="userInput" name="userInput" maxlength="512" placeholder="Search..." class="ms-global search-btn__input ms-w-full ms-flex-grow ms-truncate ms-bg-transparent ms-text-sm ms-outline-none ms-ring-0 ms-ring-transparent hover:ms-cursor-text focus:ms-outline-none focus:ms-ring-0 focus:ms-ring-transparent sm:ms-text-base"></div><div class="search-btn__shortcut ms-z-10 ms-flex ms-flex-row ms-items-center ms-gap-1 ms-rounded-lg ms-border ms-py-[2px] ms-px-[8px] ms-text-xs ms-text-gray-400 ms-transition-all disabled:ms-bg-opacity-10"><span>CTRL</span><span>K</span></div></button><div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--active" href="/langchain/docs/integrations">Integrations</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/callbacks/">Callbacks</a><button aria-label="Toggle the collapsible sidebar category &#x27;Callbacks&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/chat/">Chat models</a><button aria-label="Toggle the collapsible sidebar category &#x27;Chat models&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/chat_loaders/">Chat loaders</a><button aria-label="Toggle the collapsible sidebar category &#x27;Chat loaders&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/document_loaders/">Document loaders</a><button aria-label="Toggle the collapsible sidebar category &#x27;Document loaders&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/document_transformers/">Document transformers</a><button aria-label="Toggle the collapsible sidebar category &#x27;Document transformers&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/llms/">LLMs</a><button aria-label="Toggle the collapsible sidebar category &#x27;LLMs&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/memory/">Memory</a><button aria-label="Toggle the collapsible sidebar category &#x27;Memory&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/retrievers/">Retrievers</a><button aria-label="Toggle the collapsible sidebar category &#x27;Retrievers&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/text_embedding/">Text embedding models</a><button aria-label="Toggle the collapsible sidebar category &#x27;Text embedding models&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/toolkits/">Agents &amp; Toolkits</a><button aria-label="Toggle the collapsible sidebar category &#x27;Agents &amp; Toolkits&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/langchain/docs/integrations/tools/">Tools</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tools&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/alpha_vantage">Alpha Vantage</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/apify">Apify</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/arxiv">ArXiv</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/awslambda">AWS Lambda</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/bash">Shell (bash)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/bing_search">Bing Search</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/brave_search">Brave Search</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/chatgpt_plugins">ChatGPT Plugins</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/dalle_image_generator">Dall-E Image Generator</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/dataforseo">DataForSeo</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/ddg">DuckDuckGo Search</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/edenai_tools">Eden AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/filesystem">File System</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/golden_query">Golden Query</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/google_drive">Google Drive</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/google_places">Google Places</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/google_search">Google Search</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/google_serper">Google Serper</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/gradio_tools">Gradio</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/graphql">GraphQL</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/huggingface_tools">HuggingFace Hub Tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/human_tools">Human as a tool</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/ifttt">IFTTT WebHooks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/lemonai">Lemon Agent</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/metaphor_search">Metaphor Search</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/nuclia">Nuclia Understanding</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/openweathermap">OpenWeatherMap</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/pubmed">PubMed</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/requests">Requests</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/sceneXplain">SceneXplain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/search_tools">Search Tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/langchain/docs/integrations/tools/searx_search">SearxNG Search</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/serpapi">SerpAPI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/sqlite">SQL Database Chain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/twilio">Twilio</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/wikipedia">Wikipedia</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/wolfram_alpha">Wolfram Alpha</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/yahoo_finance_news">Yahoo Finance News</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/youtube">YouTube</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/tools/zapier">Zapier Natural Language Actions</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/vectorstores/">Vector stores</a><button aria-label="Toggle the collapsible sidebar category &#x27;Vector stores&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/providers/">Grouped by provider</a><button aria-label="Toggle the collapsible sidebar category &#x27;Grouped by provider&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/langchain/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/langchain/docs/integrations"><span itemprop="name">Integrations</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/langchain/docs/integrations/tools/"><span itemprop="name">Tools</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">SearxNG Search</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>SearxNG Search</h1><p>This notebook goes over how to use a self hosted <code>SearxNG</code> search API to search the web.</p><p>You can <a href="https://docs.searxng.org/dev/search_api.html" target="_blank" rel="noopener noreferrer">check this link</a> for more informations about <code>Searx API</code> parameters.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> pprint</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">utilities </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> SearxSearchWrapper</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><h4 style="padding-left:0.65rem;margin-bottom:0.45rem">API Reference:</h4><ul style="padding-bottom:1rem"><li><a href="https://api.python.langchain.com/en/latest/utilities/langchain.utilities.searx_search.SearxSearchWrapper.html"><span>SearxSearchWrapper</span></a></li></ul></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">search </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> SearxSearchWrapper</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">searx_host</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;http://127.0.0.1:8888&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>For some engines, if a direct <code>answer</code> is available the warpper will print the answer instead of the full list of search results. You can use the <code>results</code> method of the wrapper if you want to obtain all the results.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">search</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">run</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;What is the capital of France&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    &#x27;Paris is the capital of France, the largest country of Europe with 550 000 km2 (65 millions inhabitants). Paris has 2.234 million inhabitants end 2011. She is the core of Ile de France region (12 million people).&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="custom-parameters">Custom Parameters<a href="#custom-parameters" class="hash-link" aria-label="Direct link to Custom Parameters" title="Direct link to Custom Parameters">‚Äã</a></h2><p>SearxNG supports <a href="https://docs.searxng.org/user/configured_engines.html" target="_blank" rel="noopener noreferrer">135 search engines</a>. You can also customize the Searx wrapper with arbitrary named parameters that will be passed to the Searx search API . In the below example we will making a more interesting use of custom search parameters from searx search api.</p><p>In this example we will be using the <code>engines</code> parameters to query wikipedia</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">search </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> SearxSearchWrapper</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    searx_host</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;http://127.0.0.1:8888&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> k</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">5</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># k is for max number of items</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">search</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">run</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;large language model &quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> engines</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;wiki&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    &#x27;Large language models (LLMs) represent a major advancement in AI, with the promise of transforming domains through learned knowledge. LLM sizes have been increasing 10X every year for the last few years, and as these models grow in complexity and size, so do their capabilities.\n\nGPT-3 can translate language, write essays, generate computer code, and more ‚Äî all with limited to no supervision. In July 2020, OpenAI unveiled GPT-3, a language model that was easily the largest known at the time. Put simply, GPT-3 is trained to predict the next word in a sentence, much like how a text message autocomplete feature works.\n\nA large language model, or LLM, is a deep learning algorithm that can recognize, summarize, translate, predict and generate text and other content based on knowledge gained from massive datasets. Large language models are among the most successful applications of transformer models.\n\nAll of today‚Äôs well-known language models‚Äîe.g., GPT-3 from OpenAI, PaLM or LaMDA from Google, Galactica or OPT from Meta, Megatron-Turing from Nvidia/Microsoft, Jurassic-1 from AI21 Labs‚Äîare...\n\nLarge language models (LLMs) such as GPT-3are increasingly being used to generate text. These tools should be used with care, since they can generate content that is biased, non-verifiable, constitutes original research, or violates copyrights.&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><p>Passing other Searx parameters for searx like <code>language</code></p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">search </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> SearxSearchWrapper</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">searx_host</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;http://127.0.0.1:8888&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> k</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">search</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">run</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;deep learning&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> language</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;es&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> engines</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;wiki&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    &#x27;Aprendizaje profundo (en ingl√©s, deep learning) es un conjunto de algoritmos de aprendizaje autom√°tico (en ingl√©s, machine learning) que intenta modelar abstracciones de alto nivel en datos usando arquitecturas computacionales que admiten transformaciones no lineales m√∫ltiples e iterativas de datos expresados en forma matricial o tensorial. 1&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="obtaining-results-with-metadata">Obtaining results with metadata<a href="#obtaining-results-with-metadata" class="hash-link" aria-label="Direct link to Obtaining results with metadata" title="Direct link to Obtaining results with metadata">‚Äã</a></h2><p>In this example we will be looking for scientific paper using the <code>categories</code> parameter and limiting the results to a <code>time_range</code> (not all engines support the time range option).</p><p>We also would like to obtain the results in a structured way including metadata. For this we will be using the <code>results</code> method of the wrapper.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">search </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> SearxSearchWrapper</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">searx_host</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;http://127.0.0.1:8888&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">results </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> search</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">results</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;Large Language Model prompt&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    num_results</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">5</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    categories</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;science&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    time_range</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;year&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">pprint</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">pp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">results</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    [{&#x27;snippet&#x27;: &#x27;‚Ä¶ on natural language instructions, large language models (‚Ä¶ the &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;prompt used to steer the model, and most effective prompts ‚Ä¶ to &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;prompt engineering, we propose Automatic Prompt ‚Ä¶&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Large language models are human-level prompt engineers&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://arxiv.org/abs/2211.01910&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;google scholar&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;science&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;‚Ä¶ Large language models (LLMs) have introduced new possibilities &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;for prototyping with AI [18]. Pre-trained on a large amount of &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;text data, models ‚Ä¶ language instructions called prompts. ‚Ä¶&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Promptchainer: Chaining large language model prompts through &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">               &#x27;visual programming&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://dl.acm.org/doi/abs/10.1145/3491101.3519729&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;google scholar&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;science&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;‚Ä¶ can introspect the large prompt model. We derive the view &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;œï0(X) and the model h0 from T01. However, instead of fully &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;fine-tuning T0 during co-training, we focus on soft prompt &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;tuning, ‚Ä¶&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Co-training improves prompt-based learning for large language &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">               &#x27;models&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://proceedings.mlr.press/v162/lang22a.html&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;google scholar&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;science&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;‚Ä¶ With the success of large language models (LLMs) of code and &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;their use as ‚Ä¶ prompt design process become important. In this &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;work, we propose a framework called Repo-Level Prompt ‚Ä¶&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Repository-level prompt generation for large language models of &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">               &#x27;code&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://arxiv.org/abs/2206.12839&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;google scholar&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;science&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;‚Ä¶ Figure 2 | The benefits of different components of a prompt &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;for the largest language model (Gopher), as estimated from &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;hierarchical logistic regression. Each point estimates the &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;unique ‚Ä¶&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Can language models learn from explanations in context?&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://arxiv.org/abs/2204.02329&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;google scholar&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;science&#x27;}]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><p>Get papers from arxiv</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">results </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> search</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">results</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;Large Language Model prompt&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> num_results</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">5</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> engines</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;arxiv&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">pprint</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">pp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">results</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    [{&#x27;snippet&#x27;: &#x27;Thanks to the advanced improvement of large pre-trained language &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;models, prompt-based fine-tuning is shown to be effective on a &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;variety of downstream tasks. Though many prompting methods have &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;been investigated, it remains unknown which type of prompts are &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;the most effective among three types of prompts (i.e., &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;human-designed prompts, schema prompts and null prompts). In &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;this work, we empirically compare the three types of prompts &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;under both few-shot and fully-supervised settings. Our &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;experimental results show that schema prompts are the most &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;effective in general. Besides, the performance gaps tend to &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;diminish when the scale of training data grows large.&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Do Prompts Solve NLP Tasks Using Natural Language?&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;http://arxiv.org/abs/2203.00902v1&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;arxiv&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;science&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Cross-prompt automated essay scoring (AES) requires the system &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;to use non target-prompt essays to award scores to a &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;target-prompt essay. Since obtaining a large quantity of &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;pre-graded essays to a particular prompt is often difficult and &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;unrealistic, the task of cross-prompt AES is vital for the &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;development of real-world AES systems, yet it remains an &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;under-explored area of research. Models designed for &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;prompt-specific AES rely heavily on prompt-specific knowledge &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;and perform poorly in the cross-prompt setting, whereas current &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;approaches to cross-prompt AES either require a certain quantity &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;of labelled target-prompt essays or require a large quantity of &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;unlabelled target-prompt essays to perform transfer learning in &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;a multi-step manner. To address these issues, we introduce &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;Prompt Agnostic Essay Scorer (PAES) for cross-prompt AES. Our &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;method requires no access to labelled or unlabelled &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;target-prompt data during training and is a single-stage &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;approach. PAES is easy to apply in practice and achieves &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;state-of-the-art performance on the Automated Student Assessment &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;Prize (ASAP) dataset.&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Prompt Agnostic Essay Scorer: A Domain Generalization Approach to &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">               &#x27;Cross-prompt Automated Essay Scoring&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;http://arxiv.org/abs/2008.01441v1&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;arxiv&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;science&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Research on prompting has shown excellent performance with &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;little or even no supervised training across many tasks. &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;However, prompting for machine translation is still &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;under-explored in the literature. We fill this gap by offering a &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;systematic study on prompting strategies for translation, &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;examining various factors for prompt template and demonstration &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;example selection. We further explore the use of monolingual &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;data and the feasibility of cross-lingual, cross-domain, and &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;sentence-to-document transfer learning in prompting. Extensive &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;experiments with GLM-130B (Zeng et al., 2022) as the testbed &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;show that 1) the number and the quality of prompt examples &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;matter, where using suboptimal examples degenerates translation; &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;2) several features of prompt examples, such as semantic &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;similarity, show significant Spearman correlation with their &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;prompting performance; yet, none of the correlations are strong &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;enough; 3) using pseudo parallel prompt examples constructed &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;from monolingual data via zero-shot prompting could improve &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;translation; and 4) improved performance is achievable by &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;transferring knowledge from prompt examples selected in other &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;settings. We finally provide an analysis on the model outputs &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;and discuss several problems that prompting still suffers from.&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Prompting Large Language Model for Machine Translation: A Case &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">               &#x27;Study&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;http://arxiv.org/abs/2301.07069v2&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;arxiv&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;science&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Large language models can perform new tasks in a zero-shot &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;fashion, given natural language prompts that specify the desired &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;behavior. Such prompts are typically hand engineered, but can &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;also be learned with gradient-based methods from labeled data. &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;However, it is underexplored what factors make the prompts &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;effective, especially when the prompts are natural language. In &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;this paper, we investigate common attributes shared by effective &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;prompts. We first propose a human readable prompt tuning method &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;(F LUENT P ROMPT) based on Langevin dynamics that incorporates a &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;fluency constraint to find a diverse distribution of effective &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;and fluent prompts. Our analysis reveals that effective prompts &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;are topically related to the task domain and calibrate the prior &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;probability of label words. Based on these findings, we also &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;propose a method for generating prompts using only unlabeled &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;data, outperforming strong baselines by an average of 7.0% &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;accuracy across three tasks.&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &quot;Toward Human Readable Prompt Tuning: Kubrick&#x27;s The Shining is a &quot;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">               &#x27;good movie, and a good prompt too?&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;http://arxiv.org/abs/2212.10539v1&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;arxiv&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;science&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Prevailing methods for mapping large generative language models &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &quot;to supervised tasks may fail to sufficiently probe models&#x27; novel &quot;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;capabilities. Using GPT-3 as a case study, we show that 0-shot &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;prompts can significantly outperform few-shot prompts. We &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;suggest that the function of few-shot examples in these cases is &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;better described as locating an already learned task rather than &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;meta-learning. This analysis motivates rethinking the role of &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;prompts in controlling and evaluating powerful language models. &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;In this work, we discuss methods of prompt programming, &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;emphasizing the usefulness of considering prompts through the &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;lens of natural language. We explore techniques for exploiting &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;the capacity of narratives and cultural anchors to encode &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;nuanced intentions and techniques for encouraging deconstruction &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;of a problem into components before producing a verdict. &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;Informed by this more encompassing theory of prompt programming, &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;we also introduce the idea of a metaprompt that seeds the model &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;to generate its own natural language prompts for a range of &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;tasks. Finally, we discuss how these more general methods of &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;interacting with language models can be incorporated into &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;existing and future benchmarks and practical applications.&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Prompt Programming for Large Language Models: Beyond the Few-Shot &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">               &#x27;Paradigm&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;http://arxiv.org/abs/2102.07350v1&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;arxiv&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;science&#x27;}]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><p>In this example we query for <code>large language models</code> under the <code>it</code> category. We then filter the results that come from github.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">results </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> search</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">results</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;large language model&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> num_results</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">20</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> categories</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;it&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">pprint</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">pp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token builtin" style="color:rgb(0, 112, 193)">list</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token builtin" style="color:rgb(0, 112, 193)">filter</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token keyword" style="color:rgb(0, 0, 255)">lambda</span><span class="token plain"> r</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> r</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;engines&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token number" style="color:rgb(9, 134, 88)">0</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token plain"> </span><span class="token operator" style="color:rgb(0, 0, 0)">==</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;github&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> results</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    [{&#x27;snippet&#x27;: &#x27;Guide to using pre-trained large language models of source code&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Code-LMs&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/VHellendoorn/Code-LMs&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Dramatron uses large language models to generate coherent &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;scripts and screenplays.&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;dramatron&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/deepmind/dramatron&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;}]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><p>We could also directly query for results from <code>github</code> and other source forges.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">results </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> search</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">results</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;large language model&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> num_results</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">20</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> engines</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;github&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;gitlab&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">pprint</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">pp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">results</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    [{&#x27;snippet&#x27;: &quot;Implementation of &#x27;A Watermark for Large Language Models&#x27; paper &quot;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;by Kirchenbauer &amp; Geiping et. al.&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Peutlefaire / LMWatermark&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://gitlab.com/BrianPulfer/LMWatermark&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;gitlab&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Guide to using pre-trained large language models of source code&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Code-LMs&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/VHellendoorn/Code-LMs&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Simen Burud / Large-scale Language Models for Conversational &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">               &#x27;Speech Recognition&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://gitlab.com/BrianPulfer&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;gitlab&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Dramatron uses large language models to generate coherent &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;scripts and screenplays.&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;dramatron&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/deepmind/dramatron&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Code for loralib, an implementation of &quot;LoRA: Low-Rank &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;Adaptation of Large Language Models&quot;&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;LoRA&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/microsoft/LoRA&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Code for the paper &quot;Evaluating Large Language Models Trained on &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;Code&quot;&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;human-eval&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/openai/human-eval&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;A trend starts from &quot;Chain of Thought Prompting Elicits &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;Reasoning in Large Language Models&quot;.&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Chain-of-ThoughtsPapers&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/Timothyxxx/Chain-of-ThoughtsPapers&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Mistral: A strong, northwesterly wind: Framework for transparent &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;and accessible large-scale language model training, built with &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;Hugging Face ü§ó Transformers.&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;mistral&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/stanford-crfm/mistral&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;A prize for finding tasks that cause large language models to &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;show inverse scaling&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;prize&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/inverse-scaling/prize&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Optimus: the first large-scale pre-trained VAE language model&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Optimus&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/ChunyuanLI/Optimus&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Seminar on Large Language Models (COMP790-101 at UNC Chapel &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;Hill, Fall 2022)&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;llm-seminar&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/craffel/llm-seminar&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;A central, open resource for data and tools related to &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;chain-of-thought reasoning in large language models. Developed @ &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;Samwald research group: https://samwald.info/&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;ThoughtSource&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/OpenBioLink/ThoughtSource&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;A comprehensive list of papers using large language/multi-modal &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;models for Robotics/RL, including papers, codes, and related &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;websites&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;Awesome-LLM-Robotics&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/GT-RIPL/Awesome-LLM-Robotics&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Tools for curating biomedical training data for large-scale &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;language modeling&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;biomedical&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/bigscience-workshop/biomedical&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;ChatGPT @ Home: Large Language Model (LLM) chatbot application, &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;written by ChatGPT&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;ChatGPT-at-Home&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/Sentdex/ChatGPT-at-Home&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Design and Deploy Large Language Model Apps&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;dust&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/dust-tt/dust&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Polyglot: Large Language Models of Well-balanced Competence in &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;Multi-languages&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;polyglot&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/EleutherAI/polyglot&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;Code release for &quot;Learning Video Representations from Large &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;Language Models&quot;&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;LaViLa&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/facebookresearch/LaViLa&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;SmoothQuant: Accurate and Efficient Post-Training Quantization &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;for Large Language Models&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;smoothquant&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/mit-han-lab/smoothquant&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;},</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     {&#x27;snippet&#x27;: &#x27;This repository contains the code, data, and models of the paper &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;titled &quot;XL-Sum: Large-Scale Multilingual Abstractive &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;Summarization for 44 Languages&quot; published in Findings of the &#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">                 &#x27;Association for Computational Linguistics: ACL-IJCNLP 2021.&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;title&#x27;: &#x27;xl-sum&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;link&#x27;: &#x27;https://github.com/csebuetnlp/xl-sum&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;engines&#x27;: [&#x27;github&#x27;],</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      &#x27;category&#x27;: &#x27;it&#x27;}]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/langchain/docs/integrations/tools/search_tools"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Search Tools</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/langchain/docs/integrations/tools/serpapi"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">SerpAPI</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#custom-parameters" class="table-of-contents__link toc-highlight">Custom Parameters</a></li><li><a href="#obtaining-results-with-metadata" class="table-of-contents__link toc-highlight">Obtaining results with metadata</a></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/cU2adEyC7w" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/LangChainAI" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">GitHub</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/hwchase17/langchain" target="_blank" rel="noopener noreferrer" class="footer__link-item">Python<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/hwchase17/langchainjs" target="_blank" rel="noopener noreferrer" class="footer__link-item">JS/TS<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://langchain.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Homepage<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://blog.langchain.dev" target="_blank" rel="noopener noreferrer" class="footer__link-item">Blog<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2023 LangChain, Inc.</div></div></div></footer></div>
<script src="/langchain/assets/js/runtime~main.a20b23d6.js"></script>
<script src="/langchain/assets/js/main.af9852a9.js"></script>
</body>
</html>