<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-integrations/llms/index">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.0">
<title data-rh="true">LLMs | ğŸ¦œï¸ğŸ”— Langchain</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jiaqiwang969.github.io/langchain/img/parrot-chainlink-icon.png"><meta data-rh="true" name="twitter:image" content="https://jiaqiwang969.github.io/langchain/img/parrot-chainlink-icon.png"><meta data-rh="true" property="og:url" content="https://jiaqiwang969.github.io/langchain/docs/integrations/llms/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="LLMs | ğŸ¦œï¸ğŸ”— Langchain"><link data-rh="true" rel="icon" href="/langchain/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://jiaqiwang969.github.io/langchain/docs/integrations/llms/"><link data-rh="true" rel="alternate" href="https://jiaqiwang969.github.io/langchain/docs/integrations/llms/" hreflang="en"><link data-rh="true" rel="alternate" href="https://jiaqiwang969.github.io/langchain/docs/integrations/llms/" hreflang="x-default"><link rel="stylesheet" href="/langchain/assets/css/styles.b9396054.css">
<link rel="preload" href="/langchain/assets/js/runtime~main.96bce49c.js" as="script">
<link rel="preload" href="/langchain/assets/js/main.581eebae.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/langchain/"><b class="navbar__title text--truncate">ğŸ¦œï¸ğŸ”— LangChain</b></a><a class="navbar__item navbar__link" href="/langchain/docs/get_started/introduction">Docs</a><a class="navbar__item navbar__link" href="/langchain/docs/use_cases">Use cases</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/langchain/docs/integrations">Integrations</a><a href="https://api.python.langchain.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://smith.langchain.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">LangSmith</a><a href="https://js.langchain.com/docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">JS/TS Docs</a><a href="https://github.com/hwchase17/langchain" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="mendable-search"><button class="ms-global search-btn__input ms-m-0 ms-flex ms-h-10 ms-w-full ms-flex-row ms-items-center ms-justify-between ms-gap-2 ms-rounded-xl ms-bg-gray-50 ms-p-1 ms-pl-2 ms-pr-1 ms-shadow ms-outline-none ms-ring-0 ms-transition-all hover:ms-cursor-pointer hover:ms-shadow-md sm:ms-p-2 sm:ms-pl-4 sm:ms-pr-2"><div class="ms-global search-btn__input-container ms-flex ms-w-full ms-min-w-0 ms-items-center ms-gap-1"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="search-btn__icon hover:fill-white ms-h-5 ms-w-5 ms-fill-gray-400 ms-text-gray-400 hover:ms-text-white focus:ms-fill-white focus:ms-text-white sm:ms-h-6 sm:ms-w-6" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0z"></path><path d="M15.5 14h-.79l-.28-.27A6.471 6.471 0 0016 9.5 6.5 6.5 0 109.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"></path></svg><input readonly="" id="userInput" name="userInput" maxlength="512" placeholder="Search..." class="ms-global search-btn__input ms-w-full ms-flex-grow ms-truncate ms-bg-transparent ms-text-sm ms-outline-none ms-ring-0 ms-ring-transparent hover:ms-cursor-text focus:ms-outline-none focus:ms-ring-0 focus:ms-ring-transparent sm:ms-text-base"></div><div class="search-btn__shortcut ms-z-10 ms-flex ms-flex-row ms-items-center ms-gap-1 ms-rounded-lg ms-border ms-py-[2px] ms-px-[8px] ms-text-xs ms-text-gray-400 ms-transition-all disabled:ms-bg-opacity-10"><span>CTRL</span><span>K</span></div></button><div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--active" href="/langchain/docs/integrations">Integrations</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/callbacks/">Callbacks</a><button aria-label="Toggle the collapsible sidebar category &#x27;Callbacks&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/chat/">Chat models</a><button aria-label="Toggle the collapsible sidebar category &#x27;Chat models&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/chat_loaders/">Chat loaders</a><button aria-label="Toggle the collapsible sidebar category &#x27;Chat loaders&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/document_loaders/">Document loaders</a><button aria-label="Toggle the collapsible sidebar category &#x27;Document loaders&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/document_transformers/">Document transformers</a><button aria-label="Toggle the collapsible sidebar category &#x27;Document transformers&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible menu__list-item-collapsible--active"><a class="menu__link menu__link--sublist menu__link--active" aria-current="page" aria-expanded="true" tabindex="0" href="/langchain/docs/integrations/llms/">LLMs</a><button aria-label="Toggle the collapsible sidebar category &#x27;LLMs&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/ai21">AI21</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/aleph_alpha">Aleph Alpha</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/amazon_api_gateway">Amazon API Gateway</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/anyscale">Anyscale</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/azure_ml">Azure ML</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/azure_openai">Azure OpenAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/banana">Banana</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/baseten">Baseten</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/beam">Beam</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/bedrock">Bedrock</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/bittensor">Bittensor</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/cerebriumai">CerebriumAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/chatglm">ChatGLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/clarifai">Clarifai</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/cohere">Cohere</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/ctransformers">C Transformers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/databricks">Databricks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/deepinfra">DeepInfra</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/deepsparse">DeepSparse</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/edenai">Eden AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/fireworks">Fireworks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/forefrontai">ForefrontAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/google_vertex_ai_palm">Google Vertex AI PaLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/gooseai">GooseAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/gpt4all">GPT4All</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/huggingface_hub">Hugging Face Hub</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/huggingface_pipelines">Hugging Face Local Pipelines</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/huggingface_textgen_inference">Huggingface TextGen Inference</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/jsonformer_experimental">JSONFormer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/koboldai">KoboldAI API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/llamacpp">Llama.cpp</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/llm_caching">LLM Caching integrations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/manifest">Manifest</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/minimax">Minimax</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/modal">Modal</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/mosaicml">MosaicML</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/nlpcloud">NLP Cloud</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/octoai">OctoAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/ollama">Ollama</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/opaqueprompts">OpaquePrompts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/openai">OpenAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/openllm">OpenLLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/openlm">OpenLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/petals">Petals</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/pipelineai">PipelineAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/predibase">Predibase</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/predictionguard">Prediction Guard</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/promptlayer_openai">PromptLayer OpenAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/rellm_experimental">RELLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/replicate">Replicate</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/runhouse">Runhouse</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/sagemaker">SageMakerEndpoint</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/stochasticai">StochasticAI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/symblai_nebula">Nebula (Symbl.ai)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/textgen">TextGen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/titan_takeoff">Titan Takeoff</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/tongyi">Tongyi Qwen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/vllm">vLLM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/writer">Writer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/integrations/llms/xinference">Xorbits Inference (Xinference)</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/memory/">Memory</a><button aria-label="Toggle the collapsible sidebar category &#x27;Memory&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/retrievers/">Retrievers</a><button aria-label="Toggle the collapsible sidebar category &#x27;Retrievers&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/text_embedding/">Text embedding models</a><button aria-label="Toggle the collapsible sidebar category &#x27;Text embedding models&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/toolkits/">Agents &amp; Toolkits</a><button aria-label="Toggle the collapsible sidebar category &#x27;Agents &amp; Toolkits&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/tools/">Tools</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tools&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/vectorstores/">Vector stores</a><button aria-label="Toggle the collapsible sidebar category &#x27;Vector stores&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/integrations/providers/">Grouped by provider</a><button aria-label="Toggle the collapsible sidebar category &#x27;Grouped by provider&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/langchain/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/langchain/docs/integrations"><span itemprop="name">Integrations</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">LLMs</span><meta itemprop="position" content="2"></li></ul></nav><div class="theme-doc-markdown markdown"><h1>LLMs</h1><section class="row"><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/ai21"><h2 class="text--truncate cardTitle_rnsV" title="AI21">ğŸ“„ï¸<!-- --> <!-- -->AI21</h2><p class="text--truncate cardDescription_PWke" title="AI21 Studio provides API access to Jurassic-2 large language models.">AI21 Studio provides API access to Jurassic-2 large language models.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/aleph_alpha"><h2 class="text--truncate cardTitle_rnsV" title="Aleph Alpha">ğŸ“„ï¸<!-- --> <!-- -->Aleph Alpha</h2><p class="text--truncate cardDescription_PWke" title="The Luminous series is a family of large language models.">The Luminous series is a family of large language models.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/amazon_api_gateway"><h2 class="text--truncate cardTitle_rnsV" title="Amazon API Gateway">ğŸ“„ï¸<!-- --> <!-- -->Amazon API Gateway</h2><p class="text--truncate cardDescription_PWke" title="Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the &quot;front door&quot; for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications. API Gateway supports containerized and serverless workloads, as well as web applications.">Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the &quot;front door&quot; for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications. API Gateway supports containerized and serverless workloads, as well as web applications.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/anyscale"><h2 class="text--truncate cardTitle_rnsV" title="Anyscale">ğŸ“„ï¸<!-- --> <!-- -->Anyscale</h2><p class="text--truncate cardDescription_PWke" title="Anyscale is a fully-managed Ray platform, on which you can build, deploy, and manage scalable AI and Python applications">Anyscale is a fully-managed Ray platform, on which you can build, deploy, and manage scalable AI and Python applications</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/azure_ml"><h2 class="text--truncate cardTitle_rnsV" title="Azure ML">ğŸ“„ï¸<!-- --> <!-- -->Azure ML</h2><p class="text--truncate cardDescription_PWke" title="Azure ML is a platform used to build, train, and deploy machine learning models. Users can explore the types of models to deploy in the Model Catalog, which provides Azure Foundation Models and OpenAI Models. Azure Foundation Models include various open-source models and popular Hugging Face models. Users can also import models of their liking into AzureML.">Azure ML is a platform used to build, train, and deploy machine learning models. Users can explore the types of models to deploy in the Model Catalog, which provides Azure Foundation Models and OpenAI Models. Azure Foundation Models include various open-source models and popular Hugging Face models. Users can also import models of their liking into AzureML.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/azure_openai"><h2 class="text--truncate cardTitle_rnsV" title="Azure OpenAI">ğŸ“„ï¸<!-- --> <!-- -->Azure OpenAI</h2><p class="text--truncate cardDescription_PWke" title="This notebook goes over how to use Langchain with Azure OpenAI.">This notebook goes over how to use Langchain with Azure OpenAI.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/banana"><h2 class="text--truncate cardTitle_rnsV" title="Banana">ğŸ“„ï¸<!-- --> <!-- -->Banana</h2><p class="text--truncate cardDescription_PWke" title="Banana is focused on building the machine learning infrastructure.">Banana is focused on building the machine learning infrastructure.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/baseten"><h2 class="text--truncate cardTitle_rnsV" title="Baseten">ğŸ“„ï¸<!-- --> <!-- -->Baseten</h2><p class="text--truncate cardDescription_PWke" title="Baseten provides all the infrastructure you need to deploy and serve ML models performantly, scalably, and cost-efficiently.">Baseten provides all the infrastructure you need to deploy and serve ML models performantly, scalably, and cost-efficiently.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/beam"><h2 class="text--truncate cardTitle_rnsV" title="Beam">ğŸ“„ï¸<!-- --> <!-- -->Beam</h2><p class="text--truncate cardDescription_PWke" title="Calls the Beam API wrapper to deploy and make subsequent calls to an instance of the gpt2 LLM in a cloud deployment. Requires installation of the Beam library and registration of Beam Client ID and Client Secret. By calling the wrapper an instance of the model is created and run, with returned text relating to the prompt. Additional calls can then be made by directly calling the Beam API.">Calls the Beam API wrapper to deploy and make subsequent calls to an instance of the gpt2 LLM in a cloud deployment. Requires installation of the Beam library and registration of Beam Client ID and Client Secret. By calling the wrapper an instance of the model is created and run, with returned text relating to the prompt. Additional calls can then be made by directly calling the Beam API.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/bedrock"><h2 class="text--truncate cardTitle_rnsV" title="Bedrock">ğŸ“„ï¸<!-- --> <!-- -->Bedrock</h2><p class="text--truncate cardDescription_PWke" title="Amazon Bedrock is a fully managed service that makes FMs from leading AI startups and Amazon available via an API, so you can choose from a wide range of FMs to find the model that is best suited for your use case">Amazon Bedrock is a fully managed service that makes FMs from leading AI startups and Amazon available via an API, so you can choose from a wide range of FMs to find the model that is best suited for your use case</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/bittensor"><h2 class="text--truncate cardTitle_rnsV" title="Bittensor">ğŸ“„ï¸<!-- --> <!-- -->Bittensor</h2><p class="text--truncate cardDescription_PWke" title="Bittensor is a mining network, similar to Bitcoin, that includes built-in incentives designed to encourage miners to contribute compute + knowledge.">Bittensor is a mining network, similar to Bitcoin, that includes built-in incentives designed to encourage miners to contribute compute + knowledge.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/cerebriumai"><h2 class="text--truncate cardTitle_rnsV" title="CerebriumAI">ğŸ“„ï¸<!-- --> <!-- -->CerebriumAI</h2><p class="text--truncate cardDescription_PWke" title="Cerebrium is an AWS Sagemaker alternative. It also provides API access to several LLM models.">Cerebrium is an AWS Sagemaker alternative. It also provides API access to several LLM models.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/chatglm"><h2 class="text--truncate cardTitle_rnsV" title="ChatGLM">ğŸ“„ï¸<!-- --> <!-- -->ChatGLM</h2><p class="text--truncate cardDescription_PWke" title="ChatGLM-6B is an open bilingual language model based on General Language Model (GLM) framework, with 6.2 billion parameters. With the quantization technique, users can deploy locally on consumer-grade graphics cards (only 6GB of GPU memory is required at the INT4 quantization level).">ChatGLM-6B is an open bilingual language model based on General Language Model (GLM) framework, with 6.2 billion parameters. With the quantization technique, users can deploy locally on consumer-grade graphics cards (only 6GB of GPU memory is required at the INT4 quantization level).</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/clarifai"><h2 class="text--truncate cardTitle_rnsV" title="Clarifai">ğŸ“„ï¸<!-- --> <!-- -->Clarifai</h2><p class="text--truncate cardDescription_PWke" title="Clarifai is an AI Platform that provides the full AI lifecycle ranging from data exploration, data labeling, model training, evaluation, and inference.">Clarifai is an AI Platform that provides the full AI lifecycle ranging from data exploration, data labeling, model training, evaluation, and inference.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/cohere"><h2 class="text--truncate cardTitle_rnsV" title="Cohere">ğŸ“„ï¸<!-- --> <!-- -->Cohere</h2><p class="text--truncate cardDescription_PWke" title="Cohere is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions.">Cohere is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/ctransformers"><h2 class="text--truncate cardTitle_rnsV" title="C Transformers">ğŸ“„ï¸<!-- --> <!-- -->C Transformers</h2><p class="text--truncate cardDescription_PWke" title="The C Transformers library provides Python bindings for GGML models.">The C Transformers library provides Python bindings for GGML models.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/databricks"><h2 class="text--truncate cardTitle_rnsV" title="Databricks">ğŸ“„ï¸<!-- --> <!-- -->Databricks</h2><p class="text--truncate cardDescription_PWke" title="The Databricks Lakehouse Platform unifies data, analytics, and AI on one platform.">The Databricks Lakehouse Platform unifies data, analytics, and AI on one platform.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/deepinfra"><h2 class="text--truncate cardTitle_rnsV" title="DeepInfra">ğŸ“„ï¸<!-- --> <!-- -->DeepInfra</h2><p class="text--truncate cardDescription_PWke" title="DeepInfra provides several LLMs.">DeepInfra provides several LLMs.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/deepsparse"><h2 class="text--truncate cardTitle_rnsV" title="DeepSparse">ğŸ“„ï¸<!-- --> <!-- -->DeepSparse</h2><p class="text--truncate cardDescription_PWke" title="This page covers how to use the DeepSparse inference runtime within LangChain.">This page covers how to use the DeepSparse inference runtime within LangChain.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/edenai"><h2 class="text--truncate cardTitle_rnsV" title="Eden AI">ğŸ“„ï¸<!-- --> <!-- -->Eden AI</h2><p class="text--truncate cardDescription_PWke" title="Eden AI is revolutionizing the AI landscape by uniting the best AI providers, empowering users to unlock limitless possibilities and tap into the true potential of artificial intelligence. With an all-in-one comprehensive and hassle-free platform, it allows users to deploy AI features to production lightning fast, enabling effortless access to the full breadth of AI capabilities via a single API. (website//edenai.co/)">Eden AI is revolutionizing the AI landscape by uniting the best AI providers, empowering users to unlock limitless possibilities and tap into the true potential of artificial intelligence. With an all-in-one comprehensive and hassle-free platform, it allows users to deploy AI features to production lightning fast, enabling effortless access to the full breadth of AI capabilities via a single API. (website//edenai.co/)</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/fireworks"><h2 class="text--truncate cardTitle_rnsV" title="Fireworks">ğŸ“„ï¸<!-- --> <!-- -->Fireworks</h2><p class="text--truncate cardDescription_PWke" title="Fireworks accelerates product development on generative AI by creating an innovative AI experiment and production platform.">Fireworks accelerates product development on generative AI by creating an innovative AI experiment and production platform.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/forefrontai"><h2 class="text--truncate cardTitle_rnsV" title="ForefrontAI">ğŸ“„ï¸<!-- --> <!-- -->ForefrontAI</h2><p class="text--truncate cardDescription_PWke" title="The Forefront platform gives you the ability to fine-tune and use open source large language models.">The Forefront platform gives you the ability to fine-tune and use open source large language models.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/google_vertex_ai_palm"><h2 class="text--truncate cardTitle_rnsV" title="Google Vertex AI PaLM">ğŸ“„ï¸<!-- --> <!-- -->Google Vertex AI PaLM</h2><p class="text--truncate cardDescription_PWke" title="Note: This is seperate from the Google PaLM integration, it exposes Vertex AI PaLM API on Google Cloud.">Note: This is seperate from the Google PaLM integration, it exposes Vertex AI PaLM API on Google Cloud.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/gooseai"><h2 class="text--truncate cardTitle_rnsV" title="GooseAI">ğŸ“„ï¸<!-- --> <!-- -->GooseAI</h2><p class="text--truncate cardDescription_PWke" title="GooseAI is a fully managed NLP-as-a-Service, delivered via API. GooseAI provides access to these models.">GooseAI is a fully managed NLP-as-a-Service, delivered via API. GooseAI provides access to these models.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/gpt4all"><h2 class="text--truncate cardTitle_rnsV" title="GPT4All">ğŸ“„ï¸<!-- --> <!-- -->GPT4All</h2><p class="text--truncate cardDescription_PWke" title="GitHub:nomic-ai/gpt4all an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue.">GitHub:nomic-ai/gpt4all an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/huggingface_hub"><h2 class="text--truncate cardTitle_rnsV" title="Hugging Face Hub">ğŸ“„ï¸<!-- --> <!-- -->Hugging Face Hub</h2><p class="text--truncate cardDescription_PWke" title="The Hugging Face Hub is a platform with over 120k models, 20k datasets, and 50k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together.">The Hugging Face Hub is a platform with over 120k models, 20k datasets, and 50k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/huggingface_pipelines"><h2 class="text--truncate cardTitle_rnsV" title="Hugging Face Local Pipelines">ğŸ“„ï¸<!-- --> <!-- -->Hugging Face Local Pipelines</h2><p class="text--truncate cardDescription_PWke" title="Hugging Face models can be run locally through the HuggingFacePipeline class.">Hugging Face models can be run locally through the HuggingFacePipeline class.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/huggingface_textgen_inference"><h2 class="text--truncate cardTitle_rnsV" title="Huggingface TextGen Inference">ğŸ“„ï¸<!-- --> <!-- -->Huggingface TextGen Inference</h2><p class="text--truncate cardDescription_PWke" title="Text Generation Inference is a Rust, Python and gRPC server for text generation inference. Used in production at HuggingFace to power LLMs api-inference widgets.">Text Generation Inference is a Rust, Python and gRPC server for text generation inference. Used in production at HuggingFace to power LLMs api-inference widgets.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/jsonformer_experimental"><h2 class="text--truncate cardTitle_rnsV" title="JSONFormer">ğŸ“„ï¸<!-- --> <!-- -->JSONFormer</h2><p class="text--truncate cardDescription_PWke" title="JSONFormer is a library that wraps local HuggingFace pipeline models for structured decoding of a subset of the JSON Schema.">JSONFormer is a library that wraps local HuggingFace pipeline models for structured decoding of a subset of the JSON Schema.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/koboldai"><h2 class="text--truncate cardTitle_rnsV" title="KoboldAI API">ğŸ“„ï¸<!-- --> <!-- -->KoboldAI API</h2><p class="text--truncate cardDescription_PWke" title="KoboldAI is a &quot;a browser-based front-end for AI-assisted writing with multiple local &amp; remote AI models...&quot;. It has a public and local API that is able to be used in langchain.">KoboldAI is a &quot;a browser-based front-end for AI-assisted writing with multiple local &amp; remote AI models...&quot;. It has a public and local API that is able to be used in langchain.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/llamacpp"><h2 class="text--truncate cardTitle_rnsV" title="Llama.cpp">ğŸ“„ï¸<!-- --> <!-- -->Llama.cpp</h2><p class="text--truncate cardDescription_PWke" title="llama-cpp-python is a Python binding for llama.cpp.">llama-cpp-python is a Python binding for llama.cpp.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/llm_caching"><h2 class="text--truncate cardTitle_rnsV" title="LLM Caching integrations">ğŸ“„ï¸<!-- --> <!-- -->LLM Caching integrations</h2><p class="text--truncate cardDescription_PWke" title="This notebook covers how to cache results of individual LLM calls using different caches.">This notebook covers how to cache results of individual LLM calls using different caches.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/manifest"><h2 class="text--truncate cardTitle_rnsV" title="Manifest">ğŸ“„ï¸<!-- --> <!-- -->Manifest</h2><p class="text--truncate cardDescription_PWke" title="This notebook goes over how to use Manifest and LangChain.">This notebook goes over how to use Manifest and LangChain.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/minimax"><h2 class="text--truncate cardTitle_rnsV" title="Minimax">ğŸ“„ï¸<!-- --> <!-- -->Minimax</h2><p class="text--truncate cardDescription_PWke" title="Minimax is a Chinese startup that provides natural language processing models for companies and individuals.">Minimax is a Chinese startup that provides natural language processing models for companies and individuals.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/modal"><h2 class="text--truncate cardTitle_rnsV" title="Modal">ğŸ“„ï¸<!-- --> <!-- -->Modal</h2><p class="text--truncate cardDescription_PWke" title="The Modal cloud platform provides convenient, on-demand access to serverless cloud compute from Python scripts on your local computer.">The Modal cloud platform provides convenient, on-demand access to serverless cloud compute from Python scripts on your local computer.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/mosaicml"><h2 class="text--truncate cardTitle_rnsV" title="MosaicML">ğŸ“„ï¸<!-- --> <!-- -->MosaicML</h2><p class="text--truncate cardDescription_PWke" title="MosaicML offers a managed inference service. You can either use a variety of open source models, or deploy your own.">MosaicML offers a managed inference service. You can either use a variety of open source models, or deploy your own.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/nlpcloud"><h2 class="text--truncate cardTitle_rnsV" title="NLP Cloud">ğŸ“„ï¸<!-- --> <!-- -->NLP Cloud</h2><p class="text--truncate cardDescription_PWke" title="The NLP Cloud serves high performance pre-trained or custom models for NER, sentiment-analysis, classification, summarization, paraphrasing, grammar and spelling correction, keywords and keyphrases extraction, chatbot, product description and ad generation, intent classification, text generation, image generation, blog post generation, code generation, question answering, automatic speech recognition, machine translation, language detection, semantic search, semantic similarity, tokenization, POS tagging, embeddings, and dependency parsing. It is ready for production, served through a REST API.">The NLP Cloud serves high performance pre-trained or custom models for NER, sentiment-analysis, classification, summarization, paraphrasing, grammar and spelling correction, keywords and keyphrases extraction, chatbot, product description and ad generation, intent classification, text generation, image generation, blog post generation, code generation, question answering, automatic speech recognition, machine translation, language detection, semantic search, semantic similarity, tokenization, POS tagging, embeddings, and dependency parsing. It is ready for production, served through a REST API.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/octoai"><h2 class="text--truncate cardTitle_rnsV" title="OctoAI">ğŸ“„ï¸<!-- --> <!-- -->OctoAI</h2><p class="text--truncate cardDescription_PWke" title="OctoML is a service with efficient compute. It enables users to integrate their choice of AI models into applications. The OctoAI compute service helps you run, tune, and scale AI applications.">OctoML is a service with efficient compute. It enables users to integrate their choice of AI models into applications. The OctoAI compute service helps you run, tune, and scale AI applications.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/ollama"><h2 class="text--truncate cardTitle_rnsV" title="Ollama">ğŸ“„ï¸<!-- --> <!-- -->Ollama</h2><p class="text--truncate cardDescription_PWke" title="Ollama allows you to run open-source large language models, such as Llama 2, locally.">Ollama allows you to run open-source large language models, such as Llama 2, locally.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/opaqueprompts"><h2 class="text--truncate cardTitle_rnsV" title="OpaquePrompts">ğŸ“„ï¸<!-- --> <!-- -->OpaquePrompts</h2><p class="text--truncate cardDescription_PWke" title="OpaquePrompts is a service that enables applications to leverage the power of language models without compromising user privacy. Designed for composability and ease of integration into existing applications and services, OpaquePrompts is consumable via a simple Python library as well as through LangChain. Perhaps more importantly, OpaquePrompts leverages the power of confidential computing to ensure that even the OpaquePrompts service itself cannot access the data it is protecting.">OpaquePrompts is a service that enables applications to leverage the power of language models without compromising user privacy. Designed for composability and ease of integration into existing applications and services, OpaquePrompts is consumable via a simple Python library as well as through LangChain. Perhaps more importantly, OpaquePrompts leverages the power of confidential computing to ensure that even the OpaquePrompts service itself cannot access the data it is protecting.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/openai"><h2 class="text--truncate cardTitle_rnsV" title="OpenAI">ğŸ“„ï¸<!-- --> <!-- -->OpenAI</h2><p class="text--truncate cardDescription_PWke" title="OpenAI offers a spectrum of models with different levels of power suitable for different tasks.">OpenAI offers a spectrum of models with different levels of power suitable for different tasks.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/openllm"><h2 class="text--truncate cardTitle_rnsV" title="OpenLLM">ğŸ“„ï¸<!-- --> <!-- -->OpenLLM</h2><p class="text--truncate cardDescription_PWke" title="ğŸ¦¾ OpenLLM is an open platform for operating large language models (LLMs) in production. It enables developers to easily run inference with any open-source LLMs, deploy to the cloud or on-premises, and build powerful AI apps.">ğŸ¦¾ OpenLLM is an open platform for operating large language models (LLMs) in production. It enables developers to easily run inference with any open-source LLMs, deploy to the cloud or on-premises, and build powerful AI apps.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/openlm"><h2 class="text--truncate cardTitle_rnsV" title="OpenLM">ğŸ“„ï¸<!-- --> <!-- -->OpenLM</h2><p class="text--truncate cardDescription_PWke" title="OpenLM is a zero-dependency OpenAI-compatible LLM provider that can call different inference endpoints directly via HTTP.">OpenLM is a zero-dependency OpenAI-compatible LLM provider that can call different inference endpoints directly via HTTP.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/petals"><h2 class="text--truncate cardTitle_rnsV" title="Petals">ğŸ“„ï¸<!-- --> <!-- -->Petals</h2><p class="text--truncate cardDescription_PWke" title="Petals runs 100B+ language models at home, BitTorrent-style.">Petals runs 100B+ language models at home, BitTorrent-style.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/pipelineai"><h2 class="text--truncate cardTitle_rnsV" title="PipelineAI">ğŸ“„ï¸<!-- --> <!-- -->PipelineAI</h2><p class="text--truncate cardDescription_PWke" title="PipelineAI allows you to run your ML models at scale in the cloud. It also provides API access to several LLM models.">PipelineAI allows you to run your ML models at scale in the cloud. It also provides API access to several LLM models.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/predibase"><h2 class="text--truncate cardTitle_rnsV" title="Predibase">ğŸ“„ï¸<!-- --> <!-- -->Predibase</h2><p class="text--truncate cardDescription_PWke" title="Predibase allows you to train, finetune, and deploy any ML modelâ€”from linear regression to large language model.">Predibase allows you to train, finetune, and deploy any ML modelâ€”from linear regression to large language model.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/predictionguard"><h2 class="text--truncate cardTitle_rnsV" title="Prediction Guard">ğŸ“„ï¸<!-- --> <!-- -->Prediction Guard</h2><p class="text--truncate cardDescription_PWke" title="Basic LLM usage">Basic LLM usage</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/promptlayer_openai"><h2 class="text--truncate cardTitle_rnsV" title="PromptLayer OpenAI">ğŸ“„ï¸<!-- --> <!-- -->PromptLayer OpenAI</h2><p class="text--truncate cardDescription_PWke" title="PromptLayer is the first platform that allows you to track, manage, and share your GPT prompt engineering. PromptLayer acts a middleware between your code and OpenAIâ€™s python library.">PromptLayer is the first platform that allows you to track, manage, and share your GPT prompt engineering. PromptLayer acts a middleware between your code and OpenAIâ€™s python library.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/rellm_experimental"><h2 class="text--truncate cardTitle_rnsV" title="RELLM">ğŸ“„ï¸<!-- --> <!-- -->RELLM</h2><p class="text--truncate cardDescription_PWke" title="RELLM is a library that wraps local Hugging Face pipeline models for structured decoding.">RELLM is a library that wraps local Hugging Face pipeline models for structured decoding.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/replicate"><h2 class="text--truncate cardTitle_rnsV" title="Replicate">ğŸ“„ï¸<!-- --> <!-- -->Replicate</h2><p class="text--truncate cardDescription_PWke" title="Replicate runs machine learning models in the cloud. We have a library of open-source models that you can run with a few lines of code. If you&#x27;re building your own machine learning models, Replicate makes it easy to deploy them at scale.">Replicate runs machine learning models in the cloud. We have a library of open-source models that you can run with a few lines of code. If you&#x27;re building your own machine learning models, Replicate makes it easy to deploy them at scale.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/runhouse"><h2 class="text--truncate cardTitle_rnsV" title="Runhouse">ğŸ“„ï¸<!-- --> <!-- -->Runhouse</h2><p class="text--truncate cardDescription_PWke" title="The Runhouse allows remote compute and data across environments and users. See the Runhouse docs.">The Runhouse allows remote compute and data across environments and users. See the Runhouse docs.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/sagemaker"><h2 class="text--truncate cardTitle_rnsV" title="SageMakerEndpoint">ğŸ“„ï¸<!-- --> <!-- -->SageMakerEndpoint</h2><p class="text--truncate cardDescription_PWke" title="Amazon SageMaker is a system that can build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.">Amazon SageMaker is a system that can build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/stochasticai"><h2 class="text--truncate cardTitle_rnsV" title="StochasticAI">ğŸ“„ï¸<!-- --> <!-- -->StochasticAI</h2><p class="text--truncate cardDescription_PWke" title="Stochastic Acceleration Platform aims to simplify the life cycle of a Deep Learning model. From uploading and versioning the model, through training, compression and acceleration to putting it into production.">Stochastic Acceleration Platform aims to simplify the life cycle of a Deep Learning model. From uploading and versioning the model, through training, compression and acceleration to putting it into production.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/symblai_nebula"><h2 class="text--truncate cardTitle_rnsV" title="Nebula (Symbl.ai)">ğŸ“„ï¸<!-- --> <!-- -->Nebula (Symbl.ai)</h2><p class="text--truncate cardDescription_PWke" title="Nebula is a large language model (LLM) built by Symbl.ai. It is trained to perform generative tasks on human conversations. Nebula excels at modeling the nuanced details of a conversation and performing tasks on the conversation.">Nebula is a large language model (LLM) built by Symbl.ai. It is trained to perform generative tasks on human conversations. Nebula excels at modeling the nuanced details of a conversation and performing tasks on the conversation.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/textgen"><h2 class="text--truncate cardTitle_rnsV" title="TextGen">ğŸ“„ï¸<!-- --> <!-- -->TextGen</h2><p class="text--truncate cardDescription_PWke" title="GitHub:oobabooga/text-generation-webui A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.">GitHub:oobabooga/text-generation-webui A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/titan_takeoff"><h2 class="text--truncate cardTitle_rnsV" title="Titan Takeoff">ğŸ“„ï¸<!-- --> <!-- -->Titan Takeoff</h2><p class="text--truncate cardDescription_PWke" title="TitanML helps businesses build and deploy better, smaller, cheaper, and faster NLP models through our training, compression, and inference optimization platform.">TitanML helps businesses build and deploy better, smaller, cheaper, and faster NLP models through our training, compression, and inference optimization platform.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/tongyi"><h2 class="text--truncate cardTitle_rnsV" title="Tongyi Qwen">ğŸ“„ï¸<!-- --> <!-- -->Tongyi Qwen</h2><p class="text--truncate cardDescription_PWke" title="Tongyi Qwen is a large-scale language model developed by Alibaba&#x27;s Damo Academy. It is capable of understanding user intent through natural language understanding and semantic analysis, based on user input in natural language. It provides services and assistance to users in different domains and tasks. By providing clear and detailed instructions, you can obtain results that better align with your expectations.">Tongyi Qwen is a large-scale language model developed by Alibaba&#x27;s Damo Academy. It is capable of understanding user intent through natural language understanding and semantic analysis, based on user input in natural language. It provides services and assistance to users in different domains and tasks. By providing clear and detailed instructions, you can obtain results that better align with your expectations.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/vllm"><h2 class="text--truncate cardTitle_rnsV" title="vLLM">ğŸ“„ï¸<!-- --> <!-- -->vLLM</h2><p class="text--truncate cardDescription_PWke" title="vLLM is a fast and easy-to-use library for LLM inference and serving, offering:">vLLM is a fast and easy-to-use library for LLM inference and serving, offering:</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/writer"><h2 class="text--truncate cardTitle_rnsV" title="Writer">ğŸ“„ï¸<!-- --> <!-- -->Writer</h2><p class="text--truncate cardDescription_PWke" title="Writer is a platform to generate different language content.">Writer is a platform to generate different language content.</p></a></article><article class="col col--6 margin-bottom--lg"><a class="card padding--lg cardContainer_fWXF" href="/langchain/docs/integrations/llms/xinference"><h2 class="text--truncate cardTitle_rnsV" title="Xorbits Inference (Xinference)">ğŸ“„ï¸<!-- --> <!-- -->Xorbits Inference (Xinference)</h2><p class="text--truncate cardDescription_PWke" title="Xinference is a powerful and versatile library designed to serve LLMs,">Xinference is a powerful and versatile library designed to serve LLMs,</p></a></article></section></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/langchain/docs/integrations/document_transformers/openai_metadata_tagger"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">OpenAI Functions Metadata Tagger</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/langchain/docs/integrations/llms/ai21"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">AI21</div></a></nav></div></div></div></div></main></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/cU2adEyC7w" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/LangChainAI" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">GitHub</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/hwchase17/langchain" target="_blank" rel="noopener noreferrer" class="footer__link-item">Python<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/hwchase17/langchainjs" target="_blank" rel="noopener noreferrer" class="footer__link-item">JS/TS<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://langchain.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Homepage<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://blog.langchain.dev" target="_blank" rel="noopener noreferrer" class="footer__link-item">Blog<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2023 LangChain, Inc.</div></div></div></footer></div>
<script src="/langchain/assets/js/runtime~main.96bce49c.js"></script>
<script src="/langchain/assets/js/main.581eebae.js"></script>
</body>
</html>