<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-modules/data_connection/retrievers/web_research">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.0">
<title data-rh="true">WebResearchRetriever | 🦜️🔗 Langchain</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://jiaqiwang969.github.io/langchain/img/parrot-chainlink-icon.png"><meta data-rh="true" name="twitter:image" content="https://jiaqiwang969.github.io/langchain/img/parrot-chainlink-icon.png"><meta data-rh="true" property="og:url" content="https://jiaqiwang969.github.io/langchain/docs/modules/data_connection/retrievers/web_research"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="WebResearchRetriever | 🦜️🔗 Langchain"><meta data-rh="true" name="description" content="Given a query, this retriever will:"><meta data-rh="true" property="og:description" content="Given a query, this retriever will:"><link data-rh="true" rel="icon" href="/langchain/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://jiaqiwang969.github.io/langchain/docs/modules/data_connection/retrievers/web_research"><link data-rh="true" rel="alternate" href="https://jiaqiwang969.github.io/langchain/docs/modules/data_connection/retrievers/web_research" hreflang="en"><link data-rh="true" rel="alternate" href="https://jiaqiwang969.github.io/langchain/docs/modules/data_connection/retrievers/web_research" hreflang="x-default"><link rel="stylesheet" href="/langchain/assets/css/styles.b9396054.css">
<link rel="preload" href="/langchain/assets/js/runtime~main.96bce49c.js" as="script">
<link rel="preload" href="/langchain/assets/js/main.581eebae.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,e("light"))}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/langchain/"><b class="navbar__title text--truncate">🦜️🔗 LangChain</b></a><a class="navbar__item navbar__link" href="/langchain/docs/get_started/introduction">Docs</a><a class="navbar__item navbar__link" href="/langchain/docs/use_cases">Use cases</a><a class="navbar__item navbar__link" href="/langchain/docs/integrations">Integrations</a><a href="https://api.python.langchain.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://smith.langchain.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">LangSmith</a><a href="https://js.langchain.com/docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">JS/TS Docs</a><a href="https://github.com/hwchase17/langchain" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="mendable-search"><button class="ms-global search-btn__input ms-m-0 ms-flex ms-h-10 ms-w-full ms-flex-row ms-items-center ms-justify-between ms-gap-2 ms-rounded-xl ms-bg-gray-50 ms-p-1 ms-pl-2 ms-pr-1 ms-shadow ms-outline-none ms-ring-0 ms-transition-all hover:ms-cursor-pointer hover:ms-shadow-md sm:ms-p-2 sm:ms-pl-4 sm:ms-pr-2"><div class="ms-global search-btn__input-container ms-flex ms-w-full ms-min-w-0 ms-items-center ms-gap-1"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="search-btn__icon hover:fill-white ms-h-5 ms-w-5 ms-fill-gray-400 ms-text-gray-400 hover:ms-text-white focus:ms-fill-white focus:ms-text-white sm:ms-h-6 sm:ms-w-6" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0z"></path><path d="M15.5 14h-.79l-.28-.27A6.471 6.471 0 0016 9.5 6.5 6.5 0 109.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"></path></svg><input readonly="" id="userInput" name="userInput" maxlength="512" placeholder="Search..." class="ms-global search-btn__input ms-w-full ms-flex-grow ms-truncate ms-bg-transparent ms-text-sm ms-outline-none ms-ring-0 ms-ring-transparent hover:ms-cursor-text focus:ms-outline-none focus:ms-ring-0 focus:ms-ring-transparent sm:ms-text-base"></div><div class="search-btn__shortcut ms-z-10 ms-flex ms-flex-row ms-items-center ms-gap-1 ms-rounded-lg ms-border ms-py-[2px] ms-px-[8px] ms-text-xs ms-text-gray-400 ms-transition-all disabled:ms-bg-opacity-10"><span>CTRL</span><span>K</span></div></button><div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link" href="/langchain/docs/get_started">Get started</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/get_started/introduction">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/get_started/installation">Installation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/get_started/quickstart">Quickstart</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--active" href="/langchain/docs/modules/">Modules</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/modules/model_io/">Model I/​O</a><button aria-label="Toggle the collapsible sidebar category &#x27;Model I/​O&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/langchain/docs/modules/data_connection/">Retrieval</a><button aria-label="Toggle the collapsible sidebar category &#x27;Retrieval&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/modules/data_connection/document_loaders/">Document loaders</a><button aria-label="Toggle the collapsible sidebar category &#x27;Document loaders&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/modules/data_connection/document_transformers/">Document transformers</a><button aria-label="Toggle the collapsible sidebar category &#x27;Document transformers&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/modules/data_connection/text_embedding/">Text embedding models</a><button aria-label="Toggle the collapsible sidebar category &#x27;Text embedding models&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/modules/data_connection/vectorstores/">Vector stores</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/langchain/docs/modules/data_connection/retrievers/">Retrievers</a><button aria-label="Toggle the collapsible sidebar category &#x27;Retrievers&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/modules/data_connection/retrievers/MultiQueryRetriever">MultiQueryRetriever</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/modules/data_connection/retrievers/contextual_compression/">Contextual compression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/modules/data_connection/retrievers/ensemble">Ensemble Retriever</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/modules/data_connection/retrievers/multi_vector">MultiVector Retriever</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/modules/data_connection/retrievers/parent_document_retriever">Parent Document Retriever</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/modules/data_connection/retrievers/self_query/">Self-querying</a><button aria-label="Toggle the collapsible sidebar category &#x27;Self-querying&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/modules/data_connection/retrievers/time_weighted_vectorstore">Time-weighted vector store retriever</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/modules/data_connection/retrievers/vectorstore">Vector store-backed retriever</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/langchain/docs/modules/data_connection/retrievers/web_research">WebResearchRetriever</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/langchain/docs/modules/data_connection/indexing">Indexing</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/modules/chains/">Chains</a><button aria-label="Toggle the collapsible sidebar category &#x27;Chains&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/modules/memory/">Memory</a><button aria-label="Toggle the collapsible sidebar category &#x27;Memory&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/modules/agents/">Agents</a><button aria-label="Toggle the collapsible sidebar category &#x27;Agents&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/langchain/docs/modules/callbacks/">Callbacks</a><button aria-label="Toggle the collapsible sidebar category &#x27;Callbacks&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item hidden"><a class="menu__link" tabindex="0" href="/langchain/docs/modules/">Modules</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/langchain/docs/expression_language/">LangChain Expression Language</a><button aria-label="Toggle the collapsible sidebar category &#x27;LangChain Expression Language&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/langchain/docs/guides">Guides</a><button aria-label="Toggle the collapsible sidebar category &#x27;Guides&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/langchain/docs/additional_resources">Additional resources</a><button aria-label="Toggle the collapsible sidebar category &#x27;Additional resources&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/langchain/docs/community">Community navigator</a></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/langchain/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/langchain/docs/modules/"><span itemprop="name">Modules</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/langchain/docs/modules/data_connection/"><span itemprop="name">Retrieval</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/langchain/docs/modules/data_connection/retrievers/"><span itemprop="name">Retrievers</span></a><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">WebResearchRetriever</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>WebResearchRetriever</h1><p>Given a query, this retriever will: </p><ul><li>Formulate a set of relate Google searches</li><li>Search for each </li><li>Load all the resulting URLs</li><li>Then embed and perform similarity search with the query on the consolidate page content</li></ul><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">retrievers</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">web_research </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> WebResearchRetriever</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><h4 style="padding-left:0.65rem;margin-bottom:0.45rem">API Reference:</h4><ul style="padding-bottom:1rem"><li><a href="https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.web_research.WebResearchRetriever.html"><span>WebResearchRetriever</span></a></li></ul></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="simple-usage">Simple usage<a href="#simple-usage" class="hash-link" aria-label="Direct link to Simple usage" title="Direct link to Simple usage">​</a></h3><p>Specify the LLM to use for Google search query generation.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> os</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">vectorstores </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> Chroma</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">embeddings </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> OpenAIEmbeddings</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">chat_models</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">openai </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> ChatOpenAI</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">utilities </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> GoogleSearchAPIWrapper</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token comment" style="color:rgb(0, 128, 0)"># Vectorstore</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">vectorstore </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> Chroma</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">embedding_function</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">OpenAIEmbeddings</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">persist_directory</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;./chroma_db_oai&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token comment" style="color:rgb(0, 128, 0)"># LLM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> ChatOpenAI</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">temperature</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">0</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token comment" style="color:rgb(0, 128, 0)"># Search </span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">os</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">environ</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;GOOGLE_CSE_ID&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token plain"> </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;xxx&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">os</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">environ</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;GOOGLE_API_KEY&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token plain"> </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;xxx&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">search </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> GoogleSearchAPIWrapper</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><h4 style="padding-left:0.65rem;margin-bottom:0.45rem">API Reference:</h4><ul style="padding-bottom:1rem"><li><a href="https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.chroma.Chroma.html"><span>Chroma</span></a></li><li><a href="https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html"><span>OpenAIEmbeddings</span></a></li><li><a href="https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html"><span>ChatOpenAI</span></a></li><li><a href="https://api.python.langchain.com/en/latest/utilities/langchain.utilities.google_search.GoogleSearchAPIWrapper.html"><span>GoogleSearchAPIWrapper</span></a></li></ul></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token comment" style="color:rgb(0, 128, 0)"># Initialize</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">web_research_retriever </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> WebResearchRetriever</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">from_llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    vectorstore</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">vectorstore</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llm</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    search</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">search</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="run-with-citations">Run with citations<a href="#run-with-citations" class="hash-link" aria-label="Direct link to Run with citations" title="Direct link to Run with citations">​</a></h4><p>We can use <code>RetrievalQAWithSourcesChain</code> to retrieve docs and provide citations.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">chains </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> RetrievalQAWithSourcesChain</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">user_input </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;How do LLM Powered Autonomous Agents work?&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">qa_chain </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> RetrievalQAWithSourcesChain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">from_chain_type</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">retriever</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">web_research_retriever</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">result </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> qa_chain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">{</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;question&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> user_input</span><span class="token punctuation" style="color:rgb(4, 81, 165)">}</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">result</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><h4 style="padding-left:0.65rem;margin-bottom:0.45rem">API Reference:</h4><ul style="padding-bottom:1rem"><li><a href="https://api.python.langchain.com/en/latest/chains/langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain.html"><span>RetrievalQAWithSourcesChain</span></a></li></ul></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    Fetching pages: 100%|###################################################################################################################################| 1/1 [00:00&lt;00:00,  3.33it/s]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    {&#x27;question&#x27;: &#x27;How do LLM Powered Autonomous Agents work?&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     &#x27;answer&#x27;: &quot;LLM Powered Autonomous Agents work by using LLM (large language model) as the core controller of the agent&#x27;s brain. It is complemented by several key components, including planning, memory, and tool use. The agent system is designed to be a powerful general problem solver. \n&quot;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     &#x27;sources&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="run-with-logging">Run with logging<a href="#run-with-logging" class="hash-link" aria-label="Direct link to Run with logging" title="Direct link to Run with logging">​</a></h4><p>Here, we use <code>get_relevant_documents</code> method to return docs.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token comment" style="color:rgb(0, 128, 0)"># Run</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> logging</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">logging</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">basicConfig</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">logging</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">getLogger</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;langchain.retrievers.web_research&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">setLevel</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">logging</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">INFO</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">user_input </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;What is Task Decomposition in LLM Powered Autonomous Agents?&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">docs </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> web_research_retriever</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">get_relevant_documents</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">user_input</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Generating questions for Google Search ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Questions for Google Search (raw): {&#x27;question&#x27;: &#x27;What is Task Decomposition in LLM Powered Autonomous Agents?&#x27;, &#x27;text&#x27;: LineList(lines=[&#x27;1. How do LLM powered autonomous agents utilize task decomposition?\n&#x27;, &#x27;2. Can you explain the concept of task decomposition in LLM powered autonomous agents?\n&#x27;, &#x27;3. What role does task decomposition play in the functioning of LLM powered autonomous agents?\n&#x27;, &#x27;4. Why is task decomposition important for LLM powered autonomous agents?\n&#x27;])}</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Questions for Google Search: [&#x27;1. How do LLM powered autonomous agents utilize task decomposition?\n&#x27;, &#x27;2. Can you explain the concept of task decomposition in LLM powered autonomous agents?\n&#x27;, &#x27;3. What role does task decomposition play in the functioning of LLM powered autonomous agents?\n&#x27;, &#x27;4. Why is task decomposition important for LLM powered autonomous agents?\n&#x27;]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Search results: [{&#x27;title&#x27;: &quot;LLM Powered Autonomous Agents | Lil&#x27;Log&quot;, &#x27;link&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;, &#x27;snippet&#x27;: &#x27;Jun 23, 2023 ... Task decomposition can be done (1) by LLM with simple prompting like &quot;Steps for XYZ.\\n1.&quot; , &quot;What are the subgoals for achieving XYZ?&#x27;}]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Search results: [{&#x27;title&#x27;: &quot;LLM Powered Autonomous Agents | Lil&#x27;Log&quot;, &#x27;link&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;, &#x27;snippet&#x27;: &#x27;Jun 23, 2023 ... Task decomposition can be done (1) by LLM with simple prompting like &quot;Steps for XYZ.\\n1.&quot; , &quot;What are the subgoals for achieving XYZ?&quot; , (2)\xa0...&#x27;}]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Search results: [{&#x27;title&#x27;: &quot;LLM Powered Autonomous Agents | Lil&#x27;Log&quot;, &#x27;link&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;, &#x27;snippet&#x27;: &#x27;Jun 23, 2023 ... In a LLM-powered autonomous agent system, LLM functions as the ... Task decomposition can be done (1) by LLM with simple prompting like\xa0...&#x27;}]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Search results: [{&#x27;title&#x27;: &quot;LLM Powered Autonomous Agents | Lil&#x27;Log&quot;, &#x27;link&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;, &#x27;snippet&#x27;: &#x27;Jun 23, 2023 ... Agent System Overview In a LLM-powered autonomous agent system, ... Task decomposition can be done (1) by LLM with simple prompting like\xa0...&#x27;}]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:New URLs to load: []</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="generate-answer-using-retrieved-docs">Generate answer using retrieved docs<a href="#generate-answer-using-retrieved-docs" class="hash-link" aria-label="Direct link to Generate answer using retrieved docs" title="Direct link to Generate answer using retrieved docs">​</a></h4><p>We can use <code>load_qa_chain</code> for QA using the retrieved docs.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">chains</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">question_answering </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> load_qa_chain</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">chain </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> load_qa_chain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> chain_type</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;stuff&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">output </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> chain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">{</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;input_documents&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> docs</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;question&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> user_input</span><span class="token punctuation" style="color:rgb(4, 81, 165)">}</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">return_only_outputs</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">output</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token string" style="color:rgb(163, 21, 21)">&#x27;output_text&#x27;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><h4 style="padding-left:0.65rem;margin-bottom:0.45rem">API Reference:</h4><ul style="padding-bottom:1rem"><li><a href="https://api.python.langchain.com/en/latest/chains/langchain.chains.question_answering.load_qa_chain.html"><span>load_qa_chain</span></a></li></ul></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    &#x27;Task decomposition in LLM-powered autonomous agents refers to the process of breaking down a complex task into smaller, more manageable subgoals. This allows the agent to efficiently handle and execute the individual steps required to complete the overall task. By decomposing the task, the agent can prioritize and organize its actions, making it easier to plan and execute the necessary steps towards achieving the desired outcome.&#x27;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="more-flexibility">More flexibility<a href="#more-flexibility" class="hash-link" aria-label="Direct link to More flexibility" title="Direct link to More flexibility">​</a></h3><p>Pass an LLM chain with custom prompt and output parsing.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> os</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> re</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> typing </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> List</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">chains </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> LLMChain</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> pydantic </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> BaseModel</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> Field</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">prompts </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> PromptTemplate</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">output_parsers</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">pydantic </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> PydanticOutputParser</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token comment" style="color:rgb(0, 128, 0)"># LLMChain</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">search_prompt </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> PromptTemplate</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    input_variables</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;question&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    template</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">&quot;&quot;&quot;You are an assistant tasked with improving Google search </span><br></span><span class="token-line" style="color:#000000"><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">    results. Generate FIVE Google search queries that are similar to</span><br></span><span class="token-line" style="color:#000000"><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">    this question. The output should be a numbered list of questions and each</span><br></span><span class="token-line" style="color:#000000"><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">    should have a question mark at the end: {question}&quot;&quot;&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">class</span><span class="token plain"> </span><span class="token class-name" style="color:rgb(38, 127, 153)">LineList</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">BaseModel</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">&quot;&quot;&quot;List of questions.&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    lines</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> List</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token builtin" style="color:rgb(0, 112, 193)">str</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token plain"> </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> Field</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">description</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;Questions&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">class</span><span class="token plain"> </span><span class="token class-name" style="color:rgb(38, 127, 153)">QuestionListOutputParser</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">PydanticOutputParser</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:rgb(163, 21, 21)">&quot;&quot;&quot;Output parser for a list of numbered questions.&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><span class="token keyword" style="color:rgb(0, 0, 255)">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(0, 0, 255)">__init__</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"> </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">&gt;</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">        </span><span class="token builtin" style="color:rgb(0, 112, 193)">super</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">pydantic_object</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">LineList</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><span class="token keyword" style="color:rgb(0, 0, 255)">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(0, 0, 255)">parse</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> text</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(0, 112, 193)">str</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"> </span><span class="token operator" style="color:rgb(0, 0, 0)">-</span><span class="token operator" style="color:rgb(0, 0, 0)">&gt;</span><span class="token plain"> LineList</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">        lines </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> re</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">findall</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token string" style="color:rgb(163, 21, 21)">r&quot;\d+\..*?\n&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> text</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">        </span><span class="token keyword" style="color:rgb(0, 0, 255)">return</span><span class="token plain"> LineList</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">lines</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">lines</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llm_chain </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> LLMChain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">            llm</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">            prompt</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">search_prompt</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">            output_parser</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">QuestionListOutputParser</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><h4 style="padding-left:0.65rem;margin-bottom:0.45rem">API Reference:</h4><ul style="padding-bottom:1rem"><li><a href="https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html"><span>LLMChain</span></a></li><li><a href="https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html"><span>PromptTemplate</span></a></li><li><a href="https://api.python.langchain.com/en/latest/output_parsers/langchain.output_parsers.pydantic.PydanticOutputParser.html"><span>PydanticOutputParser</span></a></li></ul></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token comment" style="color:rgb(0, 128, 0)"># Initialize</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">web_research_retriever_llm_chain </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> WebResearchRetriever</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    vectorstore</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">vectorstore</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llm_chain</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">llm_chain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    search</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">search</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token comment" style="color:rgb(0, 128, 0)"># Run</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">docs </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> web_research_retriever_llm_chain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">get_relevant_documents</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">user_input</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Generating questions for Google Search ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Questions for Google Search (raw): {&#x27;question&#x27;: &#x27;What is Task Decomposition in LLM Powered Autonomous Agents?&#x27;, &#x27;text&#x27;: LineList(lines=[&#x27;1. How do LLM powered autonomous agents use task decomposition?\n&#x27;, &#x27;2. Why is task decomposition important for LLM powered autonomous agents?\n&#x27;, &#x27;3. Can you explain the concept of task decomposition in LLM powered autonomous agents?\n&#x27;, &#x27;4. What are the benefits of task decomposition in LLM powered autonomous agents?\n&#x27;])}</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Questions for Google Search: [&#x27;1. How do LLM powered autonomous agents use task decomposition?\n&#x27;, &#x27;2. Why is task decomposition important for LLM powered autonomous agents?\n&#x27;, &#x27;3. Can you explain the concept of task decomposition in LLM powered autonomous agents?\n&#x27;, &#x27;4. What are the benefits of task decomposition in LLM powered autonomous agents?\n&#x27;]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Search results: [{&#x27;title&#x27;: &quot;LLM Powered Autonomous Agents | Lil&#x27;Log&quot;, &#x27;link&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;, &#x27;snippet&#x27;: &#x27;Jun 23, 2023 ... Task decomposition can be done (1) by LLM with simple prompting like &quot;Steps for XYZ.\\n1.&quot; , &quot;What are the subgoals for achieving XYZ?&#x27;}]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Search results: [{&#x27;title&#x27;: &quot;LLM Powered Autonomous Agents | Lil&#x27;Log&quot;, &#x27;link&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;, &#x27;snippet&#x27;: &#x27;Jun 23, 2023 ... Task decomposition can be done (1) by LLM with simple prompting like &quot;Steps for XYZ.\\n1.&quot; , &quot;What are the subgoals for achieving XYZ?&quot; , (2)\xa0...&#x27;}]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Search results: [{&#x27;title&#x27;: &quot;LLM Powered Autonomous Agents | Lil&#x27;Log&quot;, &#x27;link&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;, &#x27;snippet&#x27;: &#x27;Jun 23, 2023 ... Task decomposition can be done (1) by LLM with simple prompting like &quot;Steps for XYZ.\\n1.&quot; , &quot;What are the subgoals for achieving XYZ?&#x27;}]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Search results: [{&#x27;title&#x27;: &quot;LLM Powered Autonomous Agents | Lil&#x27;Log&quot;, &#x27;link&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;, &#x27;snippet&#x27;: &#x27;Jun 23, 2023 ... Task decomposition can be done (1) by LLM with simple prompting like &quot;Steps for XYZ.\\n1.&quot; , &quot;What are the subgoals for achieving XYZ?&#x27;}]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:New URLs to load: [&#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Grabbing most relevant splits from urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    Fetching pages: 100%|###################################################################################################################################| 1/1 [00:00&lt;00:00,  6.32it/s]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token builtin" style="color:rgb(0, 112, 193)">len</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">docs</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="run-locally">Run locally<a href="#run-locally" class="hash-link" aria-label="Direct link to Run locally" title="Direct link to Run locally">​</a></h3><p>Specify LLM and embeddings that will run locally (e.g., on your laptop).</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">llms </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> LlamaCpp</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">embeddings </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> GPT4AllEmbeddings</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">callbacks</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">manager </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> CallbackManager</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">callbacks</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">streaming_stdout </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> StreamingStdOutCallbackHandler</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">n_gpu_layers </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(9, 134, 88)">1</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># Metal set to 1 is enough.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">n_batch </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(9, 134, 88)">512</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">callback_manager </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> CallbackManager</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">[</span><span class="token plain">StreamingStdOutCallbackHandler</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">]</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">llama </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> LlamaCpp</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    model_path</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;/Users/rlm/Desktop/Code/llama.cpp/llama-2-13b-chat.ggmlv3.q4_0.bin&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_gpu_layers</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">n_gpu_layers</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_batch</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">n_batch</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    n_ctx</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">4096</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># Context window</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    max_tokens</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token number" style="color:rgb(9, 134, 88)">1000</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># Max tokens to generate</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    f16_kv</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(0, 128, 0)"># MUST set to True, otherwise you will run into problem after a couple of calls</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    callback_manager</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">callback_manager</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    verbose</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">vectorstore_llama </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> Chroma</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">embedding_function</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">GPT4AllEmbeddings</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">persist_directory</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;./chroma_db_llama&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><h4 style="padding-left:0.65rem;margin-bottom:0.45rem">API Reference:</h4><ul style="padding-bottom:1rem"><li><a href="https://api.python.langchain.com/en/latest/llms/langchain.llms.llamacpp.LlamaCpp.html"><span>LlamaCpp</span></a></li><li><a href="https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.gpt4all.GPT4AllEmbeddings.html"><span>GPT4AllEmbeddings</span></a></li><li><a href="https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.manager.CallbackManager.html"><span>CallbackManager</span></a></li><li><a href="https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.streaming_stdout.StreamingStdOutCallbackHandler.html"><span>StreamingStdOutCallbackHandler</span></a></li></ul></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    llama.cpp: loading model from /Users/rlm/Desktop/Code/llama.cpp/llama-2-13b-chat.ggmlv3.q4_0.bin</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: format     = ggjt v3 (latest)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: n_vocab    = 32000</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: n_ctx      = 4096</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: n_embd     = 5120</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: n_mult     = 256</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: n_head     = 40</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: n_layer    = 40</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: n_rot      = 128</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: freq_base  = 10000.0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: freq_scale = 1</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: ftype      = 2 (mostly Q4_0)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: n_ff       = 13824</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: model size = 13B</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: ggml ctx size =    0.09 MB</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_model_load_internal: mem required  = 9132.71 MB (+ 1608.00 MB per state)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_new_context_with_model: kv self size  = 3200.00 MB</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: allocating</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    Found model file at  /Users/rlm/.cache/gpt4all/ggml-all-MiniLM-L6-v2-f16.bin</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_new_context_with_model: max tensor size =    87.89 MB</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: using MPS</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loading &#x27;/Users/rlm/miniforge3/envs/llama/lib/python3.9/site-packages/llama_cpp/ggml-metal.metal&#x27;</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_add                            0x110fbd600</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_mul                            0x110fbeb30</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_mul_row                        0x110fbf350</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_scale                          0x110fbf9e0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_silu                           0x110fc0150</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_relu                           0x110fbd950</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_gelu                           0x110fbdbb0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_soft_max                       0x110fc14d0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_diag_mask_inf                  0x110fc1980</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_get_rows_f16                   0x110fc22a0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_get_rows_q4_0                  0x110fc2ad0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_get_rows_q4_1                  0x110fc3260</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_get_rows_q2_K                  0x110fc3ad0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_get_rows_q3_K                  0x110fc41c0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_get_rows_q4_K                  0x110fc48c0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_get_rows_q5_K                  0x110fc4fa0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_get_rows_q6_K                  0x110fc56a0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_rms_norm                       0x110fc5da0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_norm                           0x110fc64d0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x2a5c19990</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x2a5c1d4a0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x2a5c19fc0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_mul_mat_q2_K_f32               0x2a5c1dcc0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_mul_mat_q3_K_f32               0x2a5c1e420</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_mul_mat_q4_K_f32               0x2a5c1edc0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_mul_mat_q5_K_f32               0x2a5c1fd90</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_mul_mat_q6_K_f32               0x2a5c20540</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_rope                           0x2a5c20d40</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_alibi_f32                      0x2a5c21730</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_cpy_f32_f16                    0x2a5c21ab0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_cpy_f32_f32                    0x2a5c22080</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: loaded kernel_cpy_f16_f16                    0x2a5c231d0</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: recommendedMaxWorkingSetSize = 21845.34 MB</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: hasUnifiedMemory             = true</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_init: maxTransferRate              = built-in GPU</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_add_buffer: allocated &#x27;data            &#x27; buffer, size =  6984.06 MB, ( 6984.52 / 21845.34)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_add_buffer: allocated &#x27;eval            &#x27; buffer, size =  1040.00 MB, ( 8024.52 / 21845.34)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_add_buffer: allocated &#x27;kv              &#x27; buffer, size =  3202.00 MB, (11226.52 / 21845.34)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_add_buffer: allocated &#x27;scr0            &#x27; buffer, size =   597.00 MB, (11823.52 / 21845.34)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | </span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    ggml_metal_add_buffer: allocated &#x27;scr1            &#x27; buffer, size =   512.00 MB, (12335.52 / 21845.34)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    objc[33471]: Class GGMLMetalClass is implemented in both /Users/rlm/miniforge3/envs/llama/lib/python3.9/site-packages/llama_cpp/libllama.dylib (0x2c7368208) and /Users/rlm/miniforge3/envs/llama/lib/python3.9/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libreplit-mainline-metal.dylib (0x5ebf48208). One of the two will be used. Which one is undefined.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    objc[33471]: Class GGMLMetalClass is implemented in both /Users/rlm/miniforge3/envs/llama/lib/python3.9/site-packages/llama_cpp/libllama.dylib (0x2c7368208) and /Users/rlm/miniforge3/envs/llama/lib/python3.9/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllamamodel-mainline-metal.dylib (0x5ec374208). One of the two will be used. Which one is undefined.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><p>We supplied <code>StreamingStdOutCallbackHandler()</code>, so model outputs (e.g., generated questions) are streamed. </p><p>We also have logging on, so we seem them there too.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token keyword" style="color:rgb(0, 0, 255)">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">chains </span><span class="token keyword" style="color:rgb(0, 0, 255)">import</span><span class="token plain"> RetrievalQAWithSourcesChain</span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token comment" style="color:rgb(0, 128, 0)"># Initialize</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">web_research_retriever </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> WebResearchRetriever</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">from_llm</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    vectorstore</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">vectorstore_llama</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llm</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">llama</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    search</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">search</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain"></span><span class="token comment" style="color:rgb(0, 128, 0)"># Run</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">user_input </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(163, 21, 21)">&quot;What is Task Decomposition in LLM Powered Autonomous Agents?&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">qa_chain </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> RetrievalQAWithSourcesChain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">.</span><span class="token plain">from_chain_type</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token plain">llama</span><span class="token punctuation" style="color:rgb(4, 81, 165)">,</span><span class="token plain">retriever</span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain">web_research_retriever</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">result </span><span class="token operator" style="color:rgb(0, 0, 0)">=</span><span class="token plain"> qa_chain</span><span class="token punctuation" style="color:rgb(4, 81, 165)">(</span><span class="token punctuation" style="color:rgb(4, 81, 165)">{</span><span class="token string" style="color:rgb(163, 21, 21)">&quot;question&quot;</span><span class="token punctuation" style="color:rgb(4, 81, 165)">:</span><span class="token plain"> user_input</span><span class="token punctuation" style="color:rgb(4, 81, 165)">}</span><span class="token punctuation" style="color:rgb(4, 81, 165)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">result</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div style="padding-top:1.3rem;background:var(--prism-background-color);color:var(--prism-color);margin-top:calc(-1 * var(--ifm-leading) - 5px);margin-bottom:var(--ifm-leading);box-shadow:var(--ifm-global-shadow-lw);border-bottom-left-radius:var(--ifm-code-border-radius);border-bottom-right-radius:var(--ifm-code-border-radius)"><h4 style="padding-left:0.65rem;margin-bottom:0.45rem">API Reference:</h4><ul style="padding-bottom:1rem"><li><a href="https://api.python.langchain.com/en/latest/chains/langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain.html"><span>RetrievalQAWithSourcesChain</span></a></li></ul></div><div lang="python"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#000000;--prism-background-color:#F5F5F5"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Generating questions for Google Search ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">      Sure, here are five Google search queries that are similar to &quot;What is Task Decomposition in LLM Powered Autonomous Agents?&quot;:</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    1. How does Task Decomposition work in LLM Powered Autonomous Agents? </span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    2. What are the benefits of using Task Decomposition in LLM Powered Autonomous Agents? </span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    3. Can you provide examples of Task Decomposition in LLM Powered Autonomous Agents? </span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    4. How does Task Decomposition improve the performance of LLM Powered Autonomous Agents? </span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    5. What are some common challenges or limitations of using Task Decomposition in LLM Powered Autonomous Agents, and how can they be addressed?</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_print_timings:        load time =  8585.01 ms</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_print_timings:      sample time =   124.24 ms /   164 runs   (    0.76 ms per token,  1320.04 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_print_timings: prompt eval time =  8584.83 ms /   101 tokens (   85.00 ms per token,    11.76 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_print_timings:        eval time =  7268.55 ms /   163 runs   (   44.59 ms per token,    22.43 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_print_timings:       total time = 16236.13 ms</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Questions for Google Search (raw): {&#x27;question&#x27;: &#x27;What is Task Decomposition in LLM Powered Autonomous Agents?&#x27;, &#x27;text&#x27;: LineList(lines=[&#x27;1. How does Task Decomposition work in LLM Powered Autonomous Agents? \n&#x27;, &#x27;2. What are the benefits of using Task Decomposition in LLM Powered Autonomous Agents? \n&#x27;, &#x27;3. Can you provide examples of Task Decomposition in LLM Powered Autonomous Agents? \n&#x27;, &#x27;4. How does Task Decomposition improve the performance of LLM Powered Autonomous Agents? \n&#x27;])}</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Questions for Google Search: [&#x27;1. How does Task Decomposition work in LLM Powered Autonomous Agents? \n&#x27;, &#x27;2. What are the benefits of using Task Decomposition in LLM Powered Autonomous Agents? \n&#x27;, &#x27;3. Can you provide examples of Task Decomposition in LLM Powered Autonomous Agents? \n&#x27;, &#x27;4. How does Task Decomposition improve the performance of LLM Powered Autonomous Agents? \n&#x27;]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Search results: [{&#x27;title&#x27;: &quot;LLM Powered Autonomous Agents | Lil&#x27;Log&quot;, &#x27;link&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;, &#x27;snippet&#x27;: &#x27;Jun 23, 2023 ... Task decomposition can be done (1) by LLM with simple prompting like &quot;Steps for XYZ.\\n1.&quot; , &quot;What are the subgoals for achieving XYZ?&#x27;}]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Search results: [{&#x27;title&#x27;: &quot;LLM Powered Autonomous Agents | Lil&#x27;Log&quot;, &#x27;link&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;, &#x27;snippet&#x27;: &#x27;Jun 23, 2023 ... Task decomposition can be done (1) by LLM with simple prompting like &quot;Steps for XYZ.\\n1.&quot; , &quot;What are the subgoals for achieving XYZ?&quot; , (2)\xa0...&#x27;}]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Search results: [{&#x27;title&#x27;: &quot;LLM Powered Autonomous Agents | Lil&#x27;Log&quot;, &#x27;link&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;, &#x27;snippet&#x27;: &#x27;Jun 23, 2023 ... A complicated task usually involves many steps. An agent needs to know what they are and plan ahead. Task Decomposition#. Chain of thought (CoT;\xa0...&#x27;}]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Searching for relevat urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Search results: [{&#x27;title&#x27;: &quot;LLM Powered Autonomous Agents | Lil&#x27;Log&quot;, &#x27;link&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;, &#x27;snippet&#x27;: &#x27;Jun 23, 2023 ... Agent System Overview In a LLM-powered autonomous agent system, ... Task decomposition can be done (1) by LLM with simple prompting like\xa0...&#x27;}]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:New URLs to load: [&#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    INFO:langchain.retrievers.web_research:Grabbing most relevant splits from urls ...</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    Fetching pages: 100%|###################################################################################################################################| 1/1 [00:00&lt;00:00, 10.49it/s]</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    Llama.generate: prefix-match hit</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     The content discusses Task Decomposition in LLM Powered Autonomous Agents, which involves breaking down large tasks into smaller, manageable subgoals for efficient handling of complex tasks.</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    SOURCES:</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    https://lilianweng.github.io/posts/2023-06-23-agent/</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    </span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_print_timings:        load time =  8585.01 ms</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_print_timings:      sample time =    52.88 ms /    72 runs   (    0.73 ms per token,  1361.55 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_print_timings: prompt eval time = 125925.13 ms /  2358 tokens (   53.40 ms per token,    18.73 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_print_timings:        eval time =  3504.16 ms /    71 runs   (   49.35 ms per token,    20.26 tokens per second)</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    llama_print_timings:       total time = 129584.60 ms</span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#000000"><span class="token plain">    {&#x27;question&#x27;: &#x27;What is Task Decomposition in LLM Powered Autonomous Agents?&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     &#x27;answer&#x27;: &#x27; The content discusses Task Decomposition in LLM Powered Autonomous Agents, which involves breaking down large tasks into smaller, manageable subgoals for efficient handling of complex tasks.\n&#x27;,</span><br></span><span class="token-line" style="color:#000000"><span class="token plain">     &#x27;sources&#x27;: &#x27;https://lilianweng.github.io/posts/2023-06-23-agent/&#x27;}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/langchain/docs/modules/data_connection/retrievers/vectorstore"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Vector store-backed retriever</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/langchain/docs/modules/data_connection/indexing"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Indexing</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#simple-usage" class="table-of-contents__link toc-highlight">Simple usage</a></li><li><a href="#more-flexibility" class="table-of-contents__link toc-highlight">More flexibility</a></li><li><a href="#run-locally" class="table-of-contents__link toc-highlight">Run locally</a></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/cU2adEyC7w" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/LangChainAI" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">GitHub</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/hwchase17/langchain" target="_blank" rel="noopener noreferrer" class="footer__link-item">Python<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/hwchase17/langchainjs" target="_blank" rel="noopener noreferrer" class="footer__link-item">JS/TS<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://langchain.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Homepage<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://blog.langchain.dev" target="_blank" rel="noopener noreferrer" class="footer__link-item">Blog<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 LangChain, Inc.</div></div></div></footer></div>
<script src="/langchain/assets/js/runtime~main.96bce49c.js"></script>
<script src="/langchain/assets/js/main.581eebae.js"></script>
</body>
</html>